{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd92af09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "nb_dir = os.path.split(os.getcwd())[0]\n",
    "if nb_dir not in sys.path:\n",
    "    sys.path.append(nb_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f56a508a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/teddy_t/miniconda3/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "from utils.config import Config\n",
    "from learner.dataset import FragmentDataset, DataCollator\n",
    "from utils.parser import command_parser\n",
    "from learner.model import Loss, Frag2Mol\n",
    "import argparse\n",
    "import pickle\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from learner.trainer import Trainer, save_ckpt\n",
    "from torch.nn import functional as F\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "611bc0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = pickle.load(open('RUNS/2022-07-15@11:41:09-LAPTOP-E1483HNR-CHEMBL/config/config.pkl', \"rb\"))\n",
    "vocab = pickle.load(open('RUNS/2022-07-15@11:41:09-LAPTOP-E1483HNR-CHEMBL/config/vocab.pkl', \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4cc0cb81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab created/loaded. Size: 90175. Effective size: 90175. Time elapsed: 00:00:00.\n",
      "loading best_loss.pt at epoch 9...\n",
      "Data loaded. Size: 1090461. Time elapsed: 00:00:00.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/teddy_t/miniconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py:487: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n",
      "Epoch loss:  0.17289263010025024\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "96\n",
      "Epoch loss:  0.4078162908554077\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "128\n",
      "Epoch loss:  0.5805893093347549\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "160\n",
      "Epoch loss:  0.8800695985555649\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "192\n",
      "Epoch loss:  1.1888530403375626\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "224\n",
      "Epoch loss:  1.5157525092363358\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "256\n",
      "Epoch loss:  1.7229757755994797\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "288\n",
      "Epoch loss:  1.960098534822464\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "320\n",
      "Epoch loss:  2.160068765282631\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "352\n",
      "Epoch loss:  2.4088552743196487\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "384\n",
      "Epoch loss:  2.6935195177793503\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "416\n",
      "Epoch loss:  2.835120916366577\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "448\n",
      "Epoch loss:  3.150307983160019\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "480\n",
      "Epoch loss:  3.316389635205269\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "512\n",
      "Epoch loss:  3.6600161343812943\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "544\n",
      "Epoch loss:  3.874921962618828\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "576\n",
      "Epoch loss:  4.052250370383263\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "608\n",
      "Epoch loss:  4.204348176717758\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "640\n",
      "Epoch loss:  4.438559949398041\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "672\n",
      "Epoch loss:  4.73278483748436\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "704\n",
      "Epoch loss:  4.87148642539978\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "736\n",
      "Epoch loss:  5.106197953224182\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "768\n",
      "Epoch loss:  5.357048898935318\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "800\n",
      "Epoch loss:  5.592932879924774\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "832\n",
      "Epoch loss:  5.781417712569237\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "864\n",
      "Epoch loss:  6.012952551245689\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "896\n",
      "Epoch loss:  6.279640421271324\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "928\n",
      "Epoch loss:  6.551081612706184\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "960\n",
      "Epoch loss:  6.876484289765358\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "992\n",
      "Epoch loss:  7.032197758555412\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "1024\n",
      "Epoch loss:  7.25567689538002\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "1056\n",
      "Epoch loss:  7.439495831727982\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "1088\n",
      "Epoch loss:  7.63402895629406\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "1120\n",
      "Epoch loss:  7.910906568169594\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "1152\n",
      "Epoch loss:  8.233135655522346\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "1184\n",
      "Epoch loss:  8.501288548111916\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "1216\n",
      "Epoch loss:  8.73927953839302\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "1248\n",
      "Epoch loss:  8.937973111867905\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "1280\n",
      "Epoch loss:  9.087584719061852\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "1312\n",
      "Epoch loss:  9.323833972215652\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "1344\n",
      "Epoch loss:  9.62026160955429\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "1376\n",
      "Epoch loss:  9.960909217596054\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "1408\n",
      "Epoch loss:  10.249485790729523\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "1440\n",
      "Epoch loss:  10.48762321472168\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "1472\n",
      "Epoch loss:  10.705121085047722\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "1504\n",
      "Epoch loss:  10.908623188734055\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "1536\n",
      "Epoch loss:  11.11296284198761\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "1568\n",
      "Epoch loss:  11.405384749174118\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "1600\n",
      "Epoch loss:  11.708635061979294\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "1632\n",
      "Epoch loss:  11.88506031036377\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "1664\n",
      "Epoch loss:  12.112017199397087\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "1696\n",
      "Epoch loss:  12.382950201630592\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "1728\n",
      "Epoch loss:  12.733243361115456\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "1760\n",
      "Epoch loss:  12.918660432100296\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "1792\n",
      "Epoch loss:  13.063260689377785\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "1824\n",
      "Epoch loss:  13.202404528856277\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "1856\n",
      "Epoch loss:  13.385580867528915\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "1888\n",
      "Epoch loss:  13.600460320711136\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "1920\n",
      "Epoch loss:  13.839936167001724\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "1952\n",
      "Epoch loss:  14.181361377239227\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "1984\n",
      "Epoch loss:  14.537412375211716\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "2016\n",
      "Epoch loss:  14.762244179844856\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "2048\n",
      "Epoch loss:  14.99466297030449\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "2080\n",
      "Epoch loss:  15.195698201656342\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "2112\n",
      "Epoch loss:  15.429504483938217\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "2144\n",
      "Epoch loss:  15.527897596359253\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "2176\n",
      "Epoch loss:  15.772283047437668\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "2208\n",
      "Epoch loss:  16.01100516319275\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "2240\n",
      "Epoch loss:  16.375172942876816\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "2272\n",
      "Epoch loss:  16.768494099378586\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "2304\n",
      "Epoch loss:  17.00002032518387\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "2336\n",
      "Epoch loss:  17.274851977825165\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "2368\n",
      "Epoch loss:  17.532454788684845\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "2400\n",
      "Epoch loss:  17.695610404014587\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "2432\n",
      "Epoch loss:  17.96276730298996\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "2464\n",
      "Epoch loss:  18.188699692487717\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "2496\n",
      "Epoch loss:  18.29314360767603\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "2528\n",
      "Epoch loss:  18.565766014158726\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "2560\n",
      "Epoch loss:  18.76871144026518\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "2592\n",
      "Epoch loss:  18.912467889487743\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "2624\n",
      "Epoch loss:  19.178897105157375\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "2656\n",
      "Epoch loss:  19.534921072423458\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "2688\n",
      "Epoch loss:  19.78863301128149\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "2720\n",
      "Epoch loss:  19.993317000567913\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "2752\n",
      "Epoch loss:  20.313965253531933\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "2784\n",
      "Epoch loss:  20.611401967704296\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "2816\n",
      "Epoch loss:  20.849001206457615\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "2848\n",
      "Epoch loss:  21.29086071997881\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "2880\n",
      "Epoch loss:  21.57700464874506\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "2912\n",
      "Epoch loss:  21.842215605080128\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "2944\n",
      "Epoch loss:  22.08458399027586\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "2976\n",
      "Epoch loss:  22.37033572047949\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "3008\n",
      "Epoch loss:  22.58634353429079\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "3040\n",
      "Epoch loss:  22.83494558185339\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "3072\n",
      "Epoch loss:  23.037974007427692\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "3104\n",
      "Epoch loss:  23.220230601727962\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "3136\n",
      "Epoch loss:  23.40279983729124\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "3168\n",
      "Epoch loss:  23.688542030751705\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "3200\n",
      "Epoch loss:  23.843533106148243\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "3232\n",
      "Epoch loss:  24.12347064167261\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "3264\n",
      "Epoch loss:  24.36788109689951\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "3296\n",
      "Epoch loss:  24.471333377063274\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "3328\n",
      "Epoch loss:  24.66107562929392\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "3360\n",
      "Epoch loss:  24.95541886240244\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "3392\n",
      "Epoch loss:  25.129143320024014\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "3424\n",
      "Epoch loss:  25.388733707368374\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "3456\n",
      "Epoch loss:  25.725724808871746\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "3488\n",
      "Epoch loss:  26.028832785785198\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "3520\n",
      "Epoch loss:  26.289392344653606\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "3552\n",
      "Epoch loss:  26.536516956984997\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "3584\n",
      "Epoch loss:  26.77865233272314\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "3616\n",
      "Epoch loss:  26.97638341039419\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "3648\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch loss:  27.242286764085293\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "3680\n",
      "Epoch loss:  27.445202223956585\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "3712\n",
      "Epoch loss:  27.634848915040493\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "3744\n",
      "Epoch loss:  27.973315499722958\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "3776\n",
      "Epoch loss:  28.1959111019969\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "3808\n",
      "Epoch loss:  28.423507653176785\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "3840\n",
      "Epoch loss:  28.612421549856663\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "3872\n",
      "Epoch loss:  28.821154482662678\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "3904\n",
      "Epoch loss:  28.984826751053333\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "3936\n",
      "Epoch loss:  29.151772387325764\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "3968\n",
      "Epoch loss:  29.343397699296474\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "4000\n",
      "Epoch loss:  29.46850637346506\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "4032\n",
      "Epoch loss:  29.56354756653309\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "4064\n",
      "Epoch loss:  29.809740766882896\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "4096\n",
      "Epoch loss:  30.27274389564991\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "4128\n",
      "Epoch loss:  30.548935428261757\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "4160\n",
      "Epoch loss:  30.721653178334236\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "4192\n",
      "Epoch loss:  30.89029422402382\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "4224\n",
      "Epoch loss:  31.037407621741295\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "4256\n",
      "Epoch loss:  31.254524171352386\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "4288\n",
      "Epoch loss:  31.396748766303062\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "4320\n",
      "Epoch loss:  31.75785280764103\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "4352\n",
      "Epoch loss:  31.970728158950806\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "4384\n",
      "Epoch loss:  32.119891345500946\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "4416\n",
      "Epoch loss:  32.318285539746284\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "4448\n",
      "Epoch loss:  32.518642008304596\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "4480\n",
      "Epoch loss:  32.67616152763367\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "4512\n",
      "Epoch loss:  32.85347753763199\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "4544\n",
      "Epoch loss:  33.15734922885895\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "4576\n",
      "Epoch loss:  33.413078635931015\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "4608\n",
      "Epoch loss:  33.53319436311722\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "4640\n",
      "Epoch loss:  33.7985645532608\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "4672\n",
      "Epoch loss:  34.0170708745718\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "4704\n",
      "Epoch loss:  34.32842452824116\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "4736\n",
      "Epoch loss:  34.47057542204857\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "4768\n",
      "Epoch loss:  34.698539435863495\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "4800\n",
      "Epoch loss:  34.945948511362076\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "4832\n",
      "Epoch loss:  35.20733231306076\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "4864\n",
      "Epoch loss:  35.46024492383003\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "4896\n",
      "Epoch loss:  35.72151255607605\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "4928\n",
      "Epoch loss:  35.93420633673668\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "4960\n",
      "Epoch loss:  36.11421912908554\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "4992\n",
      "Epoch loss:  36.342790111899376\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "5024\n",
      "Epoch loss:  36.541098818182945\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "5056\n",
      "Epoch loss:  36.80360458791256\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "5088\n",
      "Epoch loss:  37.049927055835724\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "5120\n",
      "Epoch loss:  37.271133080124855\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "5152\n",
      "Epoch loss:  37.56611727178097\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "5184\n",
      "Epoch loss:  37.80928957462311\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "5216\n",
      "Epoch loss:  38.021655797958374\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "5248\n",
      "Epoch loss:  38.220646381378174\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "5280\n",
      "Epoch loss:  38.54342678189278\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "5312\n",
      "Epoch loss:  38.80933302640915\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "5344\n",
      "Epoch loss:  39.06228479743004\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "5376\n",
      "Epoch loss:  39.40191912651062\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "5408\n",
      "Epoch loss:  39.57958424091339\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "5440\n",
      "Epoch loss:  39.77744436264038\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "5472\n",
      "Epoch loss:  39.93892548978329\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "5504\n",
      "Epoch loss:  40.06519351899624\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "5536\n",
      "Epoch loss:  40.25595864653587\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "5568\n",
      "Epoch loss:  40.44711869955063\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "5600\n",
      "Epoch loss:  40.68974943459034\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "5632\n",
      "Epoch loss:  40.84435707330704\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "5664\n",
      "Epoch loss:  41.16151747107506\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "5696\n",
      "Epoch loss:  41.404667630791664\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "5728\n",
      "Epoch loss:  41.59992444515228\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "5760\n",
      "Epoch loss:  41.849486500024796\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "5792\n",
      "Epoch loss:  41.981545865535736\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "5824\n",
      "Epoch loss:  42.24711126089096\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "5856\n",
      "Epoch loss:  42.62430766224861\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "5888\n",
      "Epoch loss:  42.7833763808012\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "5920\n",
      "Epoch loss:  42.93858531117439\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "5952\n",
      "Epoch loss:  43.12333098053932\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "5984\n",
      "Epoch loss:  43.31296879053116\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "6016\n",
      "Epoch loss:  43.51434952020645\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "6048\n",
      "Epoch loss:  43.716436848044395\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "6080\n",
      "Epoch loss:  43.95533508062363\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "6112\n",
      "Epoch loss:  44.182330414652824\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "6144\n",
      "Epoch loss:  44.40970826148987\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "6176\n",
      "Epoch loss:  44.60528223216534\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "6208\n",
      "Epoch loss:  44.98121862113476\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "6240\n",
      "Epoch loss:  45.193286284804344\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "6272\n",
      "Epoch loss:  45.40037661790848\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "6304\n",
      "Epoch loss:  45.75222161412239\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "6336\n",
      "Epoch loss:  46.0533222258091\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "6368\n",
      "Epoch loss:  46.305945456027985\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "6400\n",
      "Epoch loss:  46.49886702001095\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "6432\n",
      "Epoch loss:  46.730366840958595\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "6464\n",
      "Epoch loss:  46.94209173321724\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "6496\n",
      "Epoch loss:  47.13281798362732\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "6528\n",
      "Epoch loss:  47.27815927565098\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "6560\n",
      "Epoch loss:  47.48160697519779\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "6592\n",
      "Epoch loss:  47.767673805356026\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "6624\n",
      "Epoch loss:  47.99047814309597\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "6656\n",
      "Epoch loss:  48.17223960161209\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "6688\n",
      "Epoch loss:  48.45936036109924\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "6720\n",
      "Epoch loss:  48.62152364850044\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "6752\n",
      "Epoch loss:  48.91542872786522\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "6784\n",
      "Epoch loss:  49.33226752281189\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "6816\n",
      "Epoch loss:  49.596745401620865\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "6848\n",
      "Epoch loss:  49.80715762078762\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "6880\n",
      "Epoch loss:  50.016563549637794\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "6912\n",
      "Epoch loss:  50.27149794995785\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "6944\n",
      "Epoch loss:  50.54831211268902\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "6976\n",
      "Epoch loss:  50.82073114812374\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "7008\n",
      "Epoch loss:  51.06446652114391\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "7040\n",
      "Epoch loss:  51.207317903637886\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "7072\n",
      "Epoch loss:  51.471125051379204\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "7104\n",
      "Epoch loss:  51.70278473198414\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "7136\n",
      "Epoch loss:  51.938720136880875\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "7168\n",
      "Epoch loss:  52.2263417840004\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "7200\n",
      "Epoch loss:  52.393355548381805\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "7232\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch loss:  52.68371531367302\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "7264\n",
      "Epoch loss:  52.899058654904366\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "7296\n",
      "Epoch loss:  53.12840047478676\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "7328\n",
      "Epoch loss:  53.31436009705067\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "7360\n",
      "Epoch loss:  53.513392210006714\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "7392\n",
      "Epoch loss:  53.79151776432991\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "7424\n",
      "Epoch loss:  53.979029819369316\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "7456\n",
      "Epoch loss:  54.23101417720318\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "7488\n",
      "Epoch loss:  54.40046267211437\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "7520\n",
      "Epoch loss:  54.61808027327061\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "7552\n",
      "Epoch loss:  54.90964566171169\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "7584\n",
      "Epoch loss:  55.24100239574909\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "7616\n",
      "Epoch loss:  55.4862712174654\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "7648\n",
      "Epoch loss:  55.6717010140419\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "7680\n",
      "Epoch loss:  55.84397183358669\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "7712\n",
      "Epoch loss:  56.00097952783108\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "7744\n",
      "Epoch loss:  56.28822575509548\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "7776\n",
      "Epoch loss:  56.50975036621094\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "7808\n",
      "Epoch loss:  56.69198478758335\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "7840\n",
      "Epoch loss:  56.9864437431097\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "7872\n",
      "Epoch loss:  57.18111436069012\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "7904\n",
      "Epoch loss:  57.44511400163174\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "7936\n",
      "Epoch loss:  57.59190049767494\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "7968\n",
      "Epoch loss:  57.9194912314415\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "8000\n",
      "Epoch loss:  58.188298404216766\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "8032\n",
      "Epoch loss:  58.4705014526844\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "8064\n",
      "Epoch loss:  58.701509311795235\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "8096\n",
      "Epoch loss:  58.91111458837986\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "8128\n",
      "Epoch loss:  59.118564784526825\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "8160\n",
      "Epoch loss:  59.30095574259758\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "8192\n",
      "Epoch loss:  59.588321179151535\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "8224\n",
      "Epoch loss:  59.79132425785065\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "8256\n",
      "Epoch loss:  60.0330570936203\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "8288\n",
      "Epoch loss:  60.223799616098404\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "8320\n",
      "Epoch loss:  60.36681418120861\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "8352\n",
      "Epoch loss:  60.58471621572971\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "8384\n",
      "Epoch loss:  60.76784273982048\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "8416\n",
      "Epoch loss:  60.99946203827858\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "8448\n",
      "Epoch loss:  61.26836320757866\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "8480\n",
      "Epoch loss:  61.4624125957489\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "8512\n",
      "Epoch loss:  61.66121754050255\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "8544\n",
      "Epoch loss:  61.87240840494633\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "8576\n",
      "Epoch loss:  62.13793770968914\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "8608\n",
      "Epoch loss:  62.43591450154781\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "8640\n",
      "Epoch loss:  62.57849434018135\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "8672\n",
      "Epoch loss:  62.82205930352211\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "8704\n",
      "Epoch loss:  63.117184817790985\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "8736\n",
      "Epoch loss:  63.39370548725128\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "8768\n",
      "Epoch loss:  63.641579300165176\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "8800\n",
      "Epoch loss:  63.88496707379818\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "8832\n",
      "Epoch loss:  64.09906972944736\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "8864\n",
      "Epoch loss:  64.46908129751682\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "8896\n",
      "Epoch loss:  64.69553489983082\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "8928\n",
      "Epoch loss:  64.90569588541985\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "8960\n",
      "Epoch loss:  65.11528913676739\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "8992\n",
      "Epoch loss:  65.27827632427216\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "9024\n",
      "Epoch loss:  65.57650426030159\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "9056\n",
      "Epoch loss:  65.72243568301201\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "9088\n",
      "Epoch loss:  65.9118972569704\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "9120\n",
      "Epoch loss:  66.15072172880173\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "9152\n",
      "Epoch loss:  66.45113521814346\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "9184\n",
      "Epoch loss:  66.63345365226269\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "9216\n",
      "Epoch loss:  66.85554367303848\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "9248\n",
      "Epoch loss:  67.05667577683926\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "9280\n",
      "Epoch loss:  67.18397280573845\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "9312\n",
      "Epoch loss:  67.40627340972424\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "9344\n",
      "Epoch loss:  67.54506842792034\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "9376\n",
      "Epoch loss:  67.77870428562164\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "9408\n",
      "Epoch loss:  68.0750383734703\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "9440\n",
      "Epoch loss:  68.37285336852074\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "9472\n",
      "Epoch loss:  68.59795318543911\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "9504\n",
      "Epoch loss:  68.75653532147408\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "9536\n",
      "Epoch loss:  68.95440593361855\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "9568\n",
      "Epoch loss:  69.23528343439102\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "9600\n",
      "Epoch loss:  69.42554220557213\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "9632\n",
      "Epoch loss:  69.62108321487904\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "9664\n",
      "Epoch loss:  69.80205258727074\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "9696\n",
      "Epoch loss:  70.08999001979828\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "9728\n",
      "Epoch loss:  70.28129468858242\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "9760\n",
      "Epoch loss:  70.40077644586563\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "9792\n",
      "Epoch loss:  70.58906562626362\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "9824\n",
      "Epoch loss:  70.8492573350668\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "9856\n",
      "Epoch loss:  71.09732228517532\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "9888\n",
      "Epoch loss:  71.31185811758041\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "9920\n",
      "Epoch loss:  71.49556662142277\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "9952\n",
      "Epoch loss:  71.65402168035507\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "9984\n",
      "Epoch loss:  71.85397577285767\n",
      "len:  34077\n",
      "Dataset: <class 'tuple'>\n",
      "10016\n"
     ]
    }
   ],
   "source": [
    "dataset = FragmentDataset(config)\n",
    "vocab = dataset.get_vocab()\n",
    "load_last = config.get('load_last')\n",
    "trainer, epoch = Trainer.load(config, vocab, last=load_last)\n",
    "data_sample, mu_stack = trainer.train(dataset.get_loader(), epoch + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c46f344e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sample_index = [item for sublist in data_sample for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "866583ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.92612, 4.1662 , 1.0295 , ..., 3.11182, 3.7222 , 4.64287])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.data.iloc[data_sample_index].logP.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a5ab86d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12, 10))\n",
    "plt.scatter(mu_stack[:9984, 0].detach().numpy(), mu_stack[:9984, 1].detach().numpy(), c=dataset.data.iloc[data_sample_index].logP.to_numpy())\n",
    "plt.xlabel(\"z[0]\")\n",
    "plt.ylabel(\"z[1]\")\n",
    "plt.colorbar()\n",
    "#plt.xlim(-0.0008, 0.0008)\n",
    "#plt.ylim(-0.0009, 0.0009)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "82853075",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "x = mu_stack[:9984].detach().numpy()\n",
    "x = StandardScaler().fit_transform(x)\n",
    "pca = PCA(n_components=3)\n",
    "principalComponents = pca.fit_transform(x)\n",
    "principalDf = pd.DataFrame(data = principalComponents, columns = ['pc1', 'pc2', 'pc3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ccce364b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pc1</th>\n",
       "      <th>pc2</th>\n",
       "      <th>pc3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.077090</td>\n",
       "      <td>-0.050692</td>\n",
       "      <td>0.017952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.077132</td>\n",
       "      <td>-0.052495</td>\n",
       "      <td>0.017956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.077131</td>\n",
       "      <td>-0.052482</td>\n",
       "      <td>0.017941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.077131</td>\n",
       "      <td>-0.052482</td>\n",
       "      <td>0.017957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.077131</td>\n",
       "      <td>-0.052482</td>\n",
       "      <td>0.017955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9979</th>\n",
       "      <td>-0.077164</td>\n",
       "      <td>-0.052512</td>\n",
       "      <td>-0.798874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9980</th>\n",
       "      <td>-0.077159</td>\n",
       "      <td>-0.052507</td>\n",
       "      <td>-0.748614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9981</th>\n",
       "      <td>-0.077160</td>\n",
       "      <td>-0.052508</td>\n",
       "      <td>-0.803975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9982</th>\n",
       "      <td>-0.077160</td>\n",
       "      <td>-0.052508</td>\n",
       "      <td>-0.865643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9983</th>\n",
       "      <td>-0.077163</td>\n",
       "      <td>-0.052511</td>\n",
       "      <td>-0.809417</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9984 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           pc1       pc2       pc3\n",
       "0    -0.077090 -0.050692  0.017952\n",
       "1    -0.077132 -0.052495  0.017956\n",
       "2    -0.077131 -0.052482  0.017941\n",
       "3    -0.077131 -0.052482  0.017957\n",
       "4    -0.077131 -0.052482  0.017955\n",
       "...        ...       ...       ...\n",
       "9979 -0.077164 -0.052512 -0.798874\n",
       "9980 -0.077159 -0.052507 -0.748614\n",
       "9981 -0.077160 -0.052508 -0.803975\n",
       "9982 -0.077160 -0.052508 -0.865643\n",
       "9983 -0.077163 -0.052511 -0.809417\n",
       "\n",
       "[9984 rows x 3 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "principalDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b170589b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12, 10))\n",
    "plt.scatter(principalDf['pc1'].to_numpy(), \n",
    "            principalDf['pc2'].to_numpy(), \n",
    "            c=dataset.data.iloc[data_sample_index].logP.to_numpy())\n",
    "plt.xlabel(\"PC1\")\n",
    "plt.ylabel(\"PC2\")\n",
    "plt.colorbar()\n",
    "plt.xlim(-0.08, -0.075)\n",
    "plt.ylim(-0.055, -0.05)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "69bf6cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimizer(config, model):\n",
    "    return Adam(model.parameters(), lr=config.get('optim_lr'))\n",
    "\n",
    "\n",
    "def get_scheduler(config, optimizer):\n",
    "    return StepLR(optimizer,\n",
    "                  step_size=config.get('sched_step_size'),\n",
    "                  gamma=config.get('sched_gamma'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "89cd76de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-94-1785cb37f18f>:7: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  best_loss = np.float('inf')\n",
      "<ipython-input-94-1785cb37f18f>:9: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  best_score = - np.float('inf')\n"
     ]
    }
   ],
   "source": [
    "model = Frag2Mol(config, vocab)\n",
    "optimizer = get_optimizer(config, model)\n",
    "scheduler = get_scheduler(config, optimizer)\n",
    "criterion = Loss(config, pad=vocab.PAD)\n",
    "model = model.cuda()\n",
    "losses = []\n",
    "best_loss = np.float('inf')\n",
    "scores = []\n",
    "best_score = - np.float('inf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6b1acfa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Frag2Mol(\n",
       "  (embedder): Embedding(90175, 64)\n",
       "  (latent2rnn): Linear(in_features=100, out_features=64, bias=True)\n",
       "  (encoder): Encoder(\n",
       "    (rnn): GRU(64, 64, num_layers=2, batch_first=True, dropout=0.3)\n",
       "    (rnn2mean): Linear(in_features=128, out_features=100, bias=True)\n",
       "    (rnn2logv): Linear(in_features=128, out_features=100, bias=True)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (rnn): GRU(64, 64, num_layers=2, batch_first=True, dropout=0.3)\n",
       "    (rnn2out): Linear(in_features=64, out_features=90175, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "69c0461a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded. Size: 1090461. Time elapsed: 00:00:00.\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(dataset.get_loader()))[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "fbf1f9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cpu')\n",
    "src = batch[0].to(device)\n",
    "tgt = batch[1]\n",
    "lengths = batch[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "ed9251a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "3ddf40ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "0efa32f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = model(Variable(src), lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "3de87387",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchviz in /home/teddy_t/miniconda3/lib/python3.9/site-packages (0.0.2)\r\n",
      "Requirement already satisfied: torch in /home/teddy_t/miniconda3/lib/python3.9/site-packages (from torchviz) (1.11.0)\r\n",
      "Requirement already satisfied: graphviz in /home/teddy_t/miniconda3/lib/python3.9/site-packages (from torchviz) (0.20.1)\r\n",
      "Requirement already satisfied: typing_extensions in /home/teddy_t/miniconda3/lib/python3.9/site-packages (from torch->torchviz) (4.1.1)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install torchviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "113fe7f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'rnn_torchviz.png'"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchviz import make_dot\n",
    "\n",
    "make_dot(yhat, params=dict(list(model.named_parameters()))).render(\"rnn_torchviz\", format=\"png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07a0aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(dataloader_train))\n",
    "yhat = model(batch.text) # Give dummy batch to forward()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8c7bee2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = vocab.get_size()\n",
    "embed_size = config.get('embed_size')\n",
    "hidden_size = config.get('hidden_size')\n",
    "hidden_layers = config.get('hidden_layers')\n",
    "latent_size = config.get('latent_size')\n",
    "dropout = config.get('dropout')\n",
    "use_gpu = config.get('use_gpu')\n",
    "embeddings = model.load_embeddings()\n",
    "embedder = nn.Embedding.from_pretrained(embeddings)\n",
    "\n",
    "latent2rnn = nn.Linear(\n",
    "    in_features=latent_size,\n",
    "    out_features=hidden_size)\n",
    "\n",
    "encoder = Encoder(\n",
    "    input_size=input_size,\n",
    "    embed_size=embed_size,\n",
    "    hidden_size=hidden_size,\n",
    "    hidden_layers=hidden_layers,\n",
    "    latent_size=self.latent_size,\n",
    "    dropout=self.dropout,\n",
    "    use_gpu=self.use_gpu)\n",
    "\n",
    "self.decoder = Decoder(\n",
    "    embed_size=self.embed_size,\n",
    "    latent_size=self.latent_size,\n",
    "    hidden_size=self.hidden_size,\n",
    "    hidden_layers=self.hidden_layers,\n",
    "    dropout=self.dropout,\n",
    "    output_size=self.input_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e78fe0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = FragmentDataset(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "bde59930",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded. Size: 1090461. Time elapsed: 00:00:00.\n"
     ]
    }
   ],
   "source": [
    "loader = dataset.get_loader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "11b13aab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab created/loaded. Size: 90175. Effective size: 90175. Time elapsed: 00:00:00.\n"
     ]
    }
   ],
   "source": [
    "dataset.vocab = dataset.get_vocab()\n",
    "collator = DataCollator(dataset.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c36e351",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-1785cb37f18f>:7: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  best_loss = np.float('inf')\n",
      "<ipython-input-10-1785cb37f18f>:9: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  best_score = - np.float('inf')\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "935fa661",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "Caught KeyError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/teddy_t/miniconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py\", line 3621, in get_loc\n    return self._engine.get_loc(casted_key)\n  File \"pandas/_libs/index.pyx\", line 136, in pandas._libs.index.IndexEngine.get_loc\n  File \"pandas/_libs/index.pyx\", line 163, in pandas._libs.index.IndexEngine.get_loc\n  File \"pandas/_libs/hashtable_class_helper.pxi\", line 5198, in pandas._libs.hashtable.PyObjectHashTable.get_item\n  File \"pandas/_libs/hashtable_class_helper.pxi\", line 5206, in pandas._libs.hashtable.PyObjectHashTable.get_item\nKeyError: 408988\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/teddy_t/miniconda3/lib/python3.9/site-packages/torch/utils/data/_utils/worker.py\", line 287, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/home/teddy_t/miniconda3/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\", line 49, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/teddy_t/miniconda3/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\", line 49, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/teddy_t/miniconda3/lib/python3.9/site-packages/pandas/core/frame.py\", line 3505, in __getitem__\n    indexer = self.columns.get_loc(key)\n  File \"/home/teddy_t/miniconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py\", line 3623, in get_loc\n    raise KeyError(key) from err\nKeyError: 408988\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[0;32mIn [161]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m scheduler\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, (src, tgt, lengths) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(loader):\n\u001b[1;32m      3\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m      5\u001b[0m     src, tgt \u001b[38;5;241m=\u001b[39m Variable(src), Variable(tgt)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py:530\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    528\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    529\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()\n\u001b[0;32m--> 530\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    531\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    532\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    533\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    534\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1224\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1222\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1223\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_task_info[idx]\n\u001b[0;32m-> 1224\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1250\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1248\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_put_index()\n\u001b[1;32m   1249\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ExceptionWrapper):\n\u001b[0;32m-> 1250\u001b[0m     \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1251\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/_utils.py:457\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    454\u001b[0m     \u001b[38;5;66;03m# If the exception takes multiple arguments, don't try to\u001b[39;00m\n\u001b[1;32m    455\u001b[0m     \u001b[38;5;66;03m# instantiate since we don't know how to\u001b[39;00m\n\u001b[1;32m    456\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m--> 457\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception\n",
      "\u001b[0;31mKeyError\u001b[0m: Caught KeyError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/teddy_t/miniconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py\", line 3621, in get_loc\n    return self._engine.get_loc(casted_key)\n  File \"pandas/_libs/index.pyx\", line 136, in pandas._libs.index.IndexEngine.get_loc\n  File \"pandas/_libs/index.pyx\", line 163, in pandas._libs.index.IndexEngine.get_loc\n  File \"pandas/_libs/hashtable_class_helper.pxi\", line 5198, in pandas._libs.hashtable.PyObjectHashTable.get_item\n  File \"pandas/_libs/hashtable_class_helper.pxi\", line 5206, in pandas._libs.hashtable.PyObjectHashTable.get_item\nKeyError: 408988\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/teddy_t/miniconda3/lib/python3.9/site-packages/torch/utils/data/_utils/worker.py\", line 287, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/home/teddy_t/miniconda3/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\", line 49, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/teddy_t/miniconda3/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\", line 49, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/teddy_t/miniconda3/lib/python3.9/site-packages/pandas/core/frame.py\", line 3505, in __getitem__\n    indexer = self.columns.get_loc(key)\n  File \"/home/teddy_t/miniconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py\", line 3623, in get_loc\n    raise KeyError(key) from err\nKeyError: 408988\n"
     ]
    }
   ],
   "source": [
    "scheduler.step()\n",
    "for idx, (src, tgt, lengths) in enumerate(loader):\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    src, tgt = Variable(src), Variable(tgt)\n",
    "    print(src)\n",
    "    print(tgt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "94be0be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(dataset=dataset.data,\n",
    "                    collate_fn=collator,\n",
    "                    batch_size=config.get('batch_size'),\n",
    "                    num_workers=24,\n",
    "                    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7cefd11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab created/loaded. Size: 90175. Effective size: 90175. Time elapsed: 00:00:00.\n",
      "Data loaded. Size: 1090461. Time elapsed: 00:00:00.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/teddy_t/miniconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py:487: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m vocab \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mget_vocab()\n\u001b[1;32m      3\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(config, vocab)\n\u001b[0;32m----> 4\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loader\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/UCL/drug_discovery/models/fragment-based-dgm/learner/trainer.py:180\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, loader, start_epoch)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(start_epoch, start_epoch \u001b[38;5;241m+\u001b[39m num_epochs):\n\u001b[1;32m    178\u001b[0m     start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m--> 180\u001b[0m     epoch_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    181\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlosses\u001b[38;5;241m.\u001b[39mappend(epoch_loss)\n\u001b[1;32m    182\u001b[0m     logger\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m, epoch_loss, epoch)\n",
      "File \u001b[0;32m~/UCL/drug_discovery/models/fragment-based-dgm/learner/trainer.py:133\u001b[0m, in \u001b[0;36mTrainer._train_epoch\u001b[0;34m(self, epoch, loader)\u001b[0m\n\u001b[1;32m    129\u001b[0m     tgt \u001b[38;5;241m=\u001b[39m tgt\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[1;32m    131\u001b[0m output, mu, sigma \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(src, lengths)\n\u001b[0;32m--> 133\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtgt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msigma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    134\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m    135\u001b[0m clip_grad_norm_(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mparameters(),\n\u001b[1;32m    136\u001b[0m                 \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclip_norm\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/UCL/drug_discovery/models/fragment-based-dgm/learner/model.py:153\u001b[0m, in \u001b[0;36mLoss.forward\u001b[0;34m(self, output, target, mu, sigma, epoch)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, output, target, mu, sigma, epoch):\n\u001b[0;32m--> 153\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_softmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    155\u001b[0m     \u001b[38;5;66;03m# flatten all predictions and targets\u001b[39;00m\n\u001b[1;32m    156\u001b[0m     target \u001b[38;5;241m=\u001b[39m target\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/nn/functional.py:1907\u001b[0m, in \u001b[0;36mlog_softmax\u001b[0;34m(input, dim, _stacklevel, dtype)\u001b[0m\n\u001b[1;32m   1905\u001b[0m     dim \u001b[38;5;241m=\u001b[39m _get_softmax_dim(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlog_softmax\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdim(), _stacklevel)\n\u001b[1;32m   1906\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1907\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_softmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdim\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1908\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1909\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mlog_softmax(dim, dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dataset = FragmentDataset(config)\n",
    "vocab = dataset.get_vocab()\n",
    "trainer = Trainer(config, vocab)\n",
    "trainer.train(dataset.get_loader(), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "714dfa6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(config, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44d92a7f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mload_embeddings()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "embeddings = model.load_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "a8897525",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([90175, 64])"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "54d38151",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<SOS>', '*CCC', '*N(CCc1cccc(-c2ccccc2)c1)C(=O)C1OC(C(=O)O)=CC(N)C1NC(C)=O', '<EOS>']\n",
      "[1, 11, 3]\n",
      "[11, 3, 2]\n",
      "4\n",
      "tensor([ 1., 11.,  3.], device='cuda:0')\n",
      "['<SOS>', '*c1ccc(O)cc1', '*C1CC(c2ccccc2)=NN1C(=S)Nc1ccccc1', '<EOS>']\n",
      "[1, 48, 4]\n",
      "[48, 4, 2]\n",
      "4\n",
      "tensor([ 1., 48.,  4.], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for index in range(2):\n",
    "    seq = dataset.data.fragments[index].split(\" \")\n",
    "    seq = vocab.append_delimiters(seq)\n",
    "    src = vocab.translate(seq[:-1])\n",
    "    tgt = vocab.translate(seq[1:])\n",
    "    lengths = len(seq)\n",
    "    print(seq)\n",
    "    print(src)\n",
    "    print(tgt)\n",
    "    print(lengths)\n",
    "    src, tgt = Variable(torch.Tensor(src)), Variable(torch.Tensor(tgt))\n",
    "    src = src.cuda()\n",
    "    print(src)\n",
    "    #output, mu, sigma = model(src, lengths)\n",
    "    #embeddings = model.embedder(src)\n",
    "    #print(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31094d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings1 = F.dropout(embeddings, p=model.dropout, training=model.training)\n",
    "z, mu, sigma = model.encoder(src, embeddings1, lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "66c956ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded. Size: 1090461. Time elapsed: 00:00:00.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "Caught AttributeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/teddy_t/miniconda3/lib/python3.9/site-packages/torch/utils/data/_utils/worker.py\", line 287, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/home/teddy_t/miniconda3/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\", line 49, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/teddy_t/miniconda3/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\", line 49, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/teddy_t/UCL/drug_discovery/models/fragment-based-dgm/learner/dataset.py\", line 51, in __getitem__\n    seq = self.vocab.append_delimiters(seq)\nAttributeError: 'NoneType' object has no attribute 'append_delimiters'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [43]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loader\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/UCL/drug_discovery/models/fragment-based-dgm/learner/trainer.py:180\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, loader, start_epoch)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(start_epoch, start_epoch \u001b[38;5;241m+\u001b[39m num_epochs):\n\u001b[1;32m    178\u001b[0m     start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m--> 180\u001b[0m     epoch_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    181\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlosses\u001b[38;5;241m.\u001b[39mappend(epoch_loss)\n\u001b[1;32m    182\u001b[0m     logger\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m, epoch_loss, epoch)\n",
      "File \u001b[0;32m~/UCL/drug_discovery/models/fragment-based-dgm/learner/trainer.py:123\u001b[0m, in \u001b[0;36mTrainer._train_epoch\u001b[0;34m(self, epoch, loader)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m epoch \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muse_scheduler\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscheduler\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m--> 123\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, (src, tgt, lengths) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(loader):\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m    126\u001b[0m     src, tgt \u001b[38;5;241m=\u001b[39m Variable(src), Variable(tgt)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py:530\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    528\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    529\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()\n\u001b[0;32m--> 530\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    531\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    532\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    533\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    534\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1224\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1222\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1223\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_task_info[idx]\n\u001b[0;32m-> 1224\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1250\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1248\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_put_index()\n\u001b[1;32m   1249\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ExceptionWrapper):\n\u001b[0;32m-> 1250\u001b[0m     \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1251\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/_utils.py:457\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    454\u001b[0m     \u001b[38;5;66;03m# If the exception takes multiple arguments, don't try to\u001b[39;00m\n\u001b[1;32m    455\u001b[0m     \u001b[38;5;66;03m# instantiate since we don't know how to\u001b[39;00m\n\u001b[1;32m    456\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m--> 457\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception\n",
      "\u001b[0;31mAttributeError\u001b[0m: Caught AttributeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/teddy_t/miniconda3/lib/python3.9/site-packages/torch/utils/data/_utils/worker.py\", line 287, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/home/teddy_t/miniconda3/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\", line 49, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/teddy_t/miniconda3/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\", line 49, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/teddy_t/UCL/drug_discovery/models/fragment-based-dgm/learner/dataset.py\", line 51, in __getitem__\n    seq = self.vocab.append_delimiters(seq)\nAttributeError: 'NoneType' object has no attribute 'append_delimiters'\n"
     ]
    }
   ],
   "source": [
    "trainer.train(dataset.get_loader(), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2a06078b",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Caught AttributeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/teddy_t/miniconda3/lib/python3.9/site-packages/torch/utils/data/_utils/worker.py\", line 287, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/home/teddy_t/miniconda3/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\", line 49, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/teddy_t/miniconda3/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\", line 49, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/teddy_t/UCL/drug_discovery/models/fragment-based-dgm/learner/dataset.py\", line 51, in __getitem__\n    seq = self.vocab.append_delimiters(seq)\nAttributeError: 'NoneType' object has no attribute 'append_delimiters'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [42]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloader\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/UCL/drug_discovery/models/fragment-based-dgm/learner/trainer.py:123\u001b[0m, in \u001b[0;36mTrainer._train_epoch\u001b[0;34m(self, epoch, loader)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m epoch \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muse_scheduler\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscheduler\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m--> 123\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, (src, tgt, lengths) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(loader):\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m    126\u001b[0m     src, tgt \u001b[38;5;241m=\u001b[39m Variable(src), Variable(tgt)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py:530\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    528\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    529\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()\n\u001b[0;32m--> 530\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    531\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    532\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    533\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    534\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1224\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1222\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1223\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_task_info[idx]\n\u001b[0;32m-> 1224\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1250\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1248\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_put_index()\n\u001b[1;32m   1249\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ExceptionWrapper):\n\u001b[0;32m-> 1250\u001b[0m     \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1251\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/_utils.py:457\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    454\u001b[0m     \u001b[38;5;66;03m# If the exception takes multiple arguments, don't try to\u001b[39;00m\n\u001b[1;32m    455\u001b[0m     \u001b[38;5;66;03m# instantiate since we don't know how to\u001b[39;00m\n\u001b[1;32m    456\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m--> 457\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception\n",
      "\u001b[0;31mAttributeError\u001b[0m: Caught AttributeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/teddy_t/miniconda3/lib/python3.9/site-packages/torch/utils/data/_utils/worker.py\", line 287, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/home/teddy_t/miniconda3/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\", line 49, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/teddy_t/miniconda3/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\", line 49, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/teddy_t/UCL/drug_discovery/models/fragment-based-dgm/learner/dataset.py\", line 51, in __getitem__\n    seq = self.vocab.append_delimiters(seq)\nAttributeError: 'NoneType' object has no attribute 'append_delimiters'\n"
     ]
    }
   ],
   "source": [
    "trainer._train_epoch(1, loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e7566ef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded. Size: 1090461. Time elapsed: 00:00:00.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "Caught AttributeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/teddy_t/miniconda3/lib/python3.9/site-packages/torch/utils/data/_utils/worker.py\", line 287, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/home/teddy_t/miniconda3/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\", line 49, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/teddy_t/miniconda3/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\", line 49, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/teddy_t/UCL/drug_discovery/models/fragment-based-dgm/learner/dataset.py\", line 51, in __getitem__\n    seq = self.vocab.append_delimiters(seq)\nAttributeError: 'NoneType' object has no attribute 'append_delimiters'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [34]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, (src, tgt, lengths) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(dataset\u001b[38;5;241m.\u001b[39mget_loader()):\n\u001b[1;32m      2\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py:530\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    528\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    529\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()\n\u001b[0;32m--> 530\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    531\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    532\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    533\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    534\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1224\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1222\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1223\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_task_info[idx]\n\u001b[0;32m-> 1224\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1250\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1248\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_put_index()\n\u001b[1;32m   1249\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ExceptionWrapper):\n\u001b[0;32m-> 1250\u001b[0m     \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1251\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/_utils.py:457\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    454\u001b[0m     \u001b[38;5;66;03m# If the exception takes multiple arguments, don't try to\u001b[39;00m\n\u001b[1;32m    455\u001b[0m     \u001b[38;5;66;03m# instantiate since we don't know how to\u001b[39;00m\n\u001b[1;32m    456\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m--> 457\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception\n",
      "\u001b[0;31mAttributeError\u001b[0m: Caught AttributeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/teddy_t/miniconda3/lib/python3.9/site-packages/torch/utils/data/_utils/worker.py\", line 287, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/home/teddy_t/miniconda3/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\", line 49, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/teddy_t/miniconda3/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\", line 49, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/teddy_t/UCL/drug_discovery/models/fragment-based-dgm/learner/dataset.py\", line 51, in __getitem__\n    seq = self.vocab.append_delimiters(seq)\nAttributeError: 'NoneType' object has no attribute 'append_delimiters'\n"
     ]
    }
   ],
   "source": [
    "for idx, (src, tgt, lengths) in enumerate(dataset.get_loader()):\n",
    "    optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "93f7f7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('../RUNS/2022-07-15@11:41:09-LAPTOP-E1483HNR-CHEMBL/ckpt/last.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "34e45e68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'epoch': 8,\n",
       " 'best_loss': 0.2500355492672882,\n",
       " 'losses': [51.92073293764322,\n",
       "  0.45190641643213764,\n",
       "  0.3796204249695559,\n",
       "  0.33542668754950683,\n",
       "  0.3045919733856347,\n",
       "  0.2819181991444859,\n",
       "  0.2643410344735349,\n",
       "  0.2500355492672882,\n",
       "  0.23796934265875444],\n",
       " 'best_score': -inf,\n",
       " 'scores': [],\n",
       " 'model': OrderedDict([('embedder.weight',\n",
       "               tensor([[-0.0125,  0.0451,  0.0232,  ..., -0.0229,  0.0329, -0.0143],\n",
       "                       [-0.0219,  0.0043, -0.0359,  ..., -0.0073,  0.0318,  0.0361],\n",
       "                       [-0.0493,  0.0011, -0.0083,  ..., -0.0258, -0.0407,  0.0397],\n",
       "                       ...,\n",
       "                       [ 0.0182,  0.0190,  0.0054,  ..., -0.0178, -0.0505, -0.1049],\n",
       "                       [-0.1286,  0.0624,  0.1299,  ..., -0.1102, -0.0515, -0.1588],\n",
       "                       [-0.0677,  0.0685,  0.0446,  ..., -0.0077, -0.0451, -0.1195]],\n",
       "                      device='cuda:0')),\n",
       "              ('latent2rnn.weight',\n",
       "               tensor([[ 0.1167,  0.1656, -0.1321,  ..., -0.0650,  0.0478, -0.1071],\n",
       "                       [-0.0039,  0.1575, -0.1424,  ..., -0.0985,  0.1011,  0.0480],\n",
       "                       [-0.1868, -0.2682,  0.3471,  ...,  0.1396, -0.2221, -0.0369],\n",
       "                       ...,\n",
       "                       [-0.0506, -0.2056,  0.2293,  ...,  0.0198, -0.0491,  0.0600],\n",
       "                       [ 0.1196,  0.2655, -0.2098,  ..., -0.0845,  0.1390, -0.0574],\n",
       "                       [ 0.0409,  0.2041, -0.1771,  ..., -0.1463,  0.1412,  0.0860]],\n",
       "                      device='cuda:0')),\n",
       "              ('latent2rnn.bias',\n",
       "               tensor([ 0.5226, -0.6835,  0.4226, -0.5047,  0.0038,  0.5312,  0.6493, -0.3965,\n",
       "                        0.0963, -0.5117,  0.2708, -0.5304,  0.5332, -0.5000,  0.3474, -0.4289,\n",
       "                        0.2904, -0.6076, -0.3001,  0.6998, -0.0235, -0.0092,  0.5459, -0.4284,\n",
       "                        0.3086,  0.5786,  0.3086,  0.2940,  0.3781, -0.3246, -0.1293,  0.7112,\n",
       "                       -0.4657, -0.2550, -0.3916,  0.5345,  0.7533, -0.5300, -0.3614, -0.6387,\n",
       "                       -0.0025,  0.5493,  0.5069, -0.2643, -0.4515,  0.4613,  0.5859, -0.7085,\n",
       "                        0.3073,  0.1417, -0.5692, -0.4748,  0.5483, -0.1584,  0.5663, -0.3240,\n",
       "                        0.4508, -0.4392,  0.4841, -0.3471,  0.5557, -0.2114,  0.2885, -0.3168],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.rnn.weight_ih_l0',\n",
       "               tensor([[ 0.0920,  0.1218,  0.0460,  ...,  0.0180,  0.0230, -0.1116],\n",
       "                       [ 0.1624,  0.0282,  0.1155,  ..., -0.1833, -0.1505, -0.0226],\n",
       "                       [ 0.1322, -0.0585,  0.1940,  ..., -0.0969, -0.0298, -0.1227],\n",
       "                       ...,\n",
       "                       [-0.1200, -0.0139,  0.0268,  ...,  0.1507,  0.0137,  0.0171],\n",
       "                       [ 0.0092, -0.1117,  0.0133,  ..., -0.0258, -0.1814, -0.1333],\n",
       "                       [ 0.0844, -0.0742,  0.0306,  ..., -0.1370, -0.1037, -0.0528]],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.rnn.weight_hh_l0',\n",
       "               tensor([[-0.0180,  0.1110,  0.2293,  ..., -0.1898,  0.1931,  0.2408],\n",
       "                       [ 0.1822,  0.1651,  0.0398,  ..., -0.1817, -0.0193,  0.1902],\n",
       "                       [ 0.1700,  0.1822,  0.1808,  ..., -0.0134,  0.0898,  0.2339],\n",
       "                       ...,\n",
       "                       [-0.1845, -0.1805, -0.1520,  ...,  0.1712, -0.2145, -0.2637],\n",
       "                       [ 0.1886,  0.1820,  0.2169,  ..., -0.0505,  0.1632,  0.2332],\n",
       "                       [ 0.2293,  0.1316,  0.2903,  ..., -0.1356,  0.2130,  0.2447]],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.rnn.bias_ih_l0',\n",
       "               tensor([ 0.1470,  0.3016,  0.1996,  0.1350,  0.0975,  0.1974,  0.1374,  0.2057,\n",
       "                        0.2393,  0.0756,  0.0998,  0.1564,  0.0798,  0.1887,  0.1731,  0.2478,\n",
       "                        0.1711,  0.0530,  0.2778,  0.1787,  0.1272,  0.0030,  0.2261,  0.2104,\n",
       "                        0.1304,  0.2762,  0.2896,  0.1587,  0.1854,  0.0591,  0.2975,  0.2404,\n",
       "                        0.2937,  0.3088,  0.0555,  0.1732,  0.3597,  0.2512,  0.1587,  0.1232,\n",
       "                        0.1522,  0.1753,  0.3889,  0.2707,  0.0784,  0.1267,  0.1823,  0.2397,\n",
       "                        0.2170,  0.0097,  0.0861,  0.2245,  0.2582,  0.2192,  0.1604,  0.0439,\n",
       "                        0.2081,  0.0739, -0.0105, -0.0135,  0.2216,  0.2505,  0.1830,  0.0983,\n",
       "                       -0.1834, -0.2344, -0.3619, -0.2588, -0.2241, -0.2394, -0.2993, -0.1822,\n",
       "                       -0.1928, -0.0895, -0.0533, -0.2338, -0.1289, -0.2417, -0.1492, -0.0529,\n",
       "                       -0.1579, -0.3102, -0.2005, -0.0593, -0.2055,  0.0182,  0.0297, -0.0246,\n",
       "                       -0.2213, -0.2050, -0.1519, -0.2179, -0.1081, -0.1704, -0.1624, -0.2075,\n",
       "                       -0.2017, -0.0692, -0.2932, -0.2248, -0.1756, -0.1102, -0.2397, -0.1353,\n",
       "                       -0.0457, -0.0537, -0.3206, -0.0544, -0.0486, -0.1611, -0.2342, -0.2108,\n",
       "                       -0.0613, -0.1386, -0.1646, -0.0782, -0.1684, -0.1276, -0.2369, -0.1883,\n",
       "                       -0.2123, -0.2077, -0.0525, -0.1433, -0.0573, -0.1067, -0.3127, -0.2118,\n",
       "                        0.0275,  0.2487,  0.4301,  0.4442,  0.0893,  0.1192,  0.2320,  0.2029,\n",
       "                        0.0746,  0.0288, -0.0011, -0.1359, -0.2104, -0.1355, -0.1309, -0.1828,\n",
       "                       -0.3929,  0.3270,  0.1310,  0.0781,  0.0570,  0.1154,  0.0622,  0.0588,\n",
       "                       -0.3208, -0.1041, -0.1510,  0.0679, -0.2400, -0.1501,  0.0988, -0.0376,\n",
       "                        0.2248, -0.1008, -0.2376, -0.0393, -0.3746, -0.0664, -0.0137, -0.1005,\n",
       "                        0.1549,  0.0165,  0.4162, -0.0770,  0.0471,  0.2249, -0.1670, -0.2968,\n",
       "                       -0.0836, -0.1612,  0.0020,  0.1714,  0.0713,  0.2731, -0.2065, -0.2953,\n",
       "                       -0.2221,  0.0470, -0.0539, -0.0691,  0.0345,  0.0052,  0.0155,  0.1809],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.rnn.bias_hh_l0',\n",
       "               tensor([ 0.1955,  0.1857,  0.3263,  0.1496,  0.3007,  0.1851,  0.2180,  0.0894,\n",
       "                        0.1493,  0.0215,  0.1774,  0.0633,  0.0878,  0.2095,  0.0331,  0.1939,\n",
       "                        0.3119,  0.2198,  0.3285,  0.2307,  0.2373,  0.0290,  0.0800,  0.2165,\n",
       "                        0.1225,  0.2157,  0.2658,  0.2563,  0.2350,  0.1615,  0.2920,  0.2463,\n",
       "                        0.1631,  0.2363,  0.0950,  0.2350,  0.1951,  0.1336,  0.1614,  0.2081,\n",
       "                        0.2263,  0.0867,  0.3384,  0.1524,  0.1271,  0.2493,  0.2095,  0.1893,\n",
       "                        0.1896,  0.1206,  0.1292,  0.2220,  0.2453,  0.1591,  0.2738,  0.1329,\n",
       "                        0.2153,  0.1583,  0.0903,  0.1449,  0.0804,  0.0734,  0.0654,  0.2496,\n",
       "                        0.0354, -0.1741, -0.2051, -0.1704, -0.1357, -0.1470, -0.1318, -0.0879,\n",
       "                       -0.1929, -0.1597, -0.0829, -0.2957, -0.0964, -0.1843, -0.1215, -0.0944,\n",
       "                       -0.3516, -0.2365, -0.0708, -0.0650, -0.1125, -0.0842, -0.0602, -0.1279,\n",
       "                       -0.3030, -0.1144, -0.3142, -0.0013, -0.2137, -0.0405, -0.0232, -0.1546,\n",
       "                       -0.0950, -0.1519, -0.2203, -0.1371, -0.2737, -0.0179, -0.1945, -0.1078,\n",
       "                       -0.1482, -0.1200, -0.3115, -0.1433, -0.0381, -0.2500, -0.2292, -0.3282,\n",
       "                       -0.0572, -0.1048,  0.0225, -0.0263, -0.2151, -0.1337, -0.2830, -0.2373,\n",
       "                       -0.2401, -0.1760, -0.2457, -0.1350, -0.2179, -0.1012, -0.2986, -0.0544,\n",
       "                        0.1758,  0.1663,  0.2914,  0.2292,  0.2699,  0.1072,  0.2239,  0.2002,\n",
       "                        0.1934,  0.1774,  0.2071, -0.1163, -0.2286, -0.3136, -0.1460, -0.2587,\n",
       "                       -0.3764,  0.1820,  0.2027,  0.1293,  0.0873,  0.0945,  0.1011,  0.1585,\n",
       "                       -0.1576, -0.2428, -0.2760, -0.0270, -0.2861, -0.1313,  0.0077,  0.0879,\n",
       "                        0.1841, -0.2583, -0.2930, -0.1260, -0.3452, -0.2172,  0.2109, -0.1085,\n",
       "                        0.0914,  0.1199,  0.3548, -0.1164,  0.0514,  0.1981, -0.2404, -0.3250,\n",
       "                       -0.1623, -0.1333,  0.0590,  0.1079,  0.0470,  0.1490, -0.2076, -0.1329,\n",
       "                       -0.0599,  0.0796,  0.0607, -0.1165,  0.2448, -0.1009,  0.1197,  0.2217],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.rnn.weight_ih_l1',\n",
       "               tensor([[ 0.0677, -0.0754,  0.1058,  ..., -0.0703,  0.0722,  0.1214],\n",
       "                       [ 0.1532,  0.0920, -0.0011,  ...,  0.0237,  0.0833, -0.0536],\n",
       "                       [ 0.1309,  0.0640,  0.0227,  ...,  0.0418, -0.0523,  0.0754],\n",
       "                       ...,\n",
       "                       [-0.0874, -0.0903, -0.0864,  ..., -0.0189, -0.1090, -0.1112],\n",
       "                       [-0.1343, -0.0588, -0.0402,  ..., -0.1090,  0.0195,  0.0366],\n",
       "                       [ 0.0248,  0.0627,  0.0362,  ...,  0.0042,  0.0340,  0.0259]],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.rnn.weight_hh_l1',\n",
       "               tensor([[ 0.0968, -0.0274,  0.0421,  ..., -0.0116, -0.0673, -0.0541],\n",
       "                       [ 0.1471,  0.1199, -0.0389,  ..., -0.0271, -0.0477, -0.0343],\n",
       "                       [ 0.0782,  0.1050,  0.0222,  ..., -0.0332, -0.0405, -0.0810],\n",
       "                       ...,\n",
       "                       [-0.1712, -0.0869, -0.1360,  ..., -0.0415, -0.0132, -0.0938],\n",
       "                       [ 0.0396,  0.0347,  0.1272,  ..., -0.0761,  0.0555,  0.1254],\n",
       "                       [ 0.0897,  0.2002,  0.1526,  ..., -0.0576, -0.0453,  0.1401]],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.rnn.bias_ih_l1',\n",
       "               tensor([ 0.1685, -0.0027, -0.0583,  0.0472,  0.0454,  0.1583,  0.1968,  0.1606,\n",
       "                        0.0100,  0.1429,  0.0429,  0.0546, -0.0112,  0.0961,  0.0551,  0.1598,\n",
       "                        0.1353,  0.0761,  0.1601,  0.1074,  0.0739,  0.0303, -0.0062,  0.0113,\n",
       "                        0.0378,  0.0341,  0.0664,  0.1331,  0.1190, -0.0442,  0.1414,  0.0755,\n",
       "                        0.0449, -0.0192, -0.0130,  0.0560,  0.0645, -0.0919,  0.0093,  0.0687,\n",
       "                        0.1071, -0.0159, -0.0187,  0.0506,  0.1002,  0.1213, -0.0926,  0.1655,\n",
       "                        0.0535, -0.1712,  0.0233,  0.0726,  0.0017, -0.0702, -0.0528,  0.1177,\n",
       "                        0.0242, -0.0193,  0.0942,  0.0411,  0.0928,  0.1399, -0.0476,  0.0976,\n",
       "                        0.0091, -0.1104, -0.0540, -0.2057, -0.0832, -0.0614, -0.0473,  0.0072,\n",
       "                       -0.1956, -0.0186, -0.0829, -0.1850, -0.1907, -0.0106, -0.0167,  0.0458,\n",
       "                        0.0805, -0.0863, -0.1345, -0.0169,  0.0238, -0.0755, -0.0105, -0.0404,\n",
       "                        0.0289, -0.0946, -0.0539,  0.0159, -0.1868, -0.0758, -0.1200, -0.1436,\n",
       "                        0.0125, -0.1836, -0.0562, -0.0655, -0.1011, -0.0340, -0.0837, -0.0878,\n",
       "                       -0.1381,  0.0012, -0.0580, -0.0727, -0.0569, -0.0819, -0.0283,  0.0062,\n",
       "                       -0.1141,  0.1121, -0.1735, -0.0782, -0.1787, -0.1134,  0.0318, -0.0003,\n",
       "                       -0.0632, -0.0205, -0.0982, -0.2025, -0.0113, -0.2014, -0.0022, -0.0273,\n",
       "                        0.0206,  0.0769,  0.1695,  0.0699,  0.0232, -0.0532,  0.0510,  0.0882,\n",
       "                        0.1237,  0.1057,  0.1003, -0.0920, -0.0907,  0.0194, -0.0517,  0.0091,\n",
       "                       -0.1480, -0.0115,  0.1156,  0.1594,  0.1042, -0.0612,  0.0149, -0.1021,\n",
       "                        0.0363,  0.0195, -0.0558, -0.1752, -0.0816, -0.1023, -0.0082, -0.0999,\n",
       "                        0.0600, -0.0868,  0.1154, -0.1251,  0.0445, -0.1344, -0.0105,  0.0041,\n",
       "                        0.1347,  0.0584, -0.1582,  0.0368, -0.0477,  0.0465, -0.1489, -0.1586,\n",
       "                       -0.1307, -0.0558, -0.0038,  0.0877, -0.0064,  0.0856, -0.0777, -0.1634,\n",
       "                        0.0259,  0.0455, -0.0023, -0.1289,  0.1425, -0.1069, -0.0463,  0.0302],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.rnn.bias_hh_l1',\n",
       "               tensor([-0.0204,  0.0856,  0.1321,  0.1699,  0.0321, -0.0684,  0.0430, -0.0429,\n",
       "                        0.1682, -0.0828,  0.1288, -0.0876, -0.0835,  0.1347, -0.0662,  0.1660,\n",
       "                       -0.0151, -0.0529,  0.1467,  0.1134,  0.1115, -0.0372,  0.1328, -0.1015,\n",
       "                        0.0230, -0.0535,  0.1240,  0.0871, -0.0611,  0.1074,  0.0791,  0.1145,\n",
       "                        0.0043,  0.1436,  0.0574, -0.0345,  0.0655,  0.0472,  0.0982, -0.0218,\n",
       "                        0.0824,  0.1270, -0.0565,  0.0844,  0.0601, -0.0676, -0.0175,  0.0204,\n",
       "                       -0.0606, -0.0934,  0.0128, -0.0008,  0.0971, -0.0333,  0.0341,  0.0723,\n",
       "                        0.0579,  0.0536, -0.0387,  0.0650,  0.0828,  0.0777,  0.1040, -0.0272,\n",
       "                       -0.1266, -0.0821, -0.0680,  0.0019, -0.2040,  0.0267, -0.0728, -0.1399,\n",
       "                       -0.1554, -0.1109, -0.1019,  0.0539, -0.0776, -0.1452, -0.0385, -0.0983,\n",
       "                       -0.1301, -0.1518, -0.0886, -0.0218, -0.2008, -0.1062,  0.0180, -0.1535,\n",
       "                        0.0292,  0.0174, -0.1146, -0.0899, -0.1380, -0.1233, -0.0970, -0.1568,\n",
       "                        0.0025, -0.1899, -0.1554,  0.0355, -0.1021,  0.0354, -0.1120, -0.1546,\n",
       "                       -0.1780, -0.0372, -0.0628, -0.1819,  0.0346, -0.0010, -0.1687, -0.1630,\n",
       "                       -0.0142,  0.0899, -0.0953, -0.1612, -0.1256, -0.0454,  0.0208, -0.2053,\n",
       "                       -0.0754,  0.0397, -0.0237, -0.1103, -0.0100, -0.1191, -0.1642, -0.0659,\n",
       "                        0.1652,  0.0874,  0.0540,  0.1016,  0.0541,  0.0996,  0.1509,  0.1112,\n",
       "                        0.0532,  0.0209,  0.1021, -0.0856,  0.0283, -0.1660, -0.0619, -0.1320,\n",
       "                       -0.0592,  0.1316,  0.1372,  0.1514,  0.1582,  0.1204,  0.0404, -0.0841,\n",
       "                       -0.1614, -0.1347, -0.0812, -0.0628, -0.1444, -0.1593,  0.0658,  0.0062,\n",
       "                        0.0189, -0.0904,  0.1278, -0.1272, -0.1474, -0.1490,  0.1524,  0.0229,\n",
       "                        0.0352,  0.1727, -0.1043, -0.1264, -0.1024, -0.0495, -0.0179, -0.0598,\n",
       "                       -0.0946,  0.0243, -0.0893,  0.0844,  0.1443,  0.0044, -0.0196, -0.1226,\n",
       "                       -0.0903,  0.1431,  0.0782, -0.0470,  0.0707, -0.1568, -0.0346,  0.0907],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.rnn2mean.weight',\n",
       "               tensor([[ 0.0603, -0.0659,  0.0193,  ..., -0.0587,  0.0316, -0.0519],\n",
       "                       [ 0.0458, -0.0189,  0.0632,  ..., -0.0398, -0.0422,  0.0691],\n",
       "                       [ 0.0230, -0.0735, -0.0391,  ..., -0.0367,  0.0089,  0.0608],\n",
       "                       ...,\n",
       "                       [-0.0372,  0.0123, -0.0448,  ...,  0.0852,  0.0573, -0.0420],\n",
       "                       [ 0.0882, -0.0737,  0.0708,  ..., -0.0600, -0.0427, -0.0707],\n",
       "                       [-0.0352, -0.0559,  0.0719,  ...,  0.0627, -0.0139,  0.0129]],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.rnn2mean.bias',\n",
       "               tensor([-0.0643, -0.0232,  0.0612,  0.0769, -0.0154, -0.0279,  0.0776,  0.0680,\n",
       "                       -0.0079, -0.0039, -0.0662, -0.0721,  0.0043, -0.0685,  0.0267,  0.0553,\n",
       "                       -0.0389, -0.0487, -0.0667, -0.0043, -0.0302,  0.0669,  0.0423,  0.0534,\n",
       "                        0.0529,  0.0058, -0.0239, -0.0204, -0.0522, -0.0361, -0.0673,  0.0387,\n",
       "                       -0.0596,  0.0002,  0.0596, -0.0069,  0.0572,  0.0065, -0.0184,  0.0157,\n",
       "                        0.0693,  0.0266, -0.0514, -0.0312, -0.0239, -0.0345, -0.0148, -0.0788,\n",
       "                        0.0613, -0.0580,  0.0303,  0.0084,  0.0309, -0.0549, -0.0430, -0.0567,\n",
       "                        0.0332,  0.0435,  0.0198,  0.0254,  0.0347,  0.0244, -0.0305,  0.0172,\n",
       "                       -0.0054,  0.0384,  0.0455,  0.0159, -0.0208,  0.0621,  0.0606, -0.0104,\n",
       "                        0.0623, -0.0355,  0.0509, -0.0006, -0.0111, -0.0232,  0.0718, -0.0100,\n",
       "                       -0.0518, -0.0436, -0.0266,  0.0387,  0.0589,  0.0252, -0.0134, -0.0164,\n",
       "                       -0.0140, -0.0826, -0.0129,  0.0704,  0.0021, -0.0476, -0.0666, -0.0044,\n",
       "                       -0.0317, -0.0543, -0.0319,  0.0645], device='cuda:0')),\n",
       "              ('encoder.rnn2logv.weight',\n",
       "               tensor([[-0.1561, -0.2469, -0.1333,  ...,  0.2548, -0.2625, -0.2562],\n",
       "                       [-0.1199, -0.2553, -0.2673,  ...,  0.2237, -0.2048, -0.2692],\n",
       "                       [-0.1658, -0.2379, -0.2086,  ...,  0.2259, -0.2392, -0.2867],\n",
       "                       ...,\n",
       "                       [-0.1740, -0.2200, -0.2533,  ...,  0.1487, -0.1734, -0.2279],\n",
       "                       [-0.2250, -0.1902, -0.2868,  ...,  0.2361, -0.1594, -0.1789],\n",
       "                       [-0.1835, -0.1274, -0.1206,  ...,  0.2023, -0.1546, -0.2527]],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.rnn2logv.bias',\n",
       "               tensor([-0.1350, -0.1631, -0.1098, -0.1955, -0.2336, -0.2495, -0.1252, -0.0971,\n",
       "                       -0.2251, -0.1055, -0.1487, -0.2503, -0.2527, -0.1363, -0.1626, -0.2129,\n",
       "                       -0.2294, -0.0878, -0.2333, -0.0822, -0.1794, -0.1771, -0.2433, -0.2342,\n",
       "                       -0.2467, -0.1856, -0.1513, -0.1147, -0.1991, -0.2635, -0.1227, -0.2269,\n",
       "                       -0.1480, -0.1005, -0.1572, -0.1362, -0.1911, -0.1862, -0.1724, -0.2438,\n",
       "                       -0.1960, -0.0927, -0.1303, -0.1045, -0.2138, -0.1972, -0.1546, -0.1963,\n",
       "                       -0.1835, -0.2031, -0.2026, -0.2495, -0.1457, -0.1909, -0.1018, -0.1926,\n",
       "                       -0.1187, -0.1714, -0.2301, -0.1643, -0.2173, -0.1447, -0.1218, -0.2528,\n",
       "                       -0.1948, -0.2098, -0.1231, -0.1702, -0.1792, -0.2427, -0.0823, -0.2433,\n",
       "                       -0.2038, -0.1710, -0.1369, -0.2392, -0.1249, -0.1781, -0.1349, -0.1197,\n",
       "                       -0.1468, -0.2482, -0.2108, -0.1376, -0.0976, -0.0981, -0.2317, -0.2637,\n",
       "                       -0.1875, -0.1086, -0.1581, -0.1130, -0.1046, -0.1748, -0.1594, -0.1232,\n",
       "                       -0.0823, -0.2178, -0.1100, -0.1097], device='cuda:0')),\n",
       "              ('decoder.rnn.weight_ih_l0',\n",
       "               tensor([[-0.0280, -0.0590,  0.0540,  ...,  0.0646, -0.0989,  0.1803],\n",
       "                       [-0.0543,  0.0755, -0.1558,  ...,  0.1745, -0.0657,  0.1019],\n",
       "                       [-0.0772, -0.1673,  0.1268,  ..., -0.0401,  0.0754,  0.0030],\n",
       "                       ...,\n",
       "                       [ 0.0029, -0.0516, -0.0163,  ...,  0.2207,  0.2198,  0.0791],\n",
       "                       [ 0.1034, -0.0557,  0.1629,  ..., -0.1945, -0.0074,  0.0308],\n",
       "                       [ 0.1925, -0.2442,  0.1378,  ..., -0.2354, -0.1904,  0.0032]],\n",
       "                      device='cuda:0')),\n",
       "              ('decoder.rnn.weight_hh_l0',\n",
       "               tensor([[-0.1211,  0.1600, -0.0250,  ...,  0.0352, -0.1574, -0.0513],\n",
       "                       [ 0.1066, -0.0478,  0.1183,  ...,  0.0368, -0.0784, -0.0609],\n",
       "                       [ 0.0887, -0.1646,  0.1251,  ...,  0.0135, -0.0206, -0.1940],\n",
       "                       ...,\n",
       "                       [ 0.0203,  0.0091, -0.0101,  ..., -0.0234, -0.1031,  0.0392],\n",
       "                       [ 0.2375, -0.1404, -0.1086,  ..., -0.2453, -0.0033,  0.0886],\n",
       "                       [ 0.0416,  0.1947, -0.1971,  ..., -0.1145, -0.0590,  0.0043]],\n",
       "                      device='cuda:0')),\n",
       "              ('decoder.rnn.bias_ih_l0',\n",
       "               tensor([-0.0741,  0.1182,  0.1378,  0.0746,  0.0720,  0.1040, -0.0039,  0.1177,\n",
       "                        0.0448,  0.1438,  0.1448,  0.2125,  0.1609,  0.1355,  0.0569,  0.0726,\n",
       "                        0.1575,  0.0462,  0.0835,  0.1898,  0.1467,  0.2123,  0.1276,  0.1957,\n",
       "                        0.0959,  0.0640,  0.0571,  0.1099,  0.0546,  0.0141,  0.2245,  0.1956,\n",
       "                       -0.0058,  0.2984,  0.1413,  0.0936,  0.1615,  0.0765,  0.2188, -0.1111,\n",
       "                        0.1826,  0.2485,  0.1715,  0.2051,  0.1235, -0.0014, -0.0536,  0.2192,\n",
       "                        0.1416,  0.0509,  0.0716,  0.2524,  0.1049,  0.0627, -0.1503, -0.0420,\n",
       "                        0.0046,  0.0983,  0.1880,  0.3051,  0.2497,  0.2165,  0.1660,  0.1597,\n",
       "                        0.0816, -0.0079, -0.2039, -0.3021, -0.2450, -0.1316, -0.3222, -0.1697,\n",
       "                       -0.2281, -0.1399, -0.3544, -0.1676,  0.0384, -0.1420, -0.0377, -0.2507,\n",
       "                       -0.1802, -0.2203, -0.0710, -0.1350, -0.1764, -0.2738, -0.5081, -0.2607,\n",
       "                       -0.1789, -0.1306, -0.0543, -0.1616, -0.2196, -0.4262, -0.0582,  0.0474,\n",
       "                       -0.1135, -0.3284, -0.1310,  0.0493, -0.0595, -0.1009, -0.0488, -0.2457,\n",
       "                       -0.2201, -0.0355, -0.0772, -0.3069, -0.1736, -0.3470, -0.1931, -0.2273,\n",
       "                       -0.1018, -0.2411, -0.3104, -0.1888, -0.3371, -0.1579,  0.0205, -0.2896,\n",
       "                       -0.2126, -0.3048,  0.0676, -0.1678, -0.2420, -0.2631, -0.1372, -0.1991,\n",
       "                        0.0872, -0.0623,  0.0288, -0.1025, -0.0885,  0.0672,  0.1960, -0.1639,\n",
       "                       -0.1045, -0.0469, -0.0900,  0.1833,  0.0772,  0.1282, -0.0572,  0.1320,\n",
       "                        0.1007,  0.0268,  0.2274,  0.1149,  0.1555, -0.1572,  0.2364, -0.0282,\n",
       "                       -0.2031,  0.0584,  0.0435,  0.1096, -0.1940,  0.1029, -0.2067,  0.0384,\n",
       "                       -0.0978,  0.2223, -0.0970,  0.1000,  0.0134,  0.0674, -0.2463, -0.1934,\n",
       "                        0.2002,  0.0938,  0.1460, -0.1938,  0.0252,  0.2006,  0.1313,  0.1907,\n",
       "                        0.0702, -0.2353, -0.0476, -0.1460, -0.1674,  0.2457, -0.1210, -0.0111,\n",
       "                        0.1042,  0.1770, -0.1041, -0.2407,  0.1950,  0.2242, -0.0092, -0.1766],\n",
       "                      device='cuda:0')),\n",
       "              ('decoder.rnn.bias_hh_l0',\n",
       "               tensor([-0.0057,  0.2100,  0.2524,  0.1299,  0.2617,  0.1733,  0.0689,  0.1563,\n",
       "                       -0.0062,  0.1459,  0.0850,  0.0888,  0.0169,  0.1437,  0.1907,  0.0153,\n",
       "                        0.2037, -0.0253,  0.2706,  0.1540,  0.1915,  0.1074,  0.0753,  0.0262,\n",
       "                        0.2031,  0.2177,  0.2192,  0.2103,  0.1115,  0.0146,  0.1103,  0.1239,\n",
       "                        0.1184,  0.2955,  0.1361, -0.0582,  0.2902,  0.1257,  0.2109,  0.1260,\n",
       "                        0.1355,  0.1060,  0.3272,  0.1754,  0.0511,  0.1443,  0.0288,  0.1246,\n",
       "                       -0.0332,  0.0716,  0.1732,  0.1599,  0.3220,  0.0204, -0.1245,  0.1136,\n",
       "                        0.2104,  0.2439,  0.0551,  0.1460,  0.0436,  0.1751,  0.0765,  0.0222,\n",
       "                       -0.1412, -0.0706, -0.3368, -0.2058, -0.2521, -0.0625, -0.2738, -0.2251,\n",
       "                       -0.1600, -0.1176, -0.1363, -0.3410, -0.0447, -0.1045, -0.0663, -0.3927,\n",
       "                       -0.2257, -0.1756, -0.2537, -0.1070, -0.2511, -0.1617, -0.3145, -0.1818,\n",
       "                       -0.3059,  0.0268, -0.1625, -0.0911, -0.1157, -0.2185, -0.0019, -0.0813,\n",
       "                       -0.2090, -0.1088, -0.1857, -0.0225, -0.0391,  0.0080, -0.2231, -0.1392,\n",
       "                       -0.2698, -0.0492, -0.1095, -0.2198, -0.1707, -0.2482, -0.1569, -0.2820,\n",
       "                       -0.0454, -0.3549, -0.2436, -0.1344, -0.3184, -0.3070, -0.1088, -0.2548,\n",
       "                       -0.0444, -0.2656, -0.1088, -0.3356, -0.1889, -0.1996, -0.1060, -0.2723,\n",
       "                       -0.0149, -0.1147,  0.2945, -0.1431, -0.0959,  0.1471,  0.1591,  0.0044,\n",
       "                       -0.1741, -0.1671, -0.2302,  0.2247, -0.0674,  0.1971, -0.0290,  0.0364,\n",
       "                        0.2484,  0.0300,  0.2710,  0.1277,  0.1005, -0.0631,  0.0461, -0.1800,\n",
       "                       -0.1209,  0.1377, -0.1227,  0.0460, -0.1763,  0.1695, -0.1830, -0.0617,\n",
       "                       -0.1416,  0.1281, -0.0339,  0.1709,  0.0434,  0.0117, -0.1966, -0.0401,\n",
       "                        0.0716, -0.0115, -0.0354, -0.2308,  0.1016,  0.1262, -0.0880,  0.2349,\n",
       "                        0.0252, -0.1073, -0.1200, -0.0304, -0.0692,  0.0371, -0.0207,  0.2247,\n",
       "                        0.2338,  0.1657, -0.0134, -0.1165,  0.0699,  0.2612,  0.0326, -0.2585],\n",
       "                      device='cuda:0')),\n",
       "              ('decoder.rnn.weight_ih_l1',\n",
       "               tensor([[-0.0128, -0.0155,  0.0063,  ...,  0.0707,  0.0135,  0.0266],\n",
       "                       [-0.0041,  0.0138, -0.0913,  ...,  0.0411, -0.0050, -0.2309],\n",
       "                       [ 0.0008, -0.0557,  0.0462,  ...,  0.0125, -0.0064,  0.1165],\n",
       "                       ...,\n",
       "                       [ 0.0162,  0.0837, -0.0592,  ...,  0.1384, -0.2839, -0.0930],\n",
       "                       [-0.1520, -0.0806, -0.0063,  ..., -0.3358,  0.2778,  0.3927],\n",
       "                       [-0.0765,  0.0912, -0.0048,  ..., -0.0760, -0.1318,  0.0347]],\n",
       "                      device='cuda:0')),\n",
       "              ('decoder.rnn.weight_hh_l1',\n",
       "               tensor([[-0.0917,  0.0900, -0.1233,  ..., -0.0689, -0.0013, -0.0372],\n",
       "                       [ 0.0215,  0.0778,  0.0301,  ..., -0.0495,  0.0604, -0.0342],\n",
       "                       [-0.0564, -0.1045, -0.1532,  ...,  0.0744,  0.0789,  0.1566],\n",
       "                       ...,\n",
       "                       [-0.1245, -0.1144,  0.0989,  ...,  0.0291, -0.2325,  0.0068],\n",
       "                       [-0.0290,  0.0695, -0.1510,  ..., -0.1293, -0.0692, -0.0994],\n",
       "                       [-0.0430,  0.0153, -0.0699,  ..., -0.0228, -0.0320, -0.0191]],\n",
       "                      device='cuda:0')),\n",
       "              ('decoder.rnn.bias_ih_l1',\n",
       "               tensor([ 0.1727, -0.0397,  0.1746,  0.0093,  0.1567,  0.0865,  0.0938,  0.1821,\n",
       "                        0.2204,  0.2227,  0.4333,  0.0963,  0.0778,  0.1965,  0.0346,  0.1371,\n",
       "                        0.1869,  0.1626,  0.3244,  0.1805, -0.0184,  0.0341,  0.1080,  0.0546,\n",
       "                        0.0366,  0.0999,  0.2321,  0.0610,  0.0310,  0.1266, -0.0072,  0.1264,\n",
       "                        0.2830,  0.2646,  0.1827,  0.0243, -0.0345,  0.3706,  0.1431,  0.0268,\n",
       "                        0.0021,  0.1234,  0.1120,  0.2125,  0.1117,  0.0697,  0.0661,  0.1114,\n",
       "                        0.0652, -0.0712,  0.1127,  0.1617, -0.0212, -0.0134,  0.0628,  0.2779,\n",
       "                        0.2057,  0.1230,  0.2409,  0.2547,  0.0800,  0.1998,  0.1432,  0.1670,\n",
       "                       -0.0685, -0.4085, -0.2413, -0.2280, -0.2499, -0.2394, -0.2011, -0.3811,\n",
       "                       -0.4337, -0.0769, -0.2302, -0.2397, -0.1926, -0.2094, -0.2972, -0.2555,\n",
       "                       -0.4055, -0.4760, -0.4684, -0.2266, -0.1791, -0.2562, -0.0928, -0.1401,\n",
       "                       -0.2987, -0.1163, -0.1833, -0.2063, -0.4118, -0.3786, -0.0069, -0.3168,\n",
       "                       -0.4381, -0.2897, -0.2543, -0.2735, -0.2499, -0.1432, -0.3110, -0.1866,\n",
       "                       -0.3281, -0.3473, -0.1142, -0.2743, -0.3786, -0.1324, -0.0158, -0.1770,\n",
       "                       -0.1380, -0.1761, -0.1387, -0.2776, -0.1817, -0.1707, -0.0584, -0.3925,\n",
       "                       -0.1068, -0.1375, -0.1669, -0.4036, -0.2502, -0.0035, -0.2563, -0.2243,\n",
       "                        0.0025, -0.1780,  0.0860,  0.0311,  0.1823,  0.1150, -0.1169, -0.1450,\n",
       "                        0.2750, -0.1399,  0.0092,  0.0339,  0.1648,  0.0033, -0.0374, -0.1955,\n",
       "                       -0.0305, -0.2946, -0.1980, -0.2508,  0.1581, -0.1218,  0.1009, -0.2029,\n",
       "                        0.1474,  0.0237, -0.0078,  0.0215,  0.1398, -0.1028,  0.0656,  0.1479,\n",
       "                       -0.0830, -0.1339, -0.1007,  0.3032, -0.2378, -0.1359, -0.3284,  0.1570,\n",
       "                       -0.1304,  0.0080,  0.1980, -0.0911,  0.0778, -0.1163,  0.0018,  0.0339,\n",
       "                       -0.0456,  0.0054, -0.0009, -0.1803,  0.1773, -0.0575, -0.0006, -0.1541,\n",
       "                        0.1420,  0.0413,  0.0389, -0.1763,  0.2720,  0.0538, -0.0021, -0.1723],\n",
       "                      device='cuda:0')),\n",
       "              ('decoder.rnn.bias_hh_l1',\n",
       "               tensor([ 7.4786e-02,  1.2765e-01,  2.5892e-02,  3.6145e-02,  1.3386e-01,\n",
       "                        1.0931e-01,  1.6008e-01,  2.3471e-01,  1.3226e-01,  1.1071e-01,\n",
       "                        3.7953e-01,  6.1825e-02,  7.1455e-03,  5.4352e-02,  3.6482e-02,\n",
       "                        1.0713e-01,  2.0692e-01,  2.0808e-01,  2.8300e-01,  1.1133e-01,\n",
       "                        1.4758e-01,  3.0681e-02,  2.2427e-01,  4.7234e-02,  1.5298e-01,\n",
       "                        2.2758e-01,  1.1908e-01,  1.1288e-01,  5.4020e-02,  8.8393e-02,\n",
       "                        7.8512e-02,  2.4286e-01,  3.0513e-01,  1.3617e-01,  1.4928e-01,\n",
       "                        1.1143e-01, -1.7903e-02,  4.2730e-01,  1.1558e-01,  6.2894e-02,\n",
       "                        1.2245e-01,  2.7301e-02,  2.3687e-01,  1.5867e-01,  1.1446e-01,\n",
       "                        2.5603e-02,  1.4078e-01,  1.0598e-01,  1.4843e-01,  3.9164e-02,\n",
       "                        1.4834e-01,  2.8164e-01,  4.2144e-02,  1.2384e-01,  1.6805e-01,\n",
       "                        2.7811e-01,  2.1793e-01,  1.4557e-01,  1.9529e-01,  1.1298e-01,\n",
       "                        1.4706e-01,  4.4403e-02,  1.7091e-01,  1.3027e-01, -1.2459e-01,\n",
       "                       -3.8329e-01, -2.6466e-01, -1.3143e-01, -2.1697e-01, -1.7610e-01,\n",
       "                       -2.3879e-01, -2.6781e-01, -4.7411e-01, -1.0694e-01, -3.5213e-01,\n",
       "                       -2.0581e-01, -3.1956e-01, -3.1670e-01, -2.3140e-01, -1.8606e-01,\n",
       "                       -2.8397e-01, -5.0767e-01, -4.2856e-01, -2.1322e-01, -3.0092e-01,\n",
       "                       -2.4234e-01, -1.2951e-01, -1.1351e-01, -1.5446e-01, -2.0130e-02,\n",
       "                       -6.8765e-02, -2.8353e-01, -3.3633e-01, -4.0269e-01,  4.3930e-03,\n",
       "                       -1.6334e-01, -4.2821e-01, -2.9516e-01, -3.5943e-01, -7.5272e-02,\n",
       "                       -3.3512e-01, -3.4386e-01, -4.1016e-01, -1.6741e-01, -2.5539e-01,\n",
       "                       -3.1195e-01, -9.5671e-02, -1.6978e-01, -2.4014e-01, -1.3278e-01,\n",
       "                       -1.1989e-01, -1.4562e-01, -3.4650e-01, -2.0486e-01, -1.6581e-01,\n",
       "                       -3.6583e-01, -1.5701e-01, -1.4537e-01, -1.7028e-01, -4.1562e-01,\n",
       "                        3.2147e-02,  3.5591e-02, -1.6032e-01, -3.2161e-01, -3.0830e-01,\n",
       "                       -2.7183e-02, -1.7636e-01, -3.0963e-01,  1.5223e-01, -2.7373e-01,\n",
       "                        1.2704e-01, -2.5044e-03,  2.2736e-01,  7.2029e-02,  1.8741e-02,\n",
       "                       -2.3378e-01,  2.4559e-01, -1.2934e-01, -7.4739e-02,  1.5450e-02,\n",
       "                       -6.7370e-03,  1.5128e-02,  3.2686e-02, -2.3145e-01,  8.9532e-02,\n",
       "                       -1.5687e-01, -6.4103e-02, -1.2364e-01,  3.5883e-02, -1.5175e-01,\n",
       "                        2.0840e-01, -2.0920e-01,  1.0465e-01,  3.5499e-03, -6.2389e-02,\n",
       "                        4.5379e-02,  2.5017e-01, -2.5003e-01,  3.2325e-02,  7.2323e-02,\n",
       "                        8.2718e-03, -2.4307e-01,  6.9759e-02,  6.8718e-03,  5.4091e-02,\n",
       "                       -1.0388e-02, -8.7229e-02, -1.8146e-04, -7.9951e-02,  2.1277e-01,\n",
       "                        5.3388e-02, -2.1717e-01, -9.7847e-02, -8.1781e-02,  4.4464e-02,\n",
       "                       -7.8536e-02,  1.0423e-01, -5.3128e-02, -9.0375e-03,  5.2129e-02,\n",
       "                        5.8794e-02,  4.4657e-02,  8.5561e-02, -2.0627e-01,  5.9728e-02,\n",
       "                        1.9253e-01,  8.0254e-03, -5.9460e-02, -1.1258e-02, -1.6147e-02,\n",
       "                       -1.9592e-01, -2.0975e-01], device='cuda:0')),\n",
       "              ('decoder.rnn2out.weight',\n",
       "               tensor([[-0.0619, -0.0789,  0.0189,  ..., -0.0066,  0.0705, -0.0911],\n",
       "                       [ 0.0766, -0.0645,  0.0066,  ...,  0.0278, -0.0815,  0.0776],\n",
       "                       [-0.4532,  0.4179, -0.1222,  ...,  1.2021, -0.4428,  0.3751],\n",
       "                       ...,\n",
       "                       [-0.0238,  0.0159, -0.0705,  ..., -0.0793,  0.0891, -0.0053],\n",
       "                       [-0.0111, -0.0885,  0.0369,  ...,  0.1122,  0.0485,  0.0737],\n",
       "                       [ 0.1009, -0.0880,  0.0366,  ...,  0.0258, -0.1218, -0.0282]],\n",
       "                      device='cuda:0')),\n",
       "              ('decoder.rnn2out.bias',\n",
       "               tensor([-0.0456,  0.0934, -0.3990,  ...,  0.0757,  0.0081,  0.1000],\n",
       "                      device='cuda:0'))]),\n",
       " 'optimizer': {'state': {1: {'step': 306693,\n",
       "    'exp_avg': tensor([[-1.7883e-08, -1.5104e-07, -5.2827e-08,  ..., -1.4478e-07,\n",
       "             -1.3780e-07,  2.1960e-08],\n",
       "            [ 2.1861e-08,  1.4007e-07,  4.5951e-08,  ...,  1.3275e-07,\n",
       "              1.3364e-07, -1.8940e-08],\n",
       "            [-2.5170e-08, -1.5866e-07, -1.4190e-08,  ..., -1.4200e-07,\n",
       "             -1.4487e-07,  1.2921e-08],\n",
       "            ...,\n",
       "            [ 8.1639e-09, -5.2339e-09,  5.0337e-08,  ...,  9.6227e-09,\n",
       "              1.4596e-08, -1.0294e-08],\n",
       "            [-8.3061e-09,  2.4535e-08, -3.5052e-08,  ...,  2.0689e-08,\n",
       "              3.1112e-09,  5.4563e-09],\n",
       "            [ 2.3357e-08,  6.1391e-08,  4.0630e-08,  ...,  7.0717e-08,\n",
       "              7.9610e-08, -1.0419e-08]], device='cuda:0'),\n",
       "    'exp_avg_sq': tensor([[9.3716e-16, 4.7123e-15, 2.1617e-15,  ..., 3.4984e-15, 3.1611e-15,\n",
       "             1.6705e-16],\n",
       "            [4.9466e-16, 3.5431e-15, 1.5808e-15,  ..., 2.2744e-15, 2.6203e-15,\n",
       "             1.2508e-16],\n",
       "            [2.2681e-15, 7.1388e-15, 5.9274e-15,  ..., 3.6020e-15, 5.5972e-15,\n",
       "             3.6338e-16],\n",
       "            ...,\n",
       "            [2.5590e-15, 5.8867e-15, 6.7020e-15,  ..., 2.9987e-15, 4.0990e-15,\n",
       "             4.0476e-16],\n",
       "            [2.6408e-15, 6.7589e-15, 7.9634e-15,  ..., 3.0024e-15, 4.2801e-15,\n",
       "             4.2262e-16],\n",
       "            [1.6560e-15, 4.3776e-15, 4.4578e-15,  ..., 1.9414e-15, 3.0694e-15,\n",
       "             2.7309e-16]], device='cuda:0')},\n",
       "   2: {'step': 306693,\n",
       "    'exp_avg': tensor([-6.7893e-05, -4.1921e-05,  1.0355e-04, -1.9598e-04, -7.0139e-05,\n",
       "            -3.8589e-05,  3.2900e-05, -8.1606e-05, -1.9937e-04, -8.2186e-05,\n",
       "             7.5622e-06, -4.7128e-05,  2.2954e-04,  6.3571e-05, -1.3640e-04,\n",
       "            -6.6109e-05,  1.3126e-04, -7.5853e-06,  7.3358e-06, -2.1403e-05,\n",
       "            -4.6891e-07,  3.7498e-05,  5.7183e-06,  3.1633e-04,  2.2314e-05,\n",
       "             1.1137e-04,  1.3765e-04,  2.0208e-04, -7.3382e-05, -8.9771e-05,\n",
       "            -8.0159e-05, -9.3722e-05, -1.1479e-04,  8.2415e-05, -2.5945e-05,\n",
       "             2.1949e-04, -7.6004e-05,  1.2259e-04, -1.5484e-04, -6.2139e-05,\n",
       "             1.4724e-05, -7.1616e-06,  6.9640e-05, -6.2586e-05,  1.2173e-04,\n",
       "             1.1268e-04,  3.9455e-04,  9.6496e-06, -1.3604e-05, -7.3823e-05,\n",
       "             8.9981e-05,  3.2352e-05,  7.7208e-05,  7.9075e-05,  7.9624e-05,\n",
       "             1.0750e-05,  1.0292e-04, -5.0610e-04,  2.8926e-05, -5.8498e-05,\n",
       "             8.6127e-05,  1.5180e-05, -5.4831e-05, -1.6955e-04], device='cuda:0'),\n",
       "    'exp_avg_sq': tensor([7.1559e-08, 5.2927e-08, 1.8582e-07, 1.4789e-07, 7.7618e-08, 1.9842e-08,\n",
       "            6.9368e-08, 6.7087e-08, 6.0764e-07, 6.5090e-08, 1.6240e-07, 7.1488e-08,\n",
       "            3.1831e-07, 8.6100e-08, 2.7436e-07, 5.9778e-08, 1.5935e-07, 2.6791e-08,\n",
       "            1.2889e-07, 4.5109e-08, 9.0479e-08, 4.6515e-08, 5.1732e-08, 2.6834e-06,\n",
       "            9.3072e-08, 1.1898e-07, 6.3126e-08, 1.9312e-07, 5.1199e-08, 9.4520e-08,\n",
       "            1.5575e-06, 6.6315e-08, 1.3477e-07, 5.5859e-08, 5.7721e-08, 2.7050e-07,\n",
       "            9.0109e-08, 2.2479e-07, 1.2722e-07, 7.7984e-08, 1.0511e-07, 5.2116e-08,\n",
       "            2.7954e-08, 1.3686e-07, 1.9494e-07, 9.2120e-08, 2.7851e-06, 4.6450e-08,\n",
       "            3.5248e-08, 9.1222e-08, 8.0996e-08, 1.8470e-08, 3.2031e-08, 2.5615e-07,\n",
       "            9.2644e-08, 9.6880e-08, 1.8803e-07, 5.8763e-06, 1.8762e-07, 1.7124e-07,\n",
       "            9.6412e-08, 2.4280e-07, 2.3323e-07, 1.6207e-07], device='cuda:0')},\n",
       "   3: {'step': 306693,\n",
       "    'exp_avg': tensor([[-1.5039e-07,  1.8016e-07, -8.3691e-08,  ..., -2.4039e-07,\n",
       "             -4.6965e-08, -1.2669e-07],\n",
       "            [ 8.6318e-09,  2.8759e-09, -9.9463e-09,  ..., -5.9814e-09,\n",
       "              4.1788e-09, -7.1129e-09],\n",
       "            [-2.1904e-09,  1.0108e-10, -1.0662e-09,  ..., -2.8005e-10,\n",
       "              1.5343e-10, -1.1328e-10],\n",
       "            ...,\n",
       "            [ 2.2070e-07, -2.7136e-08,  1.5932e-07,  ...,  1.0560e-07,\n",
       "             -7.9997e-08, -1.5840e-07],\n",
       "            [-5.6787e-08,  1.4549e-08, -6.9205e-08,  ..., -1.9892e-08,\n",
       "              5.1283e-08,  2.2805e-08],\n",
       "            [-7.3653e-08,  3.2791e-08, -1.3679e-08,  ..., -3.2311e-08,\n",
       "              6.0904e-08,  6.1169e-09]], device='cuda:0'),\n",
       "    'exp_avg_sq': tensor([[5.2994e-14, 1.1040e-13, 2.3263e-13,  ..., 1.7676e-13, 8.3845e-14,\n",
       "             8.6559e-14],\n",
       "            [4.0012e-17, 8.0782e-17, 1.2483e-16,  ..., 7.0420e-17, 5.5103e-17,\n",
       "             7.1086e-17],\n",
       "            [1.3029e-17, 2.0348e-18, 3.4780e-17,  ..., 6.5512e-18, 3.0049e-17,\n",
       "             4.1570e-17],\n",
       "            ...,\n",
       "            [1.5309e-14, 9.3284e-15, 1.2169e-14,  ..., 1.2686e-14, 1.8717e-14,\n",
       "             2.6921e-14],\n",
       "            [4.6611e-15, 2.5069e-16, 1.2699e-14,  ..., 1.1953e-15, 1.0875e-14,\n",
       "             1.4805e-14],\n",
       "            [1.1918e-14, 6.7334e-15, 1.3183e-14,  ..., 6.1476e-15, 2.3226e-14,\n",
       "             1.8081e-14]], device='cuda:0')},\n",
       "   4: {'step': 306693,\n",
       "    'exp_avg': tensor([[-1.2083e-09, -2.2440e-09, -6.9630e-09,  ...,  1.9701e-09,\n",
       "             -9.7890e-10, -2.2087e-09],\n",
       "            [ 4.2483e-10,  1.4376e-09,  2.5372e-09,  ..., -1.7638e-10,\n",
       "              3.8771e-10,  1.1869e-09],\n",
       "            [-2.2844e-10, -6.3812e-10, -1.2878e-09,  ...,  1.5218e-10,\n",
       "             -2.0148e-10, -5.4149e-10],\n",
       "            ...,\n",
       "            [-9.5207e-10, -4.8968e-09, -6.7554e-09,  ..., -8.8090e-11,\n",
       "             -1.7601e-09, -3.4502e-09],\n",
       "            [-3.9575e-10, -8.4571e-10, -2.0145e-09,  ...,  3.9967e-10,\n",
       "             -4.1305e-10, -7.8921e-10],\n",
       "            [ 2.1586e-09,  7.3183e-09,  1.2430e-08,  ..., -7.1759e-10,\n",
       "              2.0761e-09,  5.5112e-09]], device='cuda:0'),\n",
       "    'exp_avg_sq': tensor([[2.0260e-15, 1.8781e-14, 6.2872e-14,  ..., 6.7189e-16, 2.0938e-15,\n",
       "             1.2390e-14],\n",
       "            [2.5548e-18, 2.4195e-17, 8.3423e-17,  ..., 7.0681e-19, 2.3534e-18,\n",
       "             1.5884e-17],\n",
       "            [3.1223e-19, 2.9174e-18, 1.0178e-17,  ..., 9.0373e-20, 2.7347e-19,\n",
       "             1.9263e-18],\n",
       "            ...,\n",
       "            [2.5652e-16, 2.4350e-15, 8.3743e-15,  ..., 7.2223e-17, 2.3433e-16,\n",
       "             1.5949e-15],\n",
       "            [1.1313e-17, 1.0866e-16, 3.8160e-16,  ..., 2.9307e-18, 9.6872e-18,\n",
       "             7.1220e-17],\n",
       "            [1.2810e-16, 1.2051e-15, 4.1382e-15,  ..., 3.7255e-17, 1.1562e-16,\n",
       "             7.8894e-16]], device='cuda:0')},\n",
       "   5: {'step': 306693,\n",
       "    'exp_avg': tensor([ 5.2634e-08,  8.3800e-08,  9.7649e-09,  4.1831e-08,  6.9695e-08,\n",
       "             6.6115e-08,  9.1127e-08,  7.5645e-08,  4.4019e-08,  1.3073e-07,\n",
       "             7.7323e-08,  4.1449e-08,  1.1987e-07,  1.2157e-07,  1.2002e-07,\n",
       "             1.6939e-07,  1.0022e-07,  6.7109e-08, -2.9542e-08,  1.2507e-07,\n",
       "             4.6946e-08,  1.7292e-07,  5.9208e-08,  2.2387e-07,  3.0688e-08,\n",
       "             1.5670e-07,  1.0143e-07,  1.0410e-08,  1.3906e-07,  5.7789e-08,\n",
       "             1.7264e-08,  1.4862e-08, -2.3829e-10,  7.7158e-08,  1.0834e-07,\n",
       "             1.3630e-07,  5.8541e-08,  1.9789e-07,  2.2324e-08,  7.7378e-08,\n",
       "             6.7223e-08,  1.2800e-07,  8.0042e-07,  2.0115e-08,  2.1137e-09,\n",
       "             7.7600e-08,  1.1387e-07,  1.1277e-07,  1.7997e-07,  1.3563e-07,\n",
       "            -8.5771e-09,  4.8707e-08,  1.5284e-08,  4.1506e-08,  9.4258e-08,\n",
       "             9.1125e-08,  6.3850e-08,  3.3946e-09,  1.7041e-08,  2.9925e-07,\n",
       "             3.6081e-08,  1.5114e-07,  4.1028e-08,  7.6560e-08, -9.6166e-07,\n",
       "            -3.9498e-07,  1.2405e-07, -3.3058e-07, -3.6440e-07, -2.7783e-07,\n",
       "            -8.5077e-07, -2.0074e-06,  9.7432e-07, -1.5153e-07,  2.0918e-07,\n",
       "            -2.1907e-07, -9.8074e-07, -2.5991e-07, -2.3780e-07, -2.2821e-06,\n",
       "            -3.4596e-07, -3.5550e-07,  7.8546e-07,  4.7108e-07, -2.2014e-07,\n",
       "            -4.7122e-07, -6.0304e-07, -6.6422e-07, -1.6110e-07, -3.7093e-07,\n",
       "            -2.6771e-07, -4.9240e-07, -5.6030e-07,  5.8549e-07, -3.1259e-07,\n",
       "            -5.9365e-08,  1.0293e-06, -2.9755e-07, -1.8976e-07, -5.1046e-07,\n",
       "             6.2624e-08, -1.0861e-06,  4.9904e-08, -2.8309e-07, -3.3108e-07,\n",
       "            -1.9109e-06, -2.9600e-05,  3.8400e-07,  3.7579e-09, -3.4299e-07,\n",
       "            -3.3609e-07, -8.1985e-07, -3.1660e-07, -3.9667e-07, -5.1894e-07,\n",
       "            -2.8486e-07,  1.7380e-07, -3.0671e-07, -3.3255e-07, -7.7556e-07,\n",
       "            -6.5909e-07,  1.9231e-07, -5.1129e-08, -4.6771e-07, -8.8446e-09,\n",
       "            -5.9894e-07, -8.0719e-08, -2.3457e-07,  1.7799e-06,  2.0313e-06,\n",
       "             1.7873e-07,  8.2995e-07,  1.1084e-06,  2.2929e-06,  1.6665e-06,\n",
       "             1.3713e-06,  9.8586e-07,  2.3010e-06,  1.5705e-06, -1.5089e-06,\n",
       "            -2.0753e-06, -1.6575e-06, -3.1966e-06, -2.8062e-06, -1.1358e-06,\n",
       "             1.6166e-06, -2.5330e-08,  3.9384e-06,  2.1042e-06,  4.1829e-06,\n",
       "             2.2585e-06,  4.6310e-06, -8.6747e-07, -2.7552e-06, -1.6114e-06,\n",
       "            -9.2036e-07, -2.0369e-06, -1.8530e-06,  4.4561e-06,  2.6393e-07,\n",
       "             2.1505e-07, -1.3347e-06, -2.5025e-06, -4.2738e-06, -7.3102e-07,\n",
       "            -3.4696e-06,  5.4164e-07, -3.0427e-06,  3.1679e-06,  4.1460e-06,\n",
       "             9.9763e-06, -7.5416e-07, -1.3994e-06,  1.6330e-06, -1.9153e-06,\n",
       "            -1.4537e-06, -4.3343e-06, -3.7122e-06,  2.3436e-06,  1.9509e-06,\n",
       "             2.0963e-06,  1.1748e-06, -1.9684e-06, -2.6794e-06, -3.2570e-06,\n",
       "             4.2782e-07,  1.1142e-06, -7.9387e-06,  6.9859e-07, -6.0303e-06,\n",
       "             1.5086e-06,  1.4876e-06], device='cuda:0'),\n",
       "    'exp_avg_sq': tensor([6.2085e-13, 1.9511e-14, 2.7032e-14, 3.2077e-14, 5.5782e-14, 1.2158e-14,\n",
       "            6.7428e-14, 4.1580e-14, 3.8144e-14, 3.2336e-14, 4.2195e-14, 1.1589e-14,\n",
       "            4.0546e-14, 6.6274e-14, 2.8929e-14, 7.2993e-14, 4.0667e-14, 2.3601e-14,\n",
       "            5.7060e-14, 3.0972e-14, 1.0236e-14, 4.8536e-14, 1.7394e-14, 6.5310e-14,\n",
       "            2.3965e-14, 3.6619e-14, 3.0004e-14, 6.7236e-15, 4.8186e-14, 1.6897e-14,\n",
       "            1.2488e-15, 1.1501e-15, 1.9655e-14, 3.3547e-14, 1.5489e-14, 1.6511e-14,\n",
       "            5.4863e-14, 4.0228e-14, 4.2159e-14, 2.2596e-14, 9.7218e-15, 7.5135e-14,\n",
       "            1.2731e-13, 1.1527e-14, 8.7175e-16, 1.9331e-14, 4.2107e-14, 3.5163e-14,\n",
       "            2.8795e-14, 2.0708e-14, 1.2497e-14, 6.0316e-15, 1.8131e-15, 9.4441e-15,\n",
       "            2.1289e-14, 1.4782e-14, 7.3221e-15, 2.3093e-15, 5.5791e-15, 5.2068e-14,\n",
       "            3.1844e-14, 1.2606e-14, 1.0050e-14, 4.4745e-14, 4.3777e-11, 3.5050e-13,\n",
       "            8.1740e-13, 4.9336e-12, 5.7411e-13, 1.7150e-13, 7.1326e-12, 6.6674e-12,\n",
       "            1.2512e-12, 7.4896e-14, 5.5559e-13, 1.3126e-13, 1.0926e-12, 3.5985e-13,\n",
       "            1.6470e-13, 4.5255e-12, 9.3142e-13, 5.5232e-13, 1.5575e-11, 3.8731e-12,\n",
       "            1.3283e-13, 5.8544e-13, 5.9038e-13, 4.9719e-13, 8.3212e-13, 2.3351e-13,\n",
       "            1.9127e-13, 9.0653e-13, 6.0881e-13, 3.4945e-13, 1.2411e-13, 1.7481e-15,\n",
       "            2.6147e-12, 3.0954e-13, 1.6342e-13, 6.8061e-13, 2.8060e-12, 1.7894e-12,\n",
       "            9.7098e-14, 1.1595e-12, 2.0204e-13, 6.1081e-11, 1.0220e-10, 2.9647e-13,\n",
       "            2.6162e-15, 3.0410e-13, 3.3322e-13, 2.5208e-13, 4.3771e-13, 1.3883e-13,\n",
       "            2.0579e-13, 2.1149e-13, 1.2522e-13, 3.0000e-13, 2.2322e-13, 7.0686e-13,\n",
       "            4.3316e-13, 2.9055e-13, 5.1012e-15, 9.9526e-14, 9.7892e-14, 7.0492e-13,\n",
       "            2.9266e-14, 1.8254e-12, 1.2407e-10, 9.8777e-12, 5.6078e-12, 8.7580e-12,\n",
       "            1.2830e-11, 1.4558e-11, 1.8410e-11, 1.3709e-11, 1.4756e-11, 1.0123e-11,\n",
       "            1.4239e-11, 8.0476e-12, 1.1330e-11, 1.1437e-11, 1.5969e-11, 1.8584e-11,\n",
       "            5.0652e-12, 1.0383e-11, 8.8442e-12, 2.1411e-11, 1.6297e-11, 2.1079e-11,\n",
       "            1.6591e-11, 2.7085e-11, 1.1943e-11, 1.0449e-11, 6.9355e-12, 1.3971e-11,\n",
       "            9.6917e-12, 1.2631e-11, 1.2347e-11, 7.5775e-12, 9.3937e-12, 8.6546e-12,\n",
       "            1.2435e-11, 1.3203e-11, 8.0900e-12, 1.1964e-11, 1.3997e-11, 1.6377e-11,\n",
       "            1.3767e-11, 3.3039e-11, 1.9610e-11, 1.1213e-11, 6.4858e-12, 7.7719e-12,\n",
       "            1.1374e-11, 5.9855e-12, 1.4130e-11, 1.3478e-11, 1.7079e-11, 7.9704e-12,\n",
       "            9.8327e-12, 6.6332e-12, 8.3543e-12, 1.0073e-11, 1.3546e-11, 4.2861e-12,\n",
       "            8.5077e-12, 2.9317e-11, 7.6672e-12, 1.4441e-11, 9.8355e-12, 1.3223e-11],\n",
       "           device='cuda:0')},\n",
       "   6: {'step': 306693,\n",
       "    'exp_avg': tensor([ 5.2634e-08,  8.3800e-08,  9.7649e-09,  4.1831e-08,  6.9695e-08,\n",
       "             6.6115e-08,  9.1127e-08,  7.5645e-08,  4.4019e-08,  1.3073e-07,\n",
       "             7.7323e-08,  4.1449e-08,  1.1987e-07,  1.2157e-07,  1.2002e-07,\n",
       "             1.6939e-07,  1.0022e-07,  6.7109e-08, -2.9542e-08,  1.2507e-07,\n",
       "             4.6946e-08,  1.7292e-07,  5.9208e-08,  2.2387e-07,  3.0688e-08,\n",
       "             1.5670e-07,  1.0143e-07,  1.0410e-08,  1.3906e-07,  5.7789e-08,\n",
       "             1.7264e-08,  1.4862e-08, -2.3829e-10,  7.7158e-08,  1.0834e-07,\n",
       "             1.3630e-07,  5.8541e-08,  1.9789e-07,  2.2324e-08,  7.7378e-08,\n",
       "             6.7223e-08,  1.2800e-07,  8.0042e-07,  2.0115e-08,  2.1137e-09,\n",
       "             7.7600e-08,  1.1387e-07,  1.1277e-07,  1.7997e-07,  1.3563e-07,\n",
       "            -8.5771e-09,  4.8707e-08,  1.5284e-08,  4.1506e-08,  9.4258e-08,\n",
       "             9.1125e-08,  6.3850e-08,  3.3946e-09,  1.7041e-08,  2.9925e-07,\n",
       "             3.6081e-08,  1.5114e-07,  4.1028e-08,  7.6560e-08, -9.6166e-07,\n",
       "            -3.9498e-07,  1.2405e-07, -3.3058e-07, -3.6440e-07, -2.7783e-07,\n",
       "            -8.5077e-07, -2.0074e-06,  9.7432e-07, -1.5153e-07,  2.0918e-07,\n",
       "            -2.1907e-07, -9.8074e-07, -2.5991e-07, -2.3780e-07, -2.2821e-06,\n",
       "            -3.4596e-07, -3.5550e-07,  7.8546e-07,  4.7108e-07, -2.2014e-07,\n",
       "            -4.7122e-07, -6.0304e-07, -6.6422e-07, -1.6110e-07, -3.7093e-07,\n",
       "            -2.6771e-07, -4.9240e-07, -5.6030e-07,  5.8549e-07, -3.1259e-07,\n",
       "            -5.9365e-08,  1.0293e-06, -2.9755e-07, -1.8976e-07, -5.1046e-07,\n",
       "             6.2624e-08, -1.0861e-06,  4.9904e-08, -2.8309e-07, -3.3108e-07,\n",
       "            -1.9109e-06, -2.9600e-05,  3.8400e-07,  3.7579e-09, -3.4299e-07,\n",
       "            -3.3609e-07, -8.1985e-07, -3.1660e-07, -3.9667e-07, -5.1894e-07,\n",
       "            -2.8486e-07,  1.7380e-07, -3.0671e-07, -3.3255e-07, -7.7556e-07,\n",
       "            -6.5909e-07,  1.9231e-07, -5.1129e-08, -4.6771e-07, -8.8446e-09,\n",
       "            -5.9894e-07, -8.0719e-08, -2.3457e-07,  1.1544e-06,  1.2782e-06,\n",
       "             1.1206e-07,  4.5950e-07,  6.7122e-07,  1.4281e-06,  1.0058e-06,\n",
       "             8.2678e-07,  6.0379e-07,  1.3549e-06,  9.1702e-07, -8.4624e-07,\n",
       "            -1.1562e-06, -1.0107e-06, -1.8150e-06, -1.7530e-06, -7.0445e-07,\n",
       "             9.3527e-07, -1.5949e-07,  2.4465e-06,  1.2795e-06,  2.3699e-06,\n",
       "             1.3320e-06,  3.1266e-06, -4.8167e-07, -1.7563e-06, -1.0385e-06,\n",
       "            -7.5330e-07, -1.2554e-06, -1.0132e-06,  2.8905e-06,  1.5756e-07,\n",
       "             1.1501e-07, -8.5362e-07, -1.5306e-06, -2.6221e-06, -4.2577e-07,\n",
       "            -2.2198e-06,  3.1151e-07, -1.7681e-06,  1.9001e-06,  2.3623e-06,\n",
       "             6.8668e-06, -4.0029e-07, -7.8460e-07,  9.7872e-07, -1.1617e-06,\n",
       "            -8.9486e-07, -2.6192e-06, -2.0681e-06,  1.3355e-06,  1.1982e-06,\n",
       "             1.2875e-06,  7.0576e-07, -1.2244e-06, -1.4676e-06, -1.9760e-06,\n",
       "             2.1996e-07,  5.8663e-07, -4.4358e-06,  3.7392e-07, -3.4803e-06,\n",
       "             8.4909e-07,  8.9206e-07], device='cuda:0'),\n",
       "    'exp_avg_sq': tensor([6.2085e-13, 1.9511e-14, 2.7032e-14, 3.2077e-14, 5.5782e-14, 1.2158e-14,\n",
       "            6.7428e-14, 4.1580e-14, 3.8144e-14, 3.2336e-14, 4.2195e-14, 1.1589e-14,\n",
       "            4.0546e-14, 6.6274e-14, 2.8929e-14, 7.2993e-14, 4.0667e-14, 2.3601e-14,\n",
       "            5.7060e-14, 3.0972e-14, 1.0236e-14, 4.8536e-14, 1.7394e-14, 6.5310e-14,\n",
       "            2.3965e-14, 3.6619e-14, 3.0004e-14, 6.7236e-15, 4.8186e-14, 1.6897e-14,\n",
       "            1.2488e-15, 1.1501e-15, 1.9655e-14, 3.3547e-14, 1.5489e-14, 1.6511e-14,\n",
       "            5.4863e-14, 4.0228e-14, 4.2159e-14, 2.2596e-14, 9.7218e-15, 7.5135e-14,\n",
       "            1.2731e-13, 1.1527e-14, 8.7175e-16, 1.9331e-14, 4.2107e-14, 3.5163e-14,\n",
       "            2.8795e-14, 2.0708e-14, 1.2497e-14, 6.0316e-15, 1.8131e-15, 9.4441e-15,\n",
       "            2.1289e-14, 1.4782e-14, 7.3221e-15, 2.3093e-15, 5.5791e-15, 5.2068e-14,\n",
       "            3.1844e-14, 1.2606e-14, 1.0050e-14, 4.4745e-14, 4.3777e-11, 3.5050e-13,\n",
       "            8.1740e-13, 4.9336e-12, 5.7411e-13, 1.7150e-13, 7.1326e-12, 6.6674e-12,\n",
       "            1.2512e-12, 7.4896e-14, 5.5559e-13, 1.3126e-13, 1.0926e-12, 3.5985e-13,\n",
       "            1.6470e-13, 4.5255e-12, 9.3142e-13, 5.5232e-13, 1.5575e-11, 3.8731e-12,\n",
       "            1.3283e-13, 5.8544e-13, 5.9038e-13, 4.9719e-13, 8.3212e-13, 2.3351e-13,\n",
       "            1.9127e-13, 9.0653e-13, 6.0881e-13, 3.4945e-13, 1.2411e-13, 1.7481e-15,\n",
       "            2.6147e-12, 3.0954e-13, 1.6342e-13, 6.8061e-13, 2.8060e-12, 1.7894e-12,\n",
       "            9.7098e-14, 1.1595e-12, 2.0204e-13, 6.1081e-11, 1.0220e-10, 2.9647e-13,\n",
       "            2.6162e-15, 3.0410e-13, 3.3322e-13, 2.5208e-13, 4.3771e-13, 1.3883e-13,\n",
       "            2.0579e-13, 2.1149e-13, 1.2522e-13, 3.0000e-13, 2.2322e-13, 7.0686e-13,\n",
       "            4.3316e-13, 2.9055e-13, 5.1012e-15, 9.9526e-14, 9.7892e-14, 7.0492e-13,\n",
       "            2.9266e-14, 1.8254e-12, 7.9454e-11, 3.9007e-12, 2.2325e-12, 2.8748e-12,\n",
       "            4.7415e-12, 5.3136e-12, 6.9181e-12, 4.8158e-12, 5.4602e-12, 2.9816e-12,\n",
       "            4.9560e-12, 2.5792e-12, 3.5157e-12, 4.2472e-12, 5.2140e-12, 7.2933e-12,\n",
       "            1.9682e-12, 3.5548e-12, 4.2670e-12, 8.9410e-12, 5.9427e-12, 7.3643e-12,\n",
       "            5.8238e-12, 1.3470e-11, 3.9013e-12, 4.1469e-12, 2.9017e-12, 6.3125e-12,\n",
       "            3.6994e-12, 3.9023e-12, 5.3071e-12, 3.0822e-12, 3.6650e-12, 3.5851e-12,\n",
       "            4.3540e-12, 5.0173e-12, 3.4077e-12, 5.0418e-12, 5.0759e-12, 6.2836e-12,\n",
       "            5.0571e-12, 1.2599e-11, 9.1692e-12, 4.2436e-12, 2.1249e-12, 2.7875e-12,\n",
       "            4.1456e-12, 2.2052e-12, 5.4336e-12, 4.2014e-12, 5.8320e-12, 3.0683e-12,\n",
       "            3.8630e-12, 2.3862e-12, 3.1660e-12, 3.0535e-12, 5.0651e-12, 1.3136e-12,\n",
       "            2.3758e-12, 1.0149e-11, 2.7582e-12, 5.0725e-12, 3.1758e-12, 4.8177e-12],\n",
       "           device='cuda:0')},\n",
       "   7: {'step': 306693,\n",
       "    'exp_avg': tensor([[-1.0064e-10, -9.0329e-09, -1.6460e-08,  ...,  1.7268e-09,\n",
       "             -1.5145e-10, -4.2477e-10],\n",
       "            [ 1.4546e-09,  7.4381e-08,  1.3844e-07,  ..., -1.4548e-08,\n",
       "              1.6184e-09,  3.7157e-09],\n",
       "            [ 3.3514e-10,  1.8306e-08,  3.4176e-08,  ..., -3.6004e-09,\n",
       "              3.7941e-10,  8.6865e-10],\n",
       "            ...,\n",
       "            [ 4.1925e-09,  3.4191e-07,  6.3096e-07,  ..., -6.2252e-08,\n",
       "              1.4628e-09,  1.1386e-08],\n",
       "            [-6.6783e-08, -3.4798e-06, -6.4622e-06,  ...,  6.9049e-07,\n",
       "             -8.2332e-08, -1.7071e-07],\n",
       "            [-2.0350e-08, -1.1059e-06, -2.0598e-06,  ...,  2.0810e-07,\n",
       "             -1.5232e-08, -4.7515e-08]], device='cuda:0'),\n",
       "    'exp_avg_sq': tensor([[1.8760e-19, 9.1557e-18, 3.2499e-17,  ..., 3.3502e-19, 1.6140e-19,\n",
       "             1.2693e-18],\n",
       "            [2.7728e-17, 7.3634e-16, 2.5615e-15,  ..., 2.6528e-17, 2.6151e-17,\n",
       "             1.7157e-16],\n",
       "            [1.3552e-18, 4.1989e-17, 1.4699e-16,  ..., 1.5171e-18, 1.2631e-18,\n",
       "             8.1975e-18],\n",
       "            ...,\n",
       "            [3.5757e-16, 1.3766e-14, 4.8221e-14,  ..., 4.6495e-16, 3.2422e-16,\n",
       "             2.2237e-15],\n",
       "            [4.7460e-14, 1.4865e-12, 5.1563e-12,  ..., 5.6561e-14, 4.4147e-14,\n",
       "             2.7540e-13],\n",
       "            [5.7139e-15, 1.6158e-13, 5.6742e-13,  ..., 5.2841e-15, 5.2322e-15,\n",
       "             3.6612e-14]], device='cuda:0')},\n",
       "   8: {'step': 306693,\n",
       "    'exp_avg': tensor([[ 4.3565e-11,  4.3387e-11,  4.3450e-11,  ..., -4.3364e-11,\n",
       "              4.3659e-11,  4.3149e-11],\n",
       "            [-1.0735e-11, -1.1708e-11, -1.3364e-11,  ...,  1.2655e-11,\n",
       "             -8.2783e-12, -1.0073e-11],\n",
       "            [-1.7678e-11, -1.4296e-11, -1.6110e-11,  ...,  1.8463e-11,\n",
       "             -1.1435e-11, -1.5184e-11],\n",
       "            ...,\n",
       "            [-3.7282e-09, -3.7171e-09, -3.7273e-09,  ...,  3.7271e-09,\n",
       "             -3.7224e-09, -3.7184e-09],\n",
       "            [-5.9730e-09, -5.0432e-09, -5.3087e-09,  ...,  6.3259e-09,\n",
       "             -3.9710e-09, -5.6172e-09],\n",
       "            [ 7.5077e-09,  7.5105e-09,  7.4850e-09,  ..., -7.4757e-09,\n",
       "              7.4971e-09,  7.4676e-09]], device='cuda:0'),\n",
       "    'exp_avg_sq': tensor([[4.4303e-20, 4.3120e-20, 4.3809e-20,  ..., 4.4414e-20, 4.2916e-20,\n",
       "             4.3414e-20],\n",
       "            [2.0849e-20, 1.6302e-20, 1.9111e-20,  ..., 2.2298e-20, 1.4444e-20,\n",
       "             1.7491e-20],\n",
       "            [2.9460e-21, 2.0293e-21, 2.5232e-21,  ..., 3.1714e-21, 1.6061e-21,\n",
       "             2.2717e-21],\n",
       "            ...,\n",
       "            [9.5853e-18, 9.4395e-18, 9.5223e-18,  ..., 9.5897e-18, 9.4359e-18,\n",
       "             9.4619e-18],\n",
       "            [3.3686e-17, 3.0792e-17, 3.2183e-17,  ..., 3.4420e-17, 2.9046e-17,\n",
       "             3.1837e-17],\n",
       "            [3.8040e-17, 3.3816e-17, 3.6223e-17,  ..., 3.8976e-17, 3.1699e-17,\n",
       "             3.4910e-17]], device='cuda:0')},\n",
       "   9: {'step': 306693,\n",
       "    'exp_avg': tensor([-3.0499e-08,  2.5361e-07,  6.2514e-08,  1.8860e-07,  1.3417e-08,\n",
       "             1.5982e-07,  3.3309e-08,  2.2929e-07,  8.2780e-08,  4.2372e-08,\n",
       "            -1.4865e-07,  1.4198e-07,  2.3722e-08,  8.2778e-10,  1.8626e-07,\n",
       "             3.1094e-07,  1.3161e-07, -8.2640e-08,  3.3255e-07,  7.2332e-08,\n",
       "             2.2394e-07,  1.4156e-07,  5.9310e-08,  5.6042e-08,  1.7940e-07,\n",
       "             2.5218e-07,  3.2849e-07,  1.6370e-08,  4.9322e-07,  3.8835e-07,\n",
       "             2.5286e-08,  9.9308e-09,  1.3078e-08, -1.0931e-07,  1.7047e-07,\n",
       "             5.1300e-07,  2.6898e-07, -1.7099e-08,  3.6870e-07, -4.2653e-09,\n",
       "             9.4156e-08,  3.3041e-07,  2.4581e-07,  3.7912e-07, -1.5855e-07,\n",
       "             8.2426e-08, -1.1100e-08,  1.1578e-08,  3.1063e-08,  2.5978e-05,\n",
       "            -1.0671e-07,  1.8134e-07,  4.5455e-07, -1.3583e-09,  6.9748e-08,\n",
       "             3.6218e-07, -5.2605e-08,  4.5885e-07,  1.9589e-07,  1.0549e-07,\n",
       "             4.7110e-08, -4.3512e-08,  9.4014e-08, -8.2075e-08,  2.0930e-07,\n",
       "            -2.1653e-06, -8.8883e-07, -1.6210e-06, -2.2133e-07, -1.0801e-06,\n",
       "            -3.8662e-07, -1.7585e-06, -1.4804e-06, -8.1966e-07,  1.0361e-06,\n",
       "            -1.9418e-06,  6.0303e-07, -5.6659e-09, -9.2789e-07, -2.1793e-06,\n",
       "            -1.1830e-06,  5.7563e-07, -2.1671e-06, -5.2412e-07, -1.0064e-06,\n",
       "            -9.0632e-07, -1.0510e-06,  3.2857e-07, -8.8515e-07, -1.4263e-06,\n",
       "            -2.3454e-06, -3.2325e-07, -3.2047e-06, -1.2301e-06, -1.3136e-07,\n",
       "             1.0184e-06, -3.2701e-07,  7.8403e-07, -1.7734e-06, -2.2050e-06,\n",
       "            -1.2658e-06,  1.1170e-07, -1.7455e-06, -7.6776e-08, -1.7111e-06,\n",
       "            -2.3904e-06, -9.5262e-07, -2.6722e-06,  8.9721e-07,  6.8634e-07,\n",
       "             4.7303e-07, -1.9446e-07, -1.9857e-07,  2.3933e-04,  6.7622e-07,\n",
       "            -1.3978e-06, -1.5857e-06,  1.3509e-07, -2.2820e-06, -1.5877e-06,\n",
       "             4.8122e-07, -2.8098e-06, -1.5674e-06, -1.5224e-06, -7.0918e-07,\n",
       "             3.4726e-07,  3.9132e-07,  1.0244e-06, -7.9514e-07,  1.1782e-05,\n",
       "             4.8935e-06,  7.6064e-06,  1.0477e-06,  6.7643e-06,  9.7059e-07,\n",
       "             8.4571e-06,  6.4137e-06,  8.1643e-06, -6.3492e-06, -6.6887e-06,\n",
       "             3.3620e-06, -2.0901e-08, -1.2164e-05, -1.0357e-05, -9.1505e-06,\n",
       "            -2.6311e-06,  1.1143e-05,  2.0806e-06,  6.0030e-06,  4.9896e-06,\n",
       "             5.9555e-06, -2.7457e-06, -4.5740e-06, -7.8815e-06, -1.7179e-05,\n",
       "            -1.1694e-06, -1.4079e-05, -1.0045e-05,  1.6330e-06,  6.9395e-06,\n",
       "             2.8288e-06,  5.0409e-06,  5.3624e-06, -1.6552e-05, -7.4559e-06,\n",
       "             4.7457e-07,  1.0083e-05, -8.5216e-07,  1.1857e-05,  7.9060e-06,\n",
       "            -9.6961e-06, -1.2221e-05,  6.4356e-06, -6.7428e-06,  2.4959e-06,\n",
       "            -8.6037e-07, -1.3601e-06,  3.2727e-03,  5.1068e-06,  8.9983e-06,\n",
       "             1.3685e-05, -1.1970e-06, -1.4760e-05, -1.3184e-05,  2.3385e-06,\n",
       "             1.3460e-05,  1.0332e-05, -9.5114e-06,  3.0136e-06,  1.1649e-06,\n",
       "            -1.1797e-05, -3.7886e-06], device='cuda:0'),\n",
       "    'exp_avg_sq': tensor([1.2654e-16, 1.1063e-14, 6.1109e-16, 5.5825e-15, 3.6980e-17, 3.9287e-15,\n",
       "            2.6620e-16, 8.2390e-15, 1.1080e-15, 2.6251e-16, 3.3806e-15, 3.2516e-15,\n",
       "            8.1793e-17, 2.2990e-17, 5.0867e-15, 1.5393e-14, 2.6126e-15, 1.0718e-15,\n",
       "            1.7952e-14, 9.0369e-16, 7.8585e-15, 3.6313e-15, 5.4966e-16, 4.7590e-16,\n",
       "            4.9570e-15, 1.0082e-14, 1.6363e-14, 5.1327e-17, 4.2541e-14, 2.2251e-14,\n",
       "            1.1887e-16, 1.6009e-17, 2.6572e-17, 1.6597e-15, 4.6811e-15, 3.9435e-14,\n",
       "            1.1669e-14, 4.5556e-17, 2.0939e-14, 2.4758e-18, 1.4145e-15, 1.7730e-14,\n",
       "            8.8909e-15, 2.4471e-14, 3.8882e-15, 9.8215e-16, 1.7098e-17, 2.8902e-17,\n",
       "            1.7094e-16, 1.1511e-10, 1.5800e-15, 5.2210e-15, 3.2703e-14, 4.3518e-19,\n",
       "            7.4554e-16, 2.0994e-14, 4.1267e-16, 3.3422e-14, 5.9810e-15, 1.8050e-15,\n",
       "            3.5978e-16, 2.6905e-16, 1.3207e-15, 1.1649e-15, 6.1906e-15, 6.5617e-13,\n",
       "            1.3566e-13, 4.2323e-13, 1.0706e-14, 1.8977e-13, 2.8605e-14, 4.9661e-13,\n",
       "            3.5004e-13, 1.2436e-13, 1.7373e-13, 5.5591e-13, 5.7517e-14, 9.7576e-16,\n",
       "            1.9904e-13, 7.0271e-13, 2.2230e-13, 4.4527e-14, 7.7810e-13, 5.3918e-14,\n",
       "            1.5943e-13, 1.1670e-13, 1.7627e-13, 1.8253e-14, 1.2279e-13, 3.3020e-13,\n",
       "            9.4048e-13, 2.0661e-14, 1.3978e-12, 3.0028e-13, 4.7110e-15, 1.4480e-13,\n",
       "            2.0327e-14, 1.0423e-13, 4.8782e-13, 9.4286e-13, 2.3287e-13, 1.6091e-15,\n",
       "            5.1630e-13, 8.5425e-16, 4.6797e-13, 8.9138e-13, 1.9037e-13, 9.8463e-13,\n",
       "            1.2849e-13, 9.1960e-14, 3.5329e-14, 8.2547e-15, 6.5779e-15, 1.0110e-08,\n",
       "            8.0569e-14, 2.8430e-13, 4.1388e-13, 2.8725e-15, 8.2628e-13, 4.0107e-13,\n",
       "            3.2938e-14, 1.2234e-12, 4.2120e-13, 3.4929e-13, 7.6598e-14, 1.7707e-14,\n",
       "            4.5893e-14, 1.3855e-13, 8.5398e-14, 2.4097e-11, 3.7259e-12, 9.2306e-12,\n",
       "            2.2476e-13, 7.0471e-12, 2.2444e-13, 1.1336e-11, 6.7377e-12, 9.9465e-12,\n",
       "            6.1725e-12, 7.2452e-12, 1.6392e-12, 1.5064e-14, 2.1806e-11, 1.7356e-11,\n",
       "            1.2815e-11, 1.0755e-12, 1.9547e-11, 7.6839e-13, 5.7526e-12, 4.3900e-12,\n",
       "            5.5630e-12, 1.1296e-12, 3.2447e-12, 9.8077e-12, 4.4799e-11, 2.5126e-13,\n",
       "            3.4835e-11, 1.4860e-11, 5.0586e-13, 7.7105e-12, 1.1951e-12, 3.5255e-12,\n",
       "            4.6070e-12, 4.1588e-11, 9.0010e-12, 3.4915e-14, 1.5762e-11, 1.1108e-13,\n",
       "            2.1970e-11, 1.0129e-11, 1.3782e-11, 2.5977e-11, 6.4618e-12, 6.6804e-12,\n",
       "            8.5321e-13, 1.5814e-13, 3.2060e-13, 1.8820e-06, 3.6312e-12, 1.2856e-11,\n",
       "            2.9337e-11, 2.3874e-13, 3.3720e-11, 2.8048e-11, 8.2142e-13, 2.8582e-11,\n",
       "            1.6754e-11, 1.4708e-11, 1.4598e-12, 1.9619e-13, 2.0942e-11, 2.4779e-12],\n",
       "           device='cuda:0')},\n",
       "   10: {'step': 306693,\n",
       "    'exp_avg': tensor([-3.0499e-08,  2.5361e-07,  6.2514e-08,  1.8860e-07,  1.3417e-08,\n",
       "             1.5982e-07,  3.3309e-08,  2.2929e-07,  8.2780e-08,  4.2372e-08,\n",
       "            -1.4865e-07,  1.4198e-07,  2.3722e-08,  8.2778e-10,  1.8626e-07,\n",
       "             3.1094e-07,  1.3161e-07, -8.2640e-08,  3.3255e-07,  7.2332e-08,\n",
       "             2.2394e-07,  1.4156e-07,  5.9310e-08,  5.6042e-08,  1.7940e-07,\n",
       "             2.5218e-07,  3.2849e-07,  1.6370e-08,  4.9322e-07,  3.8835e-07,\n",
       "             2.5286e-08,  9.9308e-09,  1.3078e-08, -1.0931e-07,  1.7047e-07,\n",
       "             5.1300e-07,  2.6898e-07, -1.7099e-08,  3.6870e-07, -4.2653e-09,\n",
       "             9.4156e-08,  3.3041e-07,  2.4581e-07,  3.7912e-07, -1.5855e-07,\n",
       "             8.2426e-08, -1.1100e-08,  1.1578e-08,  3.1063e-08,  2.5978e-05,\n",
       "            -1.0671e-07,  1.8134e-07,  4.5455e-07, -1.3583e-09,  6.9748e-08,\n",
       "             3.6218e-07, -5.2605e-08,  4.5885e-07,  1.9589e-07,  1.0549e-07,\n",
       "             4.7110e-08, -4.3512e-08,  9.4014e-08, -8.2075e-08,  2.0930e-07,\n",
       "            -2.1653e-06, -8.8883e-07, -1.6210e-06, -2.2133e-07, -1.0801e-06,\n",
       "            -3.8662e-07, -1.7585e-06, -1.4804e-06, -8.1966e-07,  1.0361e-06,\n",
       "            -1.9418e-06,  6.0303e-07, -5.6659e-09, -9.2789e-07, -2.1793e-06,\n",
       "            -1.1830e-06,  5.7563e-07, -2.1671e-06, -5.2412e-07, -1.0064e-06,\n",
       "            -9.0632e-07, -1.0510e-06,  3.2857e-07, -8.8515e-07, -1.4263e-06,\n",
       "            -2.3454e-06, -3.2325e-07, -3.2047e-06, -1.2301e-06, -1.3136e-07,\n",
       "             1.0184e-06, -3.2701e-07,  7.8403e-07, -1.7734e-06, -2.2050e-06,\n",
       "            -1.2658e-06,  1.1170e-07, -1.7455e-06, -7.6776e-08, -1.7111e-06,\n",
       "            -2.3904e-06, -9.5262e-07, -2.6722e-06,  8.9721e-07,  6.8634e-07,\n",
       "             4.7303e-07, -1.9446e-07, -1.9857e-07,  2.3933e-04,  6.7622e-07,\n",
       "            -1.3978e-06, -1.5857e-06,  1.3509e-07, -2.2820e-06, -1.5877e-06,\n",
       "             4.8122e-07, -2.8098e-06, -1.5674e-06, -1.5224e-06, -7.0918e-07,\n",
       "             3.4726e-07,  3.9132e-07,  1.0244e-06, -5.0316e-07,  6.6133e-06,\n",
       "             3.0173e-06,  4.3832e-06,  6.4465e-07,  4.1585e-06,  6.2889e-07,\n",
       "             4.8964e-06,  3.7610e-06,  4.5358e-06, -4.0835e-06, -3.6627e-06,\n",
       "             1.8195e-06, -1.2827e-08, -6.7048e-06, -6.7319e-06, -5.4884e-06,\n",
       "            -1.5943e-06,  7.5782e-06,  1.3367e-06,  3.7138e-06,  3.0887e-06,\n",
       "             3.3069e-06, -1.6084e-06, -2.6727e-06, -4.8180e-06, -1.0661e-05,\n",
       "            -7.7731e-07, -8.2561e-06, -5.8858e-06,  1.0118e-06,  4.2935e-06,\n",
       "             1.6560e-06,  3.0272e-06,  2.4672e-06, -9.5931e-06, -4.2755e-06,\n",
       "             2.7657e-07,  6.0556e-06, -5.3243e-07,  7.7951e-06,  4.6585e-06,\n",
       "            -5.6523e-06, -6.9294e-06,  3.8426e-06, -3.7389e-06,  1.3147e-06,\n",
       "            -5.6889e-07, -8.0323e-07,  1.3600e-03,  3.1985e-06,  5.4575e-06,\n",
       "             8.7712e-06, -6.6707e-07, -8.7747e-06, -8.7146e-06,  1.2321e-06,\n",
       "             8.1932e-06,  6.0540e-06, -5.8830e-06,  2.0206e-06,  7.1001e-07,\n",
       "            -7.5311e-06, -2.2837e-06], device='cuda:0'),\n",
       "    'exp_avg_sq': tensor([1.2654e-16, 1.1063e-14, 6.1109e-16, 5.5825e-15, 3.6980e-17, 3.9287e-15,\n",
       "            2.6620e-16, 8.2390e-15, 1.1080e-15, 2.6251e-16, 3.3806e-15, 3.2516e-15,\n",
       "            8.1793e-17, 2.2990e-17, 5.0867e-15, 1.5393e-14, 2.6126e-15, 1.0718e-15,\n",
       "            1.7952e-14, 9.0369e-16, 7.8585e-15, 3.6313e-15, 5.4966e-16, 4.7590e-16,\n",
       "            4.9570e-15, 1.0082e-14, 1.6363e-14, 5.1327e-17, 4.2541e-14, 2.2251e-14,\n",
       "            1.1887e-16, 1.6009e-17, 2.6572e-17, 1.6597e-15, 4.6811e-15, 3.9435e-14,\n",
       "            1.1669e-14, 4.5556e-17, 2.0939e-14, 2.4758e-18, 1.4145e-15, 1.7730e-14,\n",
       "            8.8909e-15, 2.4471e-14, 3.8882e-15, 9.8215e-16, 1.7098e-17, 2.8902e-17,\n",
       "            1.7094e-16, 1.1511e-10, 1.5800e-15, 5.2210e-15, 3.2703e-14, 4.3518e-19,\n",
       "            7.4554e-16, 2.0994e-14, 4.1267e-16, 3.3422e-14, 5.9810e-15, 1.8050e-15,\n",
       "            3.5978e-16, 2.6905e-16, 1.3207e-15, 1.1649e-15, 6.1906e-15, 6.5617e-13,\n",
       "            1.3566e-13, 4.2323e-13, 1.0706e-14, 1.8977e-13, 2.8605e-14, 4.9661e-13,\n",
       "            3.5004e-13, 1.2436e-13, 1.7373e-13, 5.5591e-13, 5.7517e-14, 9.7576e-16,\n",
       "            1.9904e-13, 7.0271e-13, 2.2230e-13, 4.4527e-14, 7.7810e-13, 5.3918e-14,\n",
       "            1.5943e-13, 1.1670e-13, 1.7627e-13, 1.8253e-14, 1.2279e-13, 3.3020e-13,\n",
       "            9.4048e-13, 2.0661e-14, 1.3978e-12, 3.0028e-13, 4.7110e-15, 1.4480e-13,\n",
       "            2.0327e-14, 1.0423e-13, 4.8782e-13, 9.4286e-13, 2.3287e-13, 1.6091e-15,\n",
       "            5.1630e-13, 8.5425e-16, 4.6797e-13, 8.9138e-13, 1.9037e-13, 9.8463e-13,\n",
       "            1.2849e-13, 9.1960e-14, 3.5329e-14, 8.2547e-15, 6.5779e-15, 1.0110e-08,\n",
       "            8.0569e-14, 2.8430e-13, 4.1388e-13, 2.8725e-15, 8.2628e-13, 4.0107e-13,\n",
       "            3.2938e-14, 1.2234e-12, 4.2120e-13, 3.4929e-13, 7.6598e-14, 1.7707e-14,\n",
       "            4.5893e-14, 1.3855e-13, 3.3737e-14, 7.7784e-12, 1.3992e-12, 3.1825e-12,\n",
       "            8.4218e-14, 2.6455e-12, 9.3467e-14, 3.9102e-12, 2.3809e-12, 3.1154e-12,\n",
       "            2.5525e-12, 2.1557e-12, 4.7613e-13, 5.7572e-15, 6.6563e-12, 7.4615e-12,\n",
       "            4.6597e-12, 3.8616e-13, 8.7902e-12, 3.2620e-13, 2.2570e-12, 1.6011e-12,\n",
       "            1.7386e-12, 3.7748e-13, 1.1253e-12, 3.6287e-12, 1.7209e-11, 1.0736e-13,\n",
       "            1.2081e-11, 5.0621e-12, 1.9469e-13, 3.0047e-12, 4.1119e-13, 1.2688e-12,\n",
       "            1.0776e-12, 1.4376e-11, 2.9936e-12, 1.1669e-14, 5.7473e-12, 4.4438e-14,\n",
       "            9.2523e-12, 3.4891e-12, 4.6194e-12, 8.8054e-12, 2.3398e-12, 2.0971e-12,\n",
       "            2.4288e-13, 6.7405e-14, 1.0811e-13, 3.2036e-07, 1.4291e-12, 4.7086e-12,\n",
       "            1.1868e-11, 7.7180e-14, 1.1882e-11, 1.2341e-11, 2.3675e-13, 1.0446e-11,\n",
       "            5.8215e-12, 5.6003e-12, 6.4869e-13, 7.4896e-14, 8.5820e-12, 8.7734e-13],\n",
       "           device='cuda:0')},\n",
       "   11: {'step': 306693,\n",
       "    'exp_avg': tensor([[-0.0008, -0.0008, -0.0008,  ...,  0.0008, -0.0008, -0.0008],\n",
       "            [-0.0008, -0.0008, -0.0008,  ...,  0.0008, -0.0008, -0.0008],\n",
       "            [-0.0020, -0.0020, -0.0020,  ...,  0.0020, -0.0020, -0.0020],\n",
       "            ...,\n",
       "            [-0.0011, -0.0011, -0.0011,  ...,  0.0011, -0.0011, -0.0011],\n",
       "            [-0.0017, -0.0017, -0.0017,  ...,  0.0017, -0.0017, -0.0017],\n",
       "            [ 0.0001,  0.0001,  0.0001,  ..., -0.0001,  0.0001,  0.0001]],\n",
       "           device='cuda:0'),\n",
       "    'exp_avg_sq': tensor([[9.5234e-06, 9.5329e-06, 9.5327e-06,  ..., 9.5316e-06, 9.5330e-06,\n",
       "             9.5319e-06],\n",
       "            [2.3402e-05, 2.3427e-05, 2.3426e-05,  ..., 2.3423e-05, 2.3427e-05,\n",
       "             2.3424e-05],\n",
       "            [2.7091e-05, 2.7118e-05, 2.7117e-05,  ..., 2.7114e-05, 2.7118e-05,\n",
       "             2.7115e-05],\n",
       "            ...,\n",
       "            [1.0169e-05, 1.0179e-05, 1.0179e-05,  ..., 1.0178e-05, 1.0179e-05,\n",
       "             1.0178e-05],\n",
       "            [1.3981e-05, 1.3996e-05, 1.3996e-05,  ..., 1.3994e-05, 1.3996e-05,\n",
       "             1.3995e-05],\n",
       "            [1.2592e-06, 1.2605e-06, 1.2605e-06,  ..., 1.2603e-06, 1.2605e-06,\n",
       "             1.2603e-06]], device='cuda:0')},\n",
       "   12: {'step': 306693,\n",
       "    'exp_avg': tensor([-7.8669e-04, -7.5371e-04, -1.9628e-03, -4.1749e-03, -3.4471e-03,\n",
       "            -3.8508e-03, -3.1868e-03,  8.4165e-04, -2.7152e-03, -4.6385e-03,\n",
       "             5.7298e-03, -3.0722e-04, -3.6875e-03, -1.5543e-04,  7.7446e-03,\n",
       "            -2.9033e-03, -4.9108e-03,  5.5835e-03, -5.1904e-04, -7.3759e-03,\n",
       "             5.6327e-03,  3.9433e-03, -3.7435e-03,  6.0590e-03, -1.2033e-03,\n",
       "            -3.5786e-03, -2.4650e-03,  4.9442e-03,  2.3784e-03, -6.7043e-04,\n",
       "             5.1172e-03, -6.6365e-04, -5.8400e-03,  8.8385e-03, -2.9099e-03,\n",
       "            -3.3035e-03, -3.2687e-03, -1.1476e-03,  7.3638e-03, -5.4248e-05,\n",
       "             5.0931e-04, -6.7874e-03,  2.8168e-03, -6.0679e-03, -6.5429e-03,\n",
       "            -9.6718e-05,  2.3413e-03, -2.0816e-03, -2.0358e-03, -1.1606e-03,\n",
       "             1.4338e-03, -3.8663e-03, -2.7220e-03,  1.9642e-03, -1.1658e-04,\n",
       "             4.1412e-03, -6.7539e-03, -1.6028e-03,  5.0949e-03,  7.0881e-03,\n",
       "             9.0895e-03, -3.2860e-03, -1.6293e-03, -5.3382e-03, -3.7857e-03,\n",
       "             7.4206e-04,  9.5832e-03, -6.3311e-04, -6.8019e-03,  4.4287e-03,\n",
       "             2.7048e-03,  2.7804e-03, -8.7073e-03,  8.6248e-03, -5.1738e-03,\n",
       "            -3.8765e-03, -6.5495e-03, -4.9260e-03,  4.2938e-03,  1.0170e-02,\n",
       "             9.5208e-04, -1.0777e-03,  1.3779e-03, -2.1074e-03,  4.7385e-03,\n",
       "            -7.7604e-04, -3.4413e-03, -8.9825e-03,  4.7595e-03, -1.2094e-03,\n",
       "             7.4257e-03, -3.2534e-03,  8.5434e-03, -9.0315e-03, -3.9558e-03,\n",
       "            -1.6485e-03,  6.9357e-03, -1.0631e-03, -1.6781e-03,  1.2781e-04],\n",
       "           device='cuda:0'),\n",
       "    'exp_avg_sq': tensor([9.5330e-06, 2.3427e-05, 2.7118e-05, 2.4169e-05, 4.1087e-05, 3.5839e-05,\n",
       "            1.3731e-05, 2.5191e-05, 1.4883e-05, 1.7187e-05, 4.4172e-06, 3.7143e-05,\n",
       "            3.0877e-05, 1.9995e-05, 3.1355e-05, 2.6281e-05, 9.4082e-06, 3.9286e-05,\n",
       "            1.0066e-05, 2.5596e-05, 1.9609e-05, 1.6559e-05, 2.6490e-05, 2.8179e-05,\n",
       "            1.3426e-05, 1.1124e-05, 3.8779e-06, 1.4742e-05, 3.6930e-06, 4.7997e-05,\n",
       "            2.2763e-05, 3.1393e-05, 4.6271e-05, 2.6344e-05, 1.9709e-05, 2.4511e-05,\n",
       "            2.5408e-05, 1.5540e-05, 3.5297e-05, 4.1735e-06, 7.7463e-06, 7.7627e-06,\n",
       "            3.0759e-06, 2.9520e-05, 2.9220e-05, 1.0030e-05, 7.1302e-06, 2.1221e-05,\n",
       "            3.1685e-05, 6.2452e-06, 3.5656e-05, 3.1430e-05, 9.2017e-06, 2.9547e-05,\n",
       "            3.6827e-05, 7.1999e-06, 1.7537e-05, 8.0955e-06, 2.9153e-05, 3.7306e-05,\n",
       "            3.8331e-05, 1.5232e-05, 1.1006e-05, 4.1714e-05, 1.2898e-05, 2.0400e-05,\n",
       "            2.0019e-05, 2.7347e-06, 4.2150e-05, 4.6652e-06, 2.0035e-06, 1.1290e-05,\n",
       "            4.7463e-05, 2.2574e-05, 1.1137e-05, 3.5207e-06, 3.8370e-05, 2.6449e-05,\n",
       "            1.0449e-05, 4.0076e-05, 2.3026e-05, 1.5714e-05, 1.6128e-05, 3.4153e-05,\n",
       "            2.5289e-05, 2.4183e-05, 3.1428e-05, 3.3552e-05, 1.2065e-05, 4.9916e-05,\n",
       "            1.0810e-05, 3.9312e-05, 3.9155e-05, 2.5854e-05, 1.0956e-05, 8.3842e-06,\n",
       "            2.7964e-05, 1.0179e-05, 1.3996e-05, 1.2605e-06], device='cuda:0')},\n",
       "   13: {'step': 306693,\n",
       "    'exp_avg': tensor([[-2.5325e-10, -2.5318e-10, -2.5318e-10,  ...,  2.5317e-10,\n",
       "             -2.5318e-10, -2.5316e-10],\n",
       "            [ 8.0729e-11,  8.0859e-11,  8.0857e-11,  ..., -8.0949e-11,\n",
       "              8.0861e-11,  8.0960e-11],\n",
       "            [-6.0354e-10, -6.0322e-10, -6.0323e-10,  ...,  6.0317e-10,\n",
       "             -6.0321e-10, -6.0315e-10],\n",
       "            ...,\n",
       "            [ 5.1609e-10,  5.1598e-10,  5.1598e-10,  ..., -5.1598e-10,\n",
       "              5.1598e-10,  5.1597e-10],\n",
       "            [ 2.6242e-10,  2.6279e-10,  2.6278e-10,  ..., -2.6275e-10,\n",
       "              2.6280e-10,  2.6279e-10],\n",
       "            [ 6.2103e-11,  6.2139e-11,  6.2138e-11,  ..., -6.2136e-11,\n",
       "              6.2139e-11,  6.2137e-11]], device='cuda:0'),\n",
       "    'exp_avg_sq': tensor([[1.2953e-18, 1.2965e-18, 1.2965e-18,  ..., 1.2963e-18, 1.2965e-18,\n",
       "             1.2964e-18],\n",
       "            [5.7310e-18, 5.7352e-18, 5.7351e-18,  ..., 5.7345e-18, 5.7352e-18,\n",
       "             5.7346e-18],\n",
       "            [7.0072e-18, 7.0142e-18, 7.0141e-18,  ..., 7.0132e-18, 7.0143e-18,\n",
       "             7.0134e-18],\n",
       "            ...,\n",
       "            [1.6461e-18, 1.6473e-18, 1.6473e-18,  ..., 1.6471e-18, 1.6473e-18,\n",
       "             1.6471e-18],\n",
       "            [3.8193e-18, 3.8220e-18, 3.8220e-18,  ..., 3.8215e-18, 3.8220e-18,\n",
       "             3.8216e-18],\n",
       "            [2.9536e-20, 2.9564e-20, 2.9564e-20,  ..., 2.9560e-20, 2.9564e-20,\n",
       "             2.9561e-20]], device='cuda:0')},\n",
       "   14: {'step': 306693,\n",
       "    'exp_avg': tensor([-2.5318e-10,  8.0860e-11, -6.0321e-10, -1.1576e-10,  2.2704e-09,\n",
       "            -2.7191e-09, -7.3157e-10,  6.0112e-12, -5.5691e-10,  9.9546e-10,\n",
       "             6.2761e-11,  3.5953e-09, -5.2507e-10, -5.8920e-10, -2.9582e-10,\n",
       "            -1.4362e-10, -6.0954e-10,  8.0853e-10, -2.5039e-10,  7.4928e-10,\n",
       "            -7.1897e-10,  2.5248e-10,  2.4387e-11, -6.8956e-10,  2.9324e-10,\n",
       "             5.6443e-10, -7.9679e-11,  1.8273e-10, -8.3435e-11,  3.3848e-09,\n",
       "             1.0841e-09,  3.8128e-10,  2.5953e-09,  6.1975e-10, -1.3372e-09,\n",
       "             9.4433e-10, -1.3251e-09, -8.0551e-10,  5.0894e-10, -1.1480e-10,\n",
       "             2.8654e-10,  5.9513e-11,  9.5661e-11,  9.9864e-10, -1.3695e-09,\n",
       "            -6.7229e-11,  2.2530e-10, -2.1030e-10, -8.1856e-10,  1.2845e-10,\n",
       "             1.1569e-09,  1.0650e-09,  1.2261e-10,  1.3302e-10,  1.8384e-10,\n",
       "             3.9842e-10, -1.4308e-09,  8.9572e-10,  8.0626e-10,  9.1886e-10,\n",
       "             1.4075e-09,  3.7571e-10,  3.3161e-11,  2.3976e-10,  3.0786e-10,\n",
       "             3.0729e-10,  3.7951e-10,  9.9420e-11, -3.4489e-09,  3.5301e-10,\n",
       "             6.7184e-11, -7.4765e-10,  1.9874e-09,  4.1275e-10, -2.4559e-10,\n",
       "             5.4595e-11,  3.4541e-11, -4.6132e-11, -1.6157e-10, -1.0634e-09,\n",
       "            -1.9548e-09, -6.4169e-10, -1.3043e-10,  7.6176e-10, -1.8471e-09,\n",
       "             9.3299e-10, -4.6521e-10,  1.7875e-09,  1.9603e-10, -2.6777e-09,\n",
       "             3.2693e-10, -2.4140e-09,  4.7910e-10, -1.0799e-09,  3.7962e-10,\n",
       "            -3.7691e-10,  1.2382e-09,  5.1598e-10,  2.6280e-10,  6.2139e-11],\n",
       "           device='cuda:0'),\n",
       "    'exp_avg_sq': tensor([1.2965e-18, 5.7352e-18, 7.0143e-18, 6.7932e-18, 1.5925e-17, 1.3230e-17,\n",
       "            2.7751e-18, 7.0278e-18, 3.7645e-18, 3.5847e-18, 4.2963e-20, 1.0759e-17,\n",
       "            9.9219e-18, 5.3878e-18, 5.3365e-18, 6.7499e-18, 7.9991e-19, 1.2591e-17,\n",
       "            1.7657e-18, 5.4090e-18, 5.0375e-18, 2.5860e-18, 6.5584e-18, 7.0002e-18,\n",
       "            2.3867e-18, 1.5340e-18, 3.3613e-19, 2.4434e-18, 3.1189e-19, 2.5056e-17,\n",
       "            6.1491e-18, 9.5529e-18, 1.5268e-17, 5.1593e-18, 5.0272e-18, 5.9343e-18,\n",
       "            7.5854e-18, 6.0741e-18, 1.0178e-17, 3.5322e-19, 9.1789e-19, 2.2008e-19,\n",
       "            9.1635e-20, 8.8371e-18, 8.3468e-18, 1.6739e-18, 8.8601e-19, 4.9997e-18,\n",
       "            1.2282e-17, 6.1911e-19, 1.2670e-17, 9.2902e-18, 1.2760e-18, 9.8434e-18,\n",
       "            1.0938e-17, 8.0172e-19, 4.7624e-18, 1.3231e-18, 7.6169e-18, 1.0721e-17,\n",
       "            7.9038e-18, 3.4702e-18, 2.1725e-18, 1.7820e-17, 2.6570e-18, 5.3758e-18,\n",
       "            2.3640e-18, 1.7189e-19, 1.5577e-17, 2.2895e-19, 5.1532e-20, 2.2580e-18,\n",
       "            1.5661e-17, 2.7621e-18, 1.0521e-18, 1.0035e-19, 1.2781e-17, 8.0746e-18,\n",
       "            1.6640e-18, 1.3815e-17, 5.9659e-18, 3.5579e-18, 4.0412e-18, 9.7594e-18,\n",
       "            1.1464e-17, 7.6190e-18, 7.4973e-18, 1.1358e-17, 1.8759e-18, 2.1657e-17,\n",
       "            5.2493e-19, 1.4841e-17, 1.0374e-17, 3.7550e-18, 1.4710e-18, 1.2761e-18,\n",
       "            4.9877e-18, 1.6473e-18, 3.8221e-18, 2.9564e-20], device='cuda:0')},\n",
       "   15: {'step': 306693,\n",
       "    'exp_avg': tensor([[ 1.9216e-06, -7.8863e-06, -3.8155e-06,  ...,  2.4463e-05,\n",
       "             -1.7297e-05,  1.5983e-05],\n",
       "            [ 3.1730e-05, -1.0531e-04,  1.3641e-05,  ...,  5.3640e-05,\n",
       "              2.9982e-05, -5.1388e-05],\n",
       "            [-1.9344e-05, -1.9694e-05,  8.3736e-06,  ..., -7.4812e-05,\n",
       "             -3.9034e-05, -4.9979e-05],\n",
       "            ...,\n",
       "            [-7.8149e-05, -9.5292e-05,  4.0046e-05,  ..., -3.1171e-04,\n",
       "              1.4855e-04,  4.4958e-05],\n",
       "            [-5.8031e-05,  5.6556e-04, -2.3597e-04,  ...,  2.2408e-04,\n",
       "             -2.2500e-04, -4.3517e-05],\n",
       "            [ 2.4857e-04,  2.4638e-05,  2.5575e-04,  ...,  2.0143e-04,\n",
       "              7.2881e-05,  5.2219e-04]], device='cuda:0'),\n",
       "    'exp_avg_sq': tensor([[2.2779e-09, 6.9987e-09, 8.2798e-09,  ..., 8.1704e-09, 4.2319e-09,\n",
       "             7.1478e-09],\n",
       "            [2.6287e-08, 5.2406e-08, 3.8568e-08,  ..., 5.8920e-08, 2.6020e-08,\n",
       "             5.4444e-08],\n",
       "            [1.5733e-08, 4.8833e-08, 3.0389e-08,  ..., 5.3987e-08, 3.4074e-08,\n",
       "             3.7856e-08],\n",
       "            ...,\n",
       "            [4.8997e-07, 3.5038e-07, 5.1414e-07,  ..., 1.1150e-06, 4.3644e-07,\n",
       "             8.2275e-07],\n",
       "            [3.1642e-07, 1.0199e-06, 4.7855e-07,  ..., 6.0940e-07, 2.6997e-07,\n",
       "             6.6339e-07],\n",
       "            [8.4570e-07, 8.9556e-07, 1.0568e-06,  ..., 1.9683e-06, 6.7222e-07,\n",
       "             1.4728e-06]], device='cuda:0')},\n",
       "   16: {'step': 306693,\n",
       "    'exp_avg': tensor([[ 2.4996e-05,  2.2394e-05, -4.0868e-05,  ...,  3.8276e-05,\n",
       "             -3.0004e-05, -4.8811e-05],\n",
       "            [ 1.1424e-05,  5.5970e-06,  2.6284e-05,  ...,  1.2534e-05,\n",
       "              1.3150e-05, -4.7691e-06],\n",
       "            [ 6.7329e-06, -2.6964e-05,  3.3345e-05,  ...,  3.1049e-05,\n",
       "              2.7061e-05, -2.8952e-05],\n",
       "            ...,\n",
       "            [ 2.8489e-04,  7.3263e-05, -1.2686e-04,  ...,  3.0594e-04,\n",
       "              7.2237e-05, -2.5499e-04],\n",
       "            [-9.0665e-05,  2.3610e-04, -2.6478e-04,  ..., -2.6942e-04,\n",
       "             -2.1203e-04,  2.3107e-04],\n",
       "            [-6.6653e-05,  8.7720e-05, -2.4401e-05,  ...,  1.4033e-04,\n",
       "             -1.7345e-04, -4.8605e-05]], device='cuda:0'),\n",
       "    'exp_avg_sq': tensor([[4.6108e-09, 5.6065e-09, 1.4313e-08,  ..., 8.9364e-09, 6.6141e-09,\n",
       "             1.1529e-08],\n",
       "            [7.1086e-09, 6.0892e-08, 8.8340e-08,  ..., 9.0918e-08, 5.5459e-08,\n",
       "             6.3634e-08],\n",
       "            [6.0782e-09, 2.4366e-08, 3.8177e-08,  ..., 3.2680e-08, 2.2852e-08,\n",
       "             2.6898e-08],\n",
       "            ...,\n",
       "            [3.3553e-07, 8.1347e-07, 1.1859e-06,  ..., 8.9119e-07, 6.3232e-07,\n",
       "             8.7519e-07],\n",
       "            [5.2001e-08, 4.7634e-07, 6.7051e-07,  ..., 5.8669e-07, 3.9464e-07,\n",
       "             4.3181e-07],\n",
       "            [2.2067e-07, 4.2481e-07, 6.2081e-07,  ..., 4.8411e-07, 4.0814e-07,\n",
       "             4.9760e-07]], device='cuda:0')},\n",
       "   17: {'step': 306693,\n",
       "    'exp_avg': tensor([-4.5250e-05,  4.2666e-05,  3.8591e-05,  1.2075e-04, -2.9164e-07,\n",
       "             1.1809e-04,  1.2464e-04, -1.9572e-04, -1.9010e-06,  4.8991e-05,\n",
       "            -3.9745e-06,  1.7238e-04,  2.0725e-04, -5.6449e-06, -2.2774e-05,\n",
       "            -2.9370e-05,  8.2136e-05,  5.1208e-06,  1.2580e-06,  1.9019e-04,\n",
       "            -2.9465e-05,  1.4880e-05, -4.4872e-05, -1.7700e-05,  1.3696e-04,\n",
       "            -5.5660e-05, -2.5837e-05, -7.2835e-05,  4.4902e-05, -1.1724e-04,\n",
       "             2.1610e-04,  1.7700e-04,  2.6065e-05,  6.2962e-06,  1.1534e-05,\n",
       "            -3.7082e-05,  2.4228e-06,  8.5704e-05,  1.6316e-05,  9.8245e-05,\n",
       "            -5.3082e-05, -4.7030e-07,  7.7287e-06,  5.9958e-05,  1.3214e-05,\n",
       "             1.9326e-04,  5.8411e-04, -3.8155e-05,  2.1523e-05,  1.2958e-04,\n",
       "             6.8930e-06,  8.2340e-06, -3.8242e-05,  1.6767e-05, -8.6904e-05,\n",
       "            -5.3902e-05,  2.1041e-04,  1.4330e-04, -3.7757e-05,  8.0408e-05,\n",
       "             3.1115e-05, -5.1436e-05,  5.0826e-05,  1.8533e-04, -7.2678e-05,\n",
       "             1.2933e-04, -2.6144e-06, -8.7659e-06, -4.0621e-05, -1.9153e-04,\n",
       "            -1.1828e-05, -2.0533e-05, -2.4236e-05, -4.8755e-05,  9.5717e-06,\n",
       "             5.4792e-05,  1.2020e-04, -5.1599e-05, -3.0799e-05, -1.2215e-06,\n",
       "             2.6693e-05, -3.4456e-05, -2.3684e-05, -1.9961e-04, -4.8635e-05,\n",
       "            -7.8121e-05,  2.3306e-06,  6.0174e-06, -5.2971e-05, -1.0380e-04,\n",
       "             1.1377e-04,  2.9971e-05, -8.3577e-05, -9.2938e-06, -2.3045e-04,\n",
       "            -3.6425e-05, -9.7878e-05, -1.4061e-05,  9.3157e-06,  3.4464e-05,\n",
       "            -1.3975e-04, -1.3925e-04, -4.1799e-05, -1.0870e-04,  5.3762e-05,\n",
       "            -4.2015e-06, -5.7824e-05, -4.0218e-05,  1.2137e-05, -1.4339e-04,\n",
       "             1.5555e-05,  5.4375e-05, -1.8322e-05, -7.2636e-07,  7.6449e-06,\n",
       "            -2.4260e-05,  9.5724e-06,  1.2529e-05, -2.2210e-05,  4.8092e-06,\n",
       "             5.2281e-05,  6.4543e-05, -1.0701e-04, -4.0045e-05,  7.1726e-06,\n",
       "            -6.1823e-05, -1.3798e-04, -2.5172e-04, -1.1949e-04,  1.7401e-04,\n",
       "             1.5503e-04,  8.1981e-04, -5.6812e-05, -1.5891e-03, -6.4481e-04,\n",
       "             1.0940e-03, -6.0329e-05,  1.9445e-04, -3.4911e-04,  2.2088e-04,\n",
       "            -2.6860e-05, -9.3352e-06, -7.6943e-05,  4.7420e-05,  2.3819e-04,\n",
       "            -1.4080e-04,  7.5621e-06, -6.7141e-04,  4.5522e-04, -3.7173e-04,\n",
       "            -1.6346e-04,  5.4975e-04,  2.1022e-04,  1.9946e-04, -2.1337e-05,\n",
       "             1.6711e-04,  1.0267e-03,  2.3308e-04, -5.4202e-04, -4.7517e-04,\n",
       "             5.8988e-04, -8.4712e-06,  2.8645e-05,  1.7344e-04,  3.9086e-06,\n",
       "             3.5799e-04, -2.4947e-05,  1.5504e-03, -4.3446e-04,  2.0284e-04,\n",
       "            -2.5141e-04,  2.3724e-04,  1.2204e-04, -5.3181e-04, -1.4834e-03,\n",
       "             5.1822e-04,  2.6784e-05,  2.8284e-04,  2.9606e-04,  1.0557e-04,\n",
       "             8.5330e-05, -9.3344e-05, -1.9108e-04, -4.3964e-04,  6.9456e-04,\n",
       "            -5.4433e-04,  1.4206e-04,  1.4659e-04,  3.4865e-04, -8.9276e-05,\n",
       "            -3.4604e-04, -3.2456e-04], device='cuda:0'),\n",
       "    'exp_avg_sq': tensor([1.7337e-08, 1.0043e-07, 4.7299e-08, 1.0110e-07, 2.0320e-09, 2.1191e-07,\n",
       "            1.5254e-06, 1.4689e-07, 4.5851e-09, 7.5201e-08, 3.3396e-08, 4.8824e-07,\n",
       "            4.5851e-07, 5.7369e-08, 2.0185e-08, 1.9212e-07, 4.4220e-08, 2.6737e-08,\n",
       "            4.8584e-11, 3.3726e-07, 1.2860e-08, 1.2835e-08, 7.0708e-08, 4.8004e-08,\n",
       "            3.4486e-07, 8.0900e-07, 2.4506e-08, 2.7719e-08, 6.3254e-07, 1.2310e-07,\n",
       "            4.6841e-07, 5.2992e-07, 4.8254e-08, 1.4080e-09, 5.7604e-09, 1.6430e-08,\n",
       "            7.3939e-10, 1.0332e-07, 1.0264e-07, 8.6216e-08, 2.5090e-07, 1.7399e-09,\n",
       "            2.0427e-09, 1.9109e-07, 2.6378e-09, 9.3387e-07, 3.1297e-06, 2.3967e-07,\n",
       "            3.1174e-08, 3.5283e-06, 3.5262e-08, 2.4793e-09, 1.2022e-08, 1.1319e-07,\n",
       "            2.6532e-08, 1.5005e-07, 5.2585e-07, 2.2569e-07, 3.3333e-08, 3.6509e-08,\n",
       "            2.0908e-08, 1.3756e-08, 4.5558e-08, 8.1207e-07, 4.9090e-08, 6.4869e-08,\n",
       "            1.0088e-08, 3.0026e-08, 8.5578e-09, 2.3265e-07, 2.0224e-07, 1.5578e-07,\n",
       "            8.3352e-09, 3.8177e-08, 3.7636e-08, 1.4470e-07, 1.6613e-07, 3.9224e-08,\n",
       "            4.4311e-08, 4.6241e-08, 2.5471e-08, 4.5676e-08, 1.1578e-08, 1.8572e-07,\n",
       "            3.9701e-08, 5.0338e-08, 4.4423e-09, 1.6808e-08, 8.9454e-08, 9.1322e-07,\n",
       "            5.2422e-08, 1.2300e-08, 1.4115e-07, 2.1628e-08, 2.6484e-07, 5.1016e-07,\n",
       "            7.9748e-08, 1.7417e-08, 2.0881e-08, 1.1084e-08, 7.1365e-07, 6.8150e-07,\n",
       "            1.9093e-08, 9.8121e-08, 1.9551e-07, 5.5932e-09, 4.0761e-07, 6.1396e-08,\n",
       "            2.8217e-09, 1.5410e-07, 4.1766e-07, 6.2457e-08, 1.2270e-08, 1.8738e-08,\n",
       "            6.1702e-09, 5.3054e-08, 1.6221e-09, 1.3081e-07, 4.4005e-08, 1.3912e-07,\n",
       "            4.7087e-07, 5.0556e-08, 4.4540e-08, 3.4037e-08, 6.4406e-09, 1.3369e-07,\n",
       "            6.4089e-07, 3.4625e-07, 6.2575e-06, 5.9571e-06, 6.0282e-07, 8.1007e-06,\n",
       "            2.7508e-07, 1.3450e-05, 2.5623e-05, 1.2754e-05, 7.1637e-07, 3.1928e-06,\n",
       "            3.4709e-06, 5.6285e-06, 4.8150e-06, 1.0855e-06, 9.9822e-07, 6.0408e-06,\n",
       "            6.8553e-07, 1.8206e-06, 1.5397e-09, 6.0335e-06, 1.9149e-06, 7.8028e-07,\n",
       "            3.5442e-06, 2.8381e-06, 3.5644e-06, 1.0745e-05, 2.5265e-07, 9.0838e-07,\n",
       "            1.3317e-05, 5.7758e-06, 3.9787e-06, 4.0268e-06, 2.2372e-06, 4.0998e-07,\n",
       "            6.2080e-07, 9.1786e-07, 1.1858e-07, 1.3796e-06, 1.8118e-07, 2.2384e-05,\n",
       "            7.9456e-06, 3.5760e-07, 4.8697e-07, 3.1991e-06, 1.4895e-07, 2.7518e-05,\n",
       "            2.0490e-05, 1.6355e-06, 1.5457e-07, 2.5505e-05, 3.9497e-06, 9.3791e-07,\n",
       "            1.1539e-07, 2.1634e-06, 1.3164e-06, 4.4626e-06, 7.0706e-06, 2.0569e-06,\n",
       "            9.7889e-07, 1.1204e-06, 1.2378e-06, 2.3273e-06, 1.2753e-06, 4.7588e-06],\n",
       "           device='cuda:0')},\n",
       "   18: {'step': 306693,\n",
       "    'exp_avg': tensor([-4.5250e-05,  4.2666e-05,  3.8591e-05,  1.2075e-04, -2.9164e-07,\n",
       "             1.1809e-04,  1.2464e-04, -1.9572e-04, -1.9010e-06,  4.8991e-05,\n",
       "            -3.9745e-06,  1.7238e-04,  2.0725e-04, -5.6449e-06, -2.2774e-05,\n",
       "            -2.9370e-05,  8.2136e-05,  5.1208e-06,  1.2580e-06,  1.9019e-04,\n",
       "            -2.9465e-05,  1.4880e-05, -4.4872e-05, -1.7700e-05,  1.3696e-04,\n",
       "            -5.5660e-05, -2.5837e-05, -7.2835e-05,  4.4902e-05, -1.1724e-04,\n",
       "             2.1610e-04,  1.7700e-04,  2.6065e-05,  6.2962e-06,  1.1534e-05,\n",
       "            -3.7082e-05,  2.4228e-06,  8.5704e-05,  1.6316e-05,  9.8245e-05,\n",
       "            -5.3082e-05, -4.7030e-07,  7.7287e-06,  5.9958e-05,  1.3214e-05,\n",
       "             1.9326e-04,  5.8411e-04, -3.8155e-05,  2.1523e-05,  1.2958e-04,\n",
       "             6.8930e-06,  8.2340e-06, -3.8242e-05,  1.6767e-05, -8.6904e-05,\n",
       "            -5.3902e-05,  2.1041e-04,  1.4330e-04, -3.7757e-05,  8.0408e-05,\n",
       "             3.1115e-05, -5.1436e-05,  5.0826e-05,  1.8533e-04, -7.2678e-05,\n",
       "             1.2933e-04, -2.6144e-06, -8.7659e-06, -4.0621e-05, -1.9153e-04,\n",
       "            -1.1828e-05, -2.0533e-05, -2.4236e-05, -4.8755e-05,  9.5717e-06,\n",
       "             5.4792e-05,  1.2020e-04, -5.1599e-05, -3.0799e-05, -1.2215e-06,\n",
       "             2.6693e-05, -3.4456e-05, -2.3684e-05, -1.9961e-04, -4.8635e-05,\n",
       "            -7.8121e-05,  2.3306e-06,  6.0174e-06, -5.2971e-05, -1.0380e-04,\n",
       "             1.1377e-04,  2.9971e-05, -8.3577e-05, -9.2938e-06, -2.3045e-04,\n",
       "            -3.6425e-05, -9.7878e-05, -1.4061e-05,  9.3157e-06,  3.4464e-05,\n",
       "            -1.3975e-04, -1.3925e-04, -4.1799e-05, -1.0870e-04,  5.3762e-05,\n",
       "            -4.2015e-06, -5.7824e-05, -4.0218e-05,  1.2137e-05, -1.4339e-04,\n",
       "             1.5555e-05,  5.4375e-05, -1.8322e-05, -7.2636e-07,  7.6449e-06,\n",
       "            -2.4260e-05,  9.5724e-06,  1.2529e-05, -2.2210e-05,  4.8092e-06,\n",
       "             5.2281e-05,  6.4543e-05, -1.0701e-04, -4.0045e-05,  7.1726e-06,\n",
       "            -6.1823e-05, -1.3798e-04, -2.5172e-04, -9.4108e-05,  9.5790e-05,\n",
       "             7.6547e-05,  4.5839e-04, -1.9517e-05, -7.5360e-04, -2.9647e-04,\n",
       "             2.5020e-04, -1.9864e-05,  2.0618e-04, -2.5375e-04,  2.2857e-05,\n",
       "             7.2321e-05,  1.1534e-05, -7.9296e-06, -8.9442e-05,  1.4890e-04,\n",
       "             6.6805e-06,  7.2626e-06, -4.0886e-04,  4.4227e-04, -3.2930e-04,\n",
       "             6.9655e-05,  1.6869e-04,  1.5437e-04,  9.6030e-05, -1.6162e-05,\n",
       "             1.2731e-04,  6.5453e-04,  8.2880e-05, -2.2497e-04, -2.5485e-04,\n",
       "             3.7961e-04, -7.3825e-06,  2.0630e-05,  3.6501e-05,  1.7278e-05,\n",
       "             1.7012e-04, -1.0353e-05,  8.6444e-04, -1.2504e-04,  1.9459e-04,\n",
       "            -2.3933e-04,  1.9047e-04,  7.9084e-05, -5.3769e-04, -5.7229e-04,\n",
       "             4.0625e-04,  1.7165e-05,  3.2175e-04,  6.9513e-05,  8.2849e-05,\n",
       "             4.4442e-05, -2.7609e-05, -1.0418e-04, -1.2268e-04,  4.4086e-04,\n",
       "            -1.8559e-04,  1.1601e-04,  1.8967e-04,  3.0995e-04, -3.7478e-05,\n",
       "            -3.0132e-04, -1.0864e-04], device='cuda:0'),\n",
       "    'exp_avg_sq': tensor([1.7337e-08, 1.0043e-07, 4.7299e-08, 1.0110e-07, 2.0320e-09, 2.1191e-07,\n",
       "            1.5254e-06, 1.4689e-07, 4.5851e-09, 7.5201e-08, 3.3396e-08, 4.8824e-07,\n",
       "            4.5851e-07, 5.7369e-08, 2.0185e-08, 1.9212e-07, 4.4220e-08, 2.6737e-08,\n",
       "            4.8584e-11, 3.3726e-07, 1.2860e-08, 1.2835e-08, 7.0708e-08, 4.8004e-08,\n",
       "            3.4486e-07, 8.0900e-07, 2.4506e-08, 2.7719e-08, 6.3254e-07, 1.2310e-07,\n",
       "            4.6841e-07, 5.2992e-07, 4.8254e-08, 1.4080e-09, 5.7604e-09, 1.6430e-08,\n",
       "            7.3939e-10, 1.0332e-07, 1.0264e-07, 8.6216e-08, 2.5090e-07, 1.7399e-09,\n",
       "            2.0427e-09, 1.9109e-07, 2.6378e-09, 9.3387e-07, 3.1297e-06, 2.3967e-07,\n",
       "            3.1174e-08, 3.5283e-06, 3.5262e-08, 2.4793e-09, 1.2022e-08, 1.1319e-07,\n",
       "            2.6532e-08, 1.5005e-07, 5.2585e-07, 2.2569e-07, 3.3333e-08, 3.6509e-08,\n",
       "            2.0908e-08, 1.3756e-08, 4.5558e-08, 8.1207e-07, 4.9090e-08, 6.4869e-08,\n",
       "            1.0088e-08, 3.0026e-08, 8.5578e-09, 2.3265e-07, 2.0224e-07, 1.5578e-07,\n",
       "            8.3352e-09, 3.8177e-08, 3.7636e-08, 1.4470e-07, 1.6613e-07, 3.9224e-08,\n",
       "            4.4311e-08, 4.6241e-08, 2.5471e-08, 4.5676e-08, 1.1578e-08, 1.8572e-07,\n",
       "            3.9701e-08, 5.0338e-08, 4.4423e-09, 1.6808e-08, 8.9454e-08, 9.1322e-07,\n",
       "            5.2422e-08, 1.2300e-08, 1.4115e-07, 2.1628e-08, 2.6484e-07, 5.1016e-07,\n",
       "            7.9748e-08, 1.7417e-08, 2.0881e-08, 1.1084e-08, 7.1365e-07, 6.8150e-07,\n",
       "            1.9093e-08, 9.8121e-08, 1.9551e-07, 5.5932e-09, 4.0761e-07, 6.1396e-08,\n",
       "            2.8217e-09, 1.5410e-07, 4.1766e-07, 6.2457e-08, 1.2270e-08, 1.8738e-08,\n",
       "            6.1702e-09, 5.3054e-08, 1.6221e-09, 1.3081e-07, 4.4005e-08, 1.3912e-07,\n",
       "            4.7087e-07, 5.0556e-08, 4.4540e-08, 3.4037e-08, 6.4406e-09, 1.3369e-07,\n",
       "            6.4089e-07, 3.4625e-07, 4.4509e-07, 1.9410e-06, 1.8186e-07, 1.9080e-06,\n",
       "            9.3999e-08, 2.2051e-06, 4.3120e-06, 1.1558e-06, 3.3052e-07, 7.2338e-07,\n",
       "            1.6666e-06, 1.2864e-06, 1.9600e-06, 2.1800e-07, 6.1472e-07, 8.8110e-07,\n",
       "            3.4012e-07, 1.0874e-07, 1.1894e-09, 1.0642e-06, 1.7162e-06, 4.8734e-07,\n",
       "            1.1789e-07, 2.5193e-07, 5.5120e-07, 1.8943e-06, 8.6087e-08, 4.1178e-07,\n",
       "            2.9923e-06, 2.9128e-07, 1.1847e-06, 1.0857e-06, 8.6329e-07, 3.7228e-07,\n",
       "            5.3197e-07, 1.9103e-07, 1.0890e-07, 5.1091e-07, 4.4498e-08, 5.7993e-06,\n",
       "            1.2094e-06, 3.2070e-07, 4.3363e-07, 1.0703e-06, 5.2896e-08, 3.9664e-06,\n",
       "            3.1718e-06, 7.4251e-07, 3.1803e-08, 4.2842e-06, 3.7194e-07, 7.1016e-07,\n",
       "            4.8843e-08, 9.3337e-07, 1.4086e-07, 4.4620e-07, 2.8058e-06, 2.8241e-07,\n",
       "            3.8956e-07, 7.1929e-07, 7.3923e-07, 1.6760e-06, 8.5153e-07, 8.3955e-07],\n",
       "           device='cuda:0')},\n",
       "   19: {'step': 306693,\n",
       "    'exp_avg': tensor([[-2.5120e-06, -5.0400e-06,  8.4891e-05,  ...,  3.8110e-05,\n",
       "             -1.7053e-05, -4.5105e-05],\n",
       "            [ 5.9310e-05,  3.7254e-05,  6.1687e-06,  ...,  7.3537e-05,\n",
       "             -7.9536e-05, -1.5983e-04],\n",
       "            [ 3.3097e-05, -1.0759e-05, -8.7031e-05,  ...,  2.0455e-05,\n",
       "             -8.3737e-06, -2.6633e-05],\n",
       "            ...,\n",
       "            [ 5.4019e-05, -2.0036e-04,  1.1991e-04,  ..., -1.8659e-04,\n",
       "              1.7760e-04,  2.9897e-05],\n",
       "            [-3.7894e-04, -3.9499e-05,  2.6056e-04,  ...,  1.2126e-04,\n",
       "              2.0134e-04,  1.2866e-04],\n",
       "            [ 1.5037e-04,  1.9729e-04, -2.3133e-04,  ...,  8.8932e-05,\n",
       "             -1.0021e-04, -7.6934e-05]], device='cuda:0'),\n",
       "    'exp_avg_sq': tensor([[1.2264e-08, 8.2559e-09, 7.1947e-08,  ..., 3.6355e-08, 2.3013e-08,\n",
       "             3.0225e-08],\n",
       "            [8.7115e-08, 6.0714e-08, 4.3214e-07,  ..., 1.5070e-07, 1.1091e-07,\n",
       "             1.7495e-07],\n",
       "            [2.9240e-08, 2.2887e-08, 1.7530e-07,  ..., 6.1207e-08, 4.6959e-08,\n",
       "             7.3292e-08],\n",
       "            ...,\n",
       "            [2.2890e-07, 1.8241e-07, 3.9381e-07,  ..., 3.1972e-07, 2.3035e-07,\n",
       "             4.2574e-07],\n",
       "            [4.7191e-07, 3.7357e-07, 1.3726e-06,  ..., 2.7211e-07, 3.5296e-07,\n",
       "             4.3557e-07],\n",
       "            [1.1613e-07, 9.6212e-08, 3.7688e-07,  ..., 2.0348e-07, 8.5364e-08,\n",
       "             1.7557e-07]], device='cuda:0')},\n",
       "   20: {'step': 306693,\n",
       "    'exp_avg': tensor([[ 5.7684e-05, -5.1467e-05,  2.4703e-05,  ...,  3.8026e-05,\n",
       "             -6.3062e-06,  3.6890e-05],\n",
       "            [-4.8792e-05, -3.2335e-05, -7.4557e-05,  ...,  7.0877e-05,\n",
       "              5.2868e-05,  5.1707e-05],\n",
       "            [-6.5361e-05,  1.0375e-04, -8.7961e-05,  ...,  8.7220e-05,\n",
       "              1.0087e-04,  7.0171e-05],\n",
       "            ...,\n",
       "            [ 1.8733e-04, -1.9341e-04,  1.8879e-04,  ..., -2.1844e-04,\n",
       "             -1.5567e-04, -1.7483e-04],\n",
       "            [-1.5281e-05,  3.3360e-04,  1.4654e-04,  ...,  2.6302e-04,\n",
       "              2.2072e-04,  2.4530e-04],\n",
       "            [ 5.2322e-06,  1.8686e-05, -3.7116e-05,  ...,  6.7486e-05,\n",
       "             -8.4632e-05,  2.4464e-05]], device='cuda:0'),\n",
       "    'exp_avg_sq': tensor([[5.6077e-08, 4.9212e-08, 3.9588e-08,  ..., 5.0101e-08, 3.9785e-08,\n",
       "             5.4339e-08],\n",
       "            [3.3303e-07, 3.2445e-07, 2.7150e-07,  ..., 3.1193e-07, 2.7761e-07,\n",
       "             3.3643e-07],\n",
       "            [1.5333e-07, 1.5425e-07, 1.4955e-07,  ..., 2.0368e-07, 1.6782e-07,\n",
       "             2.0737e-07],\n",
       "            ...,\n",
       "            [3.4299e-07, 3.3806e-07, 3.3915e-07,  ..., 3.4503e-07, 3.5431e-07,\n",
       "             3.5610e-07],\n",
       "            [1.0899e-06, 9.4439e-07, 1.0498e-06,  ..., 9.0355e-07, 1.1341e-06,\n",
       "             1.0833e-06],\n",
       "            [8.3345e-08, 8.0467e-08, 7.1146e-08,  ..., 7.8514e-08, 8.9233e-08,\n",
       "             8.6924e-08]], device='cuda:0')},\n",
       "   21: {'step': 306693,\n",
       "    'exp_avg': tensor([ 5.6696e-05, -4.4637e-05, -7.0255e-05, -4.9052e-05, -6.3248e-05,\n",
       "             1.1224e-04, -6.4630e-07,  8.8141e-06,  1.2515e-05,  1.0524e-05,\n",
       "            -5.8038e-08,  2.9951e-06, -3.7457e-05, -3.3316e-05,  8.7140e-05,\n",
       "            -2.5403e-05,  6.3567e-05, -6.7979e-05,  2.9920e-07, -2.9197e-05,\n",
       "            -4.4385e-06, -3.3240e-06, -6.9434e-05,  7.4042e-06, -1.6348e-04,\n",
       "            -1.0590e-04, -3.9919e-05,  2.9109e-05, -1.3288e-05, -1.0446e-05,\n",
       "            -2.7137e-05, -9.5080e-06, -1.8748e-06, -1.4602e-05, -2.3105e-05,\n",
       "             4.1011e-05,  6.8841e-05, -4.7229e-08,  3.2188e-05,  4.8593e-05,\n",
       "             5.5478e-06, -1.6412e-04, -1.3786e-06,  2.8396e-06, -6.3583e-05,\n",
       "             1.2704e-06,  5.0648e-05, -8.8990e-05,  1.0242e-05,  3.4592e-05,\n",
       "             1.0862e-05, -8.4950e-07,  2.0887e-05, -1.2083e-04, -7.5564e-05,\n",
       "             4.1197e-05, -3.0519e-05,  1.1913e-05,  3.3397e-07,  7.6948e-06,\n",
       "             5.2544e-05,  1.7286e-06, -4.6413e-05,  1.7641e-05,  7.0773e-05,\n",
       "             1.1780e-05,  7.3251e-07,  6.5101e-08, -7.2027e-06, -3.0201e-05,\n",
       "             1.7005e-07, -8.9119e-07,  4.4866e-06, -3.1279e-05,  1.7473e-06,\n",
       "            -1.0352e-05,  2.0667e-05, -4.0981e-07, -1.1235e-05,  4.0919e-05,\n",
       "            -4.3824e-06,  3.6195e-07,  1.0861e-07,  5.3546e-06, -3.4370e-05,\n",
       "            -5.4916e-06,  1.8925e-05,  1.0720e-04, -1.4627e-05,  2.6844e-05,\n",
       "            -2.8786e-05, -1.7917e-05, -9.7737e-06,  1.0545e-05, -1.2179e-04,\n",
       "             9.8187e-06, -3.5449e-06,  6.8520e-06,  3.1765e-06,  8.7121e-05,\n",
       "             4.9657e-06,  6.9464e-07,  1.3831e-06,  1.4682e-05,  5.9307e-06,\n",
       "             7.5180e-07, -1.2144e-05,  8.1631e-06,  3.1295e-05, -1.3901e-06,\n",
       "            -9.6554e-05, -3.2878e-07, -1.5330e-06,  7.1140e-06,  2.7004e-07,\n",
       "            -3.6292e-07,  1.2233e-06, -1.0589e-06,  1.1026e-05,  1.9337e-06,\n",
       "             9.1118e-06,  1.5377e-04, -9.1227e-06,  4.5399e-06,  5.0413e-06,\n",
       "            -1.6961e-05,  6.8993e-05,  4.8158e-06,  1.0010e-04,  1.3986e-04,\n",
       "            -1.5537e-04,  4.5191e-04, -1.7600e-04,  4.3930e-04, -4.9997e-04,\n",
       "             7.8848e-06,  4.6661e-05, -5.4647e-05, -8.2652e-07, -8.0189e-05,\n",
       "             2.2254e-05,  1.3642e-04,  2.3455e-04,  9.4936e-06, -9.9204e-05,\n",
       "            -1.2326e-04, -5.3258e-05,  1.0866e-04,  2.5157e-05,  2.2783e-05,\n",
       "            -9.1542e-05,  9.3534e-05, -2.3966e-04, -1.9638e-04,  2.8172e-04,\n",
       "             4.9622e-05, -1.3091e-04,  1.2005e-04,  7.8313e-05, -4.5578e-05,\n",
       "             2.2146e-04,  1.1520e-04, -4.1222e-05, -1.6236e-04,  2.1601e-04,\n",
       "             4.0081e-05,  7.6809e-05, -2.0782e-04, -3.1645e-05, -1.3069e-04,\n",
       "             1.5221e-05,  1.2418e-04, -2.6056e-05, -2.0389e-06,  1.6225e-04,\n",
       "             6.4943e-05, -6.9351e-05, -4.5368e-05, -4.7631e-05,  2.2193e-04,\n",
       "            -5.6340e-05, -3.6543e-04, -1.7722e-05, -2.9664e-05,  4.3120e-04,\n",
       "             8.2769e-06,  7.6037e-06,  1.1674e-04, -1.8757e-04,  1.9022e-04,\n",
       "            -2.5620e-05, -1.1881e-04], device='cuda:0'),\n",
       "    'exp_avg_sq': tensor([5.6815e-08, 3.4406e-07, 1.5809e-07, 4.6687e-08, 1.7079e-07, 2.0703e-07,\n",
       "            6.5606e-11, 1.2971e-07, 1.9709e-08, 2.0931e-09, 2.5597e-13, 3.7622e-07,\n",
       "            2.0016e-08, 2.1441e-08, 9.0075e-08, 3.5387e-08, 4.4230e-08, 2.4573e-08,\n",
       "            1.8313e-11, 2.4577e-08, 8.3880e-08, 4.1526e-09, 2.0932e-07, 1.7367e-08,\n",
       "            6.2726e-07, 7.5788e-08, 2.3302e-08, 3.2681e-07, 2.0829e-07, 7.7478e-08,\n",
       "            8.3048e-08, 1.3832e-07, 4.1443e-09, 5.8386e-09, 3.3605e-08, 5.4047e-08,\n",
       "            6.0599e-08, 1.9743e-12, 6.4248e-08, 1.5792e-07, 3.6976e-08, 1.7913e-07,\n",
       "            4.2076e-10, 1.3553e-08, 3.6441e-07, 2.4521e-11, 7.4354e-08, 1.0210e-07,\n",
       "            4.5669e-07, 3.7204e-08, 2.9232e-09, 8.4032e-09, 1.6560e-08, 1.1935e-07,\n",
       "            4.0553e-07, 4.0870e-08, 8.7438e-09, 3.4507e-09, 5.9715e-11, 2.2033e-08,\n",
       "            7.7980e-08, 2.0223e-10, 4.8000e-08, 6.4194e-08, 9.7149e-08, 1.0156e-08,\n",
       "            1.8497e-09, 1.5816e-10, 9.2674e-09, 6.3748e-08, 9.9604e-08, 5.2691e-10,\n",
       "            1.0140e-09, 1.1519e-07, 1.9997e-10, 2.0464e-08, 2.7525e-09, 2.2067e-11,\n",
       "            1.9145e-08, 1.8185e-08, 2.7232e-10, 2.4543e-10, 1.0347e-10, 5.3678e-09,\n",
       "            7.6405e-09, 4.3182e-10, 2.0528e-08, 3.6311e-07, 2.0059e-09, 2.0008e-07,\n",
       "            9.6262e-08, 6.0125e-08, 5.3857e-09, 4.2972e-09, 5.4935e-07, 1.1143e-08,\n",
       "            3.6734e-10, 7.7090e-09, 2.0112e-10, 1.0158e-07, 2.0909e-10, 8.1859e-11,\n",
       "            1.3191e-10, 1.4844e-07, 4.8732e-10, 2.9896e-11, 1.4956e-08, 1.7790e-08,\n",
       "            3.5096e-09, 8.3625e-11, 1.1678e-07, 7.6743e-09, 9.9560e-08, 1.5924e-09,\n",
       "            7.0697e-10, 3.0433e-10, 6.4104e-10, 1.1735e-09, 5.5840e-08, 2.5266e-10,\n",
       "            9.9499e-08, 8.7065e-07, 3.4124e-09, 1.0279e-09, 4.0407e-10, 3.2470e-08,\n",
       "            6.2586e-08, 2.9361e-09, 4.5375e-07, 1.2165e-06, 1.1738e-06, 1.3589e-06,\n",
       "            9.7990e-07, 1.0567e-06, 6.7349e-07, 8.3401e-07, 9.5357e-07, 6.1511e-07,\n",
       "            2.1561e-10, 6.3590e-07, 3.4925e-07, 8.0274e-07, 5.0772e-07, 6.2995e-07,\n",
       "            7.5728e-07, 7.6689e-07, 7.8486e-07, 4.1684e-07, 3.4712e-07, 6.3817e-08,\n",
       "            5.6743e-07, 8.0079e-07, 1.4001e-06, 4.2603e-07, 8.0638e-07, 2.8084e-07,\n",
       "            1.3721e-06, 8.0666e-07, 1.8533e-07, 8.1865e-07, 6.8434e-07, 7.1066e-07,\n",
       "            3.1305e-07, 5.1273e-07, 3.5258e-07, 1.2352e-07, 4.5342e-07, 8.3525e-07,\n",
       "            2.7870e-07, 6.7385e-07, 1.1780e-07, 7.5027e-07, 9.5927e-07, 6.0760e-10,\n",
       "            2.4222e-07, 1.4725e-07, 8.8153e-07, 2.6651e-07, 7.5757e-08, 7.0187e-07,\n",
       "            1.1012e-07, 8.6672e-07, 3.6206e-07, 1.1103e-06, 9.0131e-07, 5.4533e-07,\n",
       "            1.8121e-09, 7.8527e-07, 4.9003e-07, 3.5324e-07, 1.3838e-06, 2.8102e-07],\n",
       "           device='cuda:0')},\n",
       "   22: {'step': 306693,\n",
       "    'exp_avg': tensor([ 5.6696e-05, -4.4637e-05, -7.0255e-05, -4.9052e-05, -6.3248e-05,\n",
       "             1.1224e-04, -6.4630e-07,  8.8141e-06,  1.2515e-05,  1.0524e-05,\n",
       "            -5.8038e-08,  2.9951e-06, -3.7457e-05, -3.3316e-05,  8.7140e-05,\n",
       "            -2.5403e-05,  6.3567e-05, -6.7979e-05,  2.9920e-07, -2.9197e-05,\n",
       "            -4.4385e-06, -3.3240e-06, -6.9434e-05,  7.4042e-06, -1.6348e-04,\n",
       "            -1.0590e-04, -3.9919e-05,  2.9109e-05, -1.3288e-05, -1.0446e-05,\n",
       "            -2.7137e-05, -9.5080e-06, -1.8748e-06, -1.4602e-05, -2.3105e-05,\n",
       "             4.1011e-05,  6.8841e-05, -4.7229e-08,  3.2188e-05,  4.8593e-05,\n",
       "             5.5478e-06, -1.6412e-04, -1.3786e-06,  2.8396e-06, -6.3583e-05,\n",
       "             1.2704e-06,  5.0648e-05, -8.8990e-05,  1.0242e-05,  3.4592e-05,\n",
       "             1.0862e-05, -8.4950e-07,  2.0887e-05, -1.2083e-04, -7.5564e-05,\n",
       "             4.1197e-05, -3.0519e-05,  1.1913e-05,  3.3397e-07,  7.6948e-06,\n",
       "             5.2544e-05,  1.7286e-06, -4.6413e-05,  1.7641e-05,  7.0773e-05,\n",
       "             1.1780e-05,  7.3251e-07,  6.5101e-08, -7.2027e-06, -3.0201e-05,\n",
       "             1.7005e-07, -8.9119e-07,  4.4866e-06, -3.1279e-05,  1.7473e-06,\n",
       "            -1.0352e-05,  2.0667e-05, -4.0981e-07, -1.1235e-05,  4.0919e-05,\n",
       "            -4.3824e-06,  3.6195e-07,  1.0861e-07,  5.3546e-06, -3.4370e-05,\n",
       "            -5.4916e-06,  1.8925e-05,  1.0720e-04, -1.4627e-05,  2.6844e-05,\n",
       "            -2.8786e-05, -1.7917e-05, -9.7737e-06,  1.0545e-05, -1.2179e-04,\n",
       "             9.8187e-06, -3.5449e-06,  6.8520e-06,  3.1765e-06,  8.7121e-05,\n",
       "             4.9657e-06,  6.9464e-07,  1.3831e-06,  1.4682e-05,  5.9307e-06,\n",
       "             7.5180e-07, -1.2144e-05,  8.1631e-06,  3.1295e-05, -1.3901e-06,\n",
       "            -9.6554e-05, -3.2878e-07, -1.5330e-06,  7.1140e-06,  2.7004e-07,\n",
       "            -3.6292e-07,  1.2233e-06, -1.0589e-06,  1.1026e-05,  1.9337e-06,\n",
       "             9.1118e-06,  1.5377e-04, -9.1227e-06,  4.5399e-06,  5.0413e-06,\n",
       "            -1.6961e-05,  6.8993e-05,  4.8158e-06,  5.8409e-05, -2.3773e-06,\n",
       "            -8.9861e-05,  1.3896e-04, -1.5141e-04,  2.9287e-05, -4.9948e-04,\n",
       "             5.4619e-06,  1.6762e-05, -6.9197e-05, -8.5040e-07, -5.8057e-05,\n",
       "             4.0449e-05,  1.3592e-04,  5.6296e-05,  6.8686e-06, -1.2524e-04,\n",
       "            -1.2073e-04, -5.2996e-05,  7.6931e-05, -3.3121e-06,  2.0092e-05,\n",
       "            -6.4976e-05,  3.1369e-05, -1.7864e-04, -1.4294e-04,  2.4363e-04,\n",
       "             1.7763e-05, -6.4307e-05,  8.3294e-05,  7.8656e-05, -3.2505e-05,\n",
       "             2.2831e-04,  8.8082e-05, -1.9429e-05,  1.0244e-04,  2.0086e-05,\n",
       "             4.0161e-05, -3.7037e-05, -2.3588e-04, -2.3060e-05, -1.8194e-05,\n",
       "             1.6314e-05,  1.0039e-04, -5.2290e-05, -1.5700e-06,  4.6811e-05,\n",
       "             1.1839e-05, -4.4409e-05, -4.0103e-06, -9.8848e-06,  2.1560e-04,\n",
       "            -1.3013e-05, -2.5116e-04, -2.3534e-05,  4.8755e-05,  4.0079e-04,\n",
       "             1.5861e-05,  6.6710e-06,  1.1419e-04, -4.5753e-05,  1.8674e-04,\n",
       "            -4.0847e-05,  1.5274e-05], device='cuda:0'),\n",
       "    'exp_avg_sq': tensor([5.6815e-08, 3.4406e-07, 1.5809e-07, 4.6687e-08, 1.7079e-07, 2.0703e-07,\n",
       "            6.5606e-11, 1.2971e-07, 1.9709e-08, 2.0931e-09, 2.5597e-13, 3.7622e-07,\n",
       "            2.0016e-08, 2.1441e-08, 9.0075e-08, 3.5387e-08, 4.4230e-08, 2.4573e-08,\n",
       "            1.8313e-11, 2.4577e-08, 8.3880e-08, 4.1526e-09, 2.0932e-07, 1.7367e-08,\n",
       "            6.2726e-07, 7.5788e-08, 2.3302e-08, 3.2681e-07, 2.0829e-07, 7.7478e-08,\n",
       "            8.3048e-08, 1.3832e-07, 4.1443e-09, 5.8386e-09, 3.3605e-08, 5.4047e-08,\n",
       "            6.0599e-08, 1.9743e-12, 6.4248e-08, 1.5792e-07, 3.6976e-08, 1.7913e-07,\n",
       "            4.2076e-10, 1.3553e-08, 3.6441e-07, 2.4521e-11, 7.4354e-08, 1.0210e-07,\n",
       "            4.5669e-07, 3.7204e-08, 2.9232e-09, 8.4032e-09, 1.6560e-08, 1.1935e-07,\n",
       "            4.0553e-07, 4.0870e-08, 8.7438e-09, 3.4507e-09, 5.9715e-11, 2.2033e-08,\n",
       "            7.7980e-08, 2.0223e-10, 4.8000e-08, 6.4194e-08, 9.7149e-08, 1.0156e-08,\n",
       "            1.8497e-09, 1.5816e-10, 9.2674e-09, 6.3748e-08, 9.9604e-08, 5.2691e-10,\n",
       "            1.0140e-09, 1.1519e-07, 1.9997e-10, 2.0464e-08, 2.7525e-09, 2.2067e-11,\n",
       "            1.9145e-08, 1.8185e-08, 2.7232e-10, 2.4543e-10, 1.0347e-10, 5.3678e-09,\n",
       "            7.6405e-09, 4.3182e-10, 2.0528e-08, 3.6311e-07, 2.0059e-09, 2.0008e-07,\n",
       "            9.6262e-08, 6.0125e-08, 5.3857e-09, 4.2972e-09, 5.4935e-07, 1.1143e-08,\n",
       "            3.6734e-10, 7.7090e-09, 2.0112e-10, 1.0158e-07, 2.0909e-10, 8.1859e-11,\n",
       "            1.3191e-10, 1.4844e-07, 4.8732e-10, 2.9896e-11, 1.4956e-08, 1.7790e-08,\n",
       "            3.5096e-09, 8.3625e-11, 1.1678e-07, 7.6743e-09, 9.9560e-08, 1.5924e-09,\n",
       "            7.0697e-10, 3.0433e-10, 6.4104e-10, 1.1735e-09, 5.5840e-08, 2.5266e-10,\n",
       "            9.9499e-08, 8.7065e-07, 3.4124e-09, 1.0279e-09, 4.0407e-10, 3.2470e-08,\n",
       "            6.2586e-08, 2.9361e-09, 1.6777e-07, 1.7008e-07, 2.1515e-07, 3.1325e-07,\n",
       "            6.2167e-07, 1.6523e-07, 6.6991e-07, 2.1156e-07, 2.3989e-07, 5.6514e-07,\n",
       "            1.9583e-10, 3.9542e-07, 1.3681e-08, 4.6633e-07, 1.4114e-07, 3.2732e-07,\n",
       "            6.2984e-07, 1.7511e-07, 7.8386e-07, 8.4546e-08, 8.6764e-08, 4.1005e-08,\n",
       "            1.1316e-07, 3.5450e-07, 5.8001e-07, 2.9479e-07, 6.7770e-07, 7.6065e-08,\n",
       "            1.2572e-07, 1.8730e-07, 1.2474e-07, 1.7053e-07, 6.0017e-07, 4.9472e-07,\n",
       "            1.8125e-08, 8.1388e-08, 3.7883e-08, 1.2349e-07, 5.3119e-08, 5.5798e-07,\n",
       "            2.4163e-08, 1.7310e-07, 9.6489e-08, 4.0334e-07, 2.1326e-07, 4.2024e-10,\n",
       "            3.1175e-08, 6.8391e-08, 1.6338e-07, 1.9963e-08, 3.7244e-09, 6.8530e-07,\n",
       "            5.5022e-09, 5.3945e-07, 8.4097e-08, 3.6748e-07, 7.3097e-07, 3.4421e-07,\n",
       "            1.3310e-09, 3.1984e-07, 7.5518e-08, 3.4746e-07, 1.1026e-06, 9.0131e-08],\n",
       "           device='cuda:0')},\n",
       "   23: {'step': 306693,\n",
       "    'exp_avg': tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "              0.0000e+00,  0.0000e+00],\n",
       "            [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "              0.0000e+00,  0.0000e+00],\n",
       "            [ 1.3087e-05,  1.2087e-05, -5.9040e-06,  ..., -5.2031e-06,\n",
       "              9.5205e-06,  8.3064e-06],\n",
       "            ...,\n",
       "            [-5.6052e-45,  5.6052e-45, -5.6052e-45,  ..., -5.6052e-45,\n",
       "              5.6052e-45, -5.6052e-45],\n",
       "            [-5.6052e-45,  5.6052e-45,  5.6052e-45,  ..., -5.6052e-45,\n",
       "              5.6052e-45, -5.6052e-45],\n",
       "            [-5.6052e-45,  5.6052e-45, -5.6052e-45,  ..., -5.6052e-45,\n",
       "             -5.6052e-45, -5.6052e-45]], device='cuda:0'),\n",
       "    'exp_avg_sq': tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
       "             0.0000e+00],\n",
       "            [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
       "             0.0000e+00],\n",
       "            [1.1455e-08, 1.8951e-08, 1.0448e-08,  ..., 4.8139e-09, 1.5086e-08,\n",
       "             6.1519e-08],\n",
       "            ...,\n",
       "            [4.8477e-19, 4.0996e-19, 5.2297e-19,  ..., 2.0960e-18, 3.2599e-18,\n",
       "             1.4187e-18],\n",
       "            [1.6147e-08, 9.7474e-09, 7.4340e-09,  ..., 7.2036e-09, 6.3901e-09,\n",
       "             3.4169e-08],\n",
       "            [2.5984e-13, 9.6556e-13, 2.7672e-13,  ..., 7.8933e-12, 2.1260e-11,\n",
       "             1.1003e-11]], device='cuda:0')},\n",
       "   24: {'step': 306693,\n",
       "    'exp_avg': tensor([ 0.0000e+00,  0.0000e+00,  1.7085e-09,  ..., -5.6052e-45,\n",
       "            -5.6052e-45, -5.6052e-45], device='cuda:0'),\n",
       "    'exp_avg_sq': tensor([0.0000e+00, 0.0000e+00, 6.3323e-18,  ..., 2.4416e-32, 4.6703e-23,\n",
       "            1.4116e-27], device='cuda:0')}},\n",
       "  'param_groups': [{'lr': 6.561e-06,\n",
       "    'betas': (0.9, 0.999),\n",
       "    'eps': 1e-08,\n",
       "    'weight_decay': 0,\n",
       "    'amsgrad': False,\n",
       "    'maximize': False,\n",
       "    'initial_lr': 1e-05,\n",
       "    'params': [0,\n",
       "     1,\n",
       "     2,\n",
       "     3,\n",
       "     4,\n",
       "     5,\n",
       "     6,\n",
       "     7,\n",
       "     8,\n",
       "     9,\n",
       "     10,\n",
       "     11,\n",
       "     12,\n",
       "     13,\n",
       "     14,\n",
       "     15,\n",
       "     16,\n",
       "     17,\n",
       "     18,\n",
       "     19,\n",
       "     20,\n",
       "     21,\n",
       "     22,\n",
       "     23,\n",
       "     24]}]},\n",
       " 'scheduler': {'step_size': 2,\n",
       "  'gamma': 0.9,\n",
       "  'base_lrs': [1e-05],\n",
       "  'last_epoch': 8,\n",
       "  '_step_count': 9,\n",
       "  'verbose': False,\n",
       "  '_get_lr_called_within_step': False,\n",
       "  '_last_lr': [6.561e-06]},\n",
       " 'criterion': OrderedDict()}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b6e6fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
